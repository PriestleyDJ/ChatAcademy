<?xml version="1.0" encoding="utf-8"?><api:response xmlns:api="http://www.symplectic.co.uk/publications/api"><api:version uri="https://mypublications.shef.ac.uk/" elements-version="6.17.0.4095" schema-version="6.13" product-name="myPublications"/><api:request href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1435337"/><api:result><api:object category="publication" id="1435337" last-affected-when="2024-05-06T15:10:04.49+01:00" last-modified-when="2024-05-06T15:10:04.49+01:00" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1435337" created-when="2022-09-20T16:42:43.917+01:00" type-id="5" type-display-name="Journal article" type="journal-article"><api:privacy-level>Public</api:privacy-level><api:privacy-level-locked>false</api:privacy-level-locked><api:ever-approved>true</api:ever-approved><api:reporting-date-1>2022-09-16</api:reporting-date-1><api:allow-type-switching>true</api:allow-type-switching><api:records><api:record format="native" id="4238679" source-id="28" source-name="eprints" source-display-name="White Rose Research Online" id-at-source="191263" last-modified-when="2023-01-05T12:43:00.957+00:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Spoken interactions between a human user and an artificial device (such as a social robot) have attracted much attention in recent decades (Lison and Meena, 2014; Oracle, 2020). Shifting from automation robots in the industrial domain, social robots are expected to be used in social domains, such as the service industry, education, healthcare, and entertainment (Bartneck et al., 2020, p.163).



According to Darling (2016)’s definition, a social robot is “a physically embodied, autonomous agent that communicates and interacts with humans on an emotional level”. Many features play important roles in interactions with a social robot, such as people’s experience with technology products, expectations of social robots, interactional environments and other features such as a social robot’s appearance, voice and behaviours. In this last regard, affordance design affects how people perceive a social robot and how such perception affects their behaviours and experiences. The term “affordance” was invented by ecological psychologist Gibson (1977), who proposed that our perception of what it is possible to do with objects is shaped by their form. Affordance indicates what users see and can do with an object in a given situation; it is about perceptual action possibilities in an environment (Matei, 2020).



A strong tendency in social robot affordance design is to make human-robot interaction (HRI) resemble human-human interaction (HHI). It is hoped in many studies that robots designed with anthropomorphic appearances and human-like cognitive behaviours can enable humans to interact with them in similar ways as they would interact with other humans, even to develop social bonds (Leite et al., 2013; Kahn et al., 2015; Koyama et al., 2017; Ligthart et al., 2018). However, there are concerns about this approach. In fact, speech-based artificial agents’ conversational interaction with human users is far from natural, and the language used tends to be formulaic (Moore et al., 2016).



One of the reasons behind this is a significant change in the applications of spoken human-agent interaction (HAI) along the evolution of spoken language technology applications (Moore, 2017a). Compared with “command and control systems” of the 1970s and contemporary smartphone-based “personal assistants”, social robots are expected to be used in more dynamic and open environments. This implies that users’ expectations, demands and ways to interact with spoken agents differ depending on the use case. What has succeeded before in real-time spoken HAI (e.g., voice command for specific uses) may not work well for social robots in some contacts. Additionally, a social robot’s human-like affordances could be seen as “dishonest” because such signals hide the fact that a social robot has limited interactive capabilities and is a “mismatched” conversational partner (Moore, 2015; 2017b). What’s more, the approach to constructing a robot by integrating off-the-shelf human-like technologies lacks an appreciation of the function and behaviour of speech in a broader theoretical framework (Moore, 2015).



This paper takes a step back to consider what human users look for when speaking to a social robot. It starts by looking at the nature and the process of spoken interactions. It then discusses why honesty is the best policy for a social robot in HRI. Furthermore, the arguments presented here support the hypothesis that aligning a social robot’s external affordances coherently with internal capabilities can shape its usability and improve human users’ experience in HRI.</api:text></api:field><api:field name="acceptance-date" type="date" display-name="Date of acceptance"><api:date><api:day>1</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30919" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30919"/></api:links><api:last-name>Huang</api:last-name><api:initials>G</api:initials><api:first-names>G</api:first-names><api:separate-first-names><api:first-name>G</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="1173" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1173"/></api:links><api:last-name>Moore</api:last-name><api:initials>RK</api:initials><api:first-names>RK</api:first-names><api:separate-first-names><api:first-name>R</api:first-name><api:first-name>K</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.3389/frvir.2022.1020169</api:text><api:links><api:link type="doi" href="http://doi.org/10.3389/frvir.2022.1020169"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.3389/frvir.2022.1020169"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2673-4192</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1431234"/></api:links></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2673-4192</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1431234"/></api:links></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>Frontiers in Virtual Reality</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>social robot</api:keyword><api:keyword>affordance design</api:keyword><api:keyword>honest signals</api:keyword><api:keyword>use cases</api:keyword><api:keyword>internal capabilities</api:keyword></api:keywords></api:field><api:field name="notes" type="text" display-name="Other information"><api:text>Copyright © 2022 Huang and Moore. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms (https://creativecommons.org/licenses/by/4.0/)</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>16</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published online</api:text></api:field><api:field name="public-url" type="text" display-name="Public URL"><api:text>https://eprints.whiterose.ac.uk/id/eprint/191263</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Frontiers Media SA</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>22</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="record-made-public-at-source-date" type="date" display-name="Record made publicly available"><api:date><api:day>10</api:day><api:month>10</api:month><api:year>2022</api:year></api:date></api:field><api:field name="repository-status" type="text" display-name="Availability"><api:text>Public</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Is honesty the best policy for mismatched partners? Aligning multi-modal affordances of a social robot: an opinion paper</api:text></api:field><api:files><api:file proprietary-id="https://eprints.whiterose.ac.uk/id/file/6108557"><api:filename>frvir-03-1020169.pdf</api:filename><api:file-url>https://eprints.whiterose.ac.uk/191263/1/frvir-03-1020169.pdf</api:file-url><api:extension>pdf</api:extension><api:file-size>559957</api:file-size><api:mime-type>application/pdf</api:mime-type><api:checksum algorithm="md5">CD9D4EB56BE51054747A396EE052BF87</api:checksum><api:file-version>Published version</api:file-version></api:file></api:files></api:native></api:record><api:record format="native" id="3903574" source-id="1" source-name="manual" source-display-name="Manual" id-at-source="5B1E5B1A-DAEB-4C39-8128-3107F9E08E07" last-modified-when="2022-10-10T12:04:02.507+01:00" is-locked="true"><api:verification-status>verified</api:verification-status><api:verification-comment>AF 10/10/2022</api:verification-comment><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>poken interactions between a human user and an artificial device (such as a social robot) have attracted much attention in recent decades (Lison and Meena, 2014; Oracle, 2020). Shifting from automation robots in the industrial domain, social robots are expected to be used in social domains, such as the service industry, education, healthcare, and entertainment (Bartneck et al., 2020, p.163).

According to Darling (2016)’s definition, a social robot is “a physically embodied, autonomous agent that communicates and interacts with humans on an emotional level”. Many features play important roles in interactions with a social robot, such as people’s experience with technology products, expectations of social robots, interactional environments and other features such as a social robot’s appearance, voice and behaviours. In this last regard, affordance design affects how people perceive a social robot and how such perception affects their behaviours and experiences. The term “affordance” was invented by ecological psychologist Gibson (1977), who proposed that our perception of what it is possible to do with objects is shaped by their form. Affordance indicates what users see and can do with an object in a given situation; it is about perceptual action possibilities in an environment (Matei, 2020).

A strong tendency in social robot affordance design is to make human-robot interaction (HRI) resemble human-human interaction (HHI). It is hoped in many studies that robots designed with anthropomorphic appearances and human-like cognitive behaviours can enable humans to interact with them in similar ways as they would interact with other humans, even to develop social bonds (Leite et al., 2013; Kahn et al., 2015; Koyama et al., 2017; Ligthart et al., 2018). However, there are concerns about this approach. In fact, speech-based artificial agents’ conversational interaction with human users is far from natural, and the language used tends to be formulaic (Moore et al., 2016).

One of the reasons behind this is a significant change in the applications of spoken human-agent interaction (HAI) along the evolution of spoken language technology applications (Moore, 2017a). Compared with “command and control systems” of the 1970s and contemporary smartphone-based “personal assistants”, social robots are expected to be used in more dynamic and open environments. This implies that users’ expectations, demands and ways to interact with spoken agents differ depending on the use case. What has succeeded before in real-time spoken HAI (e.g., voice command for specific uses) may not work well for social robots in some contacts. Additionally, a social robot’s human-like affordances could be seen as “dishonest” because such signals hide the fact that a social robot has limited interactive capabilities and is a “mismatched” conversational partner (Moore, 2015; 2017b). What’s more, the approach to constructing a robot by integrating off-the-shelf human-like technologies lacks an appreciation of the function and behaviour of speech in a broader theoretical framework (Moore, 2015).

This paper takes a step back to consider what human users look for when speaking to a social robot. It starts by looking at the nature and the process of spoken interactions. It then discusses why honesty is the best policy for a social robot in HRI. Furthermore, the arguments presented here support the hypothesis that aligning a social robot’s external affordances coherently with internal capabilities can shape its usability and improve human users’ experience in HRI.</api:text></api:field><api:field name="acceptance-date" type="date" display-name="Date of acceptance"><api:date><api:day>1</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30919" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30919"/></api:links><api:last-name>Huang</api:last-name><api:initials>G</api:initials><api:first-names>Guanyu</api:first-names><api:separate-first-names><api:first-name>Guanyu</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="1173" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1173"/></api:links><api:last-name>Moore</api:last-name><api:initials>RK</api:initials><api:first-names>Roger K</api:first-names><api:separate-first-names><api:first-name>Roger</api:first-name><api:first-name>K</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="c-data-accessibility" type="text" display-name="Data Accessibility"><api:text>DataN</api:text></api:field><api:field name="c-data-availability-statement" type="boolean" display-name="Data Availability Statement"><api:boolean>false</api:boolean></api:field><api:field name="c-goldoa" type="boolean" display-name="Gold Open Access?"><api:boolean>true</api:boolean></api:field><api:field name="c-licence-statement" type="boolean" display-name="Licence statement?"><api:boolean>false</api:boolean></api:field><api:field name="c-ref-no-issn" type="boolean" display-name="REF No ISSN"><api:boolean>false</api:boolean></api:field><api:field name="c-ref-pre-2014" type="boolean" display-name="REF pre-2014"><api:boolean>false</api:boolean></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.3389/frvir.2022.1020169</api:text><api:links><api:link type="doi" href="http://doi.org/10.3389/frvir.2022.1020169"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.3389/frvir.2022.1020169"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2673-4192</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1431234"/></api:links></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2673-4192</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1431234"/></api:links></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>Frontiers in Virtual Reality</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>social robot</api:keyword><api:keyword>affordance design</api:keyword><api:keyword>honest signals</api:keyword><api:keyword>use cases</api:keyword><api:keyword>internal capabilities</api:keyword></api:keywords></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>16</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="open-access-status" type="text" display-name="Open access status"><api:text>Gold OA</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>16</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published online</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Frontiers Media SA</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>10</api:day><api:month>10</api:month><api:year>2022</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Is honesty the best policy for mismatched partners? Aligning multi-modal affordances of a social robot: an opinion paper</api:text></api:field><api:field name="types" type="list" display-name="Sub types"><api:items><api:item>Original research article</api:item></api:items></api:field></api:native></api:record><api:record format="native" id="3893529" source-id="13" source-name="crossref" source-display-name="Crossref" id-at-source="10.3389/frvir.2022.1020169" last-modified-when="2022-10-04T16:43:40.207+01:00"><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30919" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30919"/></api:links><api:last-name>Huang</api:last-name><api:initials>G</api:initials><api:first-names>Guanyu</api:first-names><api:separate-first-names><api:first-name>Guanyu</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="1173" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1173"/></api:links><api:last-name>Moore</api:last-name><api:initials>RK</api:initials><api:first-names>Roger K</api:first-names><api:separate-first-names><api:first-name>Roger</api:first-name><api:first-name>K</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.3389/frvir.2022.1020169</api:text><api:links><api:link type="doi" href="http://doi.org/10.3389/frvir.2022.1020169"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.3389/frvir.2022.1020169"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2673-4192</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1431234"/></api:links></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>Frontiers in Virtual Reality</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>16</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published online</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Frontiers Media SA</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>http://dx.doi.org/10.3389/frvir.2022.1020169</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>16</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Is honesty the best policy for mismatched partners? Aligning multi-modal affordances of a social robot: An opinion paper</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>3</api:text></api:field></api:native></api:record><api:record format="native" id="3916345" source-id="7" source-name="scopus" source-display-name="Scopus" id-at-source="2-s2.0-85139176668" last-modified-when="2024-04-16T13:08:52.463+01:00"><api:citation-count>2</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30919" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30919"/></api:links><api:last-name>Huang</api:last-name><api:initials>G</api:initials><api:first-names>G</api:first-names><api:separate-first-names><api:first-name>G</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">The University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">57913770200</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="1173" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1173"/></api:links><api:last-name>Moore</api:last-name><api:initials>RK</api:initials><api:first-names>RK</api:first-names><api:separate-first-names><api:first-name>R</api:first-name><api:first-name>K</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">The University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">55484218200</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.3389/frvir.2022.1020169</api:text><api:links><api:link type="doi" href="http://doi.org/10.3389/frvir.2022.1020169"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.3389/frvir.2022.1020169"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2673-4192</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1431234"/></api:links></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>Frontiers in Virtual Reality</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>16</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Is honesty the best policy for mismatched partners? Aligning multi-modal affordances of a social robot: An opinion paper</api:text></api:field><api:field name="types" type="list" display-name="Sub types"><api:items><api:item>Note</api:item></api:items></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>3</api:text></api:field></api:native></api:record><api:record format="native" id="3893528" source-id="10" source-name="dimensions" source-display-name="Dimensions" id-at-source="pub.1151062275" last-modified-when="2024-04-30T17:12:59.693+01:00"><api:citation-count>3</api:citation-count><api:native><api:field name="altmetric-attention-score" type="integer" display-name="Altmetric attention score"><api:integer>5</api:integer></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30919" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30919"/></api:links><api:last-name>Huang</api:last-name><api:initials>G</api:initials><api:first-names>Guanyu</api:first-names><api:separate-first-names><api:first-name>Guanyu</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.016667704324.18</api:identifier></api:identifiers><api:author-types><api:author-type>corresponding</api:author-type></api:author-types></api:person><api:person><api:links><api:link type="elements/user" id="1173" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1173"/></api:links><api:last-name>Moore</api:last-name><api:initials>RK</api:initials><api:first-names>Roger K</api:first-names><api:separate-first-names><api:first-name>Roger</api:first-name><api:first-name>K</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.012553154205.25</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.3389/frvir.2022.1020169</api:text><api:links><api:link type="doi" href="http://doi.org/10.3389/frvir.2022.1020169"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.3389/frvir.2022.1020169"/></api:links></api:field><api:field name="field-citation-ratio" type="decimal" display-name="Field citation ratio"><api:decimal>2.48</api:decimal></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2673-4192</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1431234"/></api:links></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>Frontiers in Virtual Reality</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword scheme="for-2020">46 Information and Computing Sciences</api:keyword><api:keyword scheme="for-2020">4608 Human-Centred Computing</api:keyword></api:keywords></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>16</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="open-access-status" type="text" display-name="Open access status"><api:text>Gold OA</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1020169</api:begin-page></api:pagination></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Frontiers</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>17</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Is honesty the best policy for mismatched partners? Aligning multi-modal affordances of a social robot: An opinion paper</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>3</api:text></api:field></api:native></api:record><api:record format="native" id="4332797" source-id="11" source-name="wos-lite" source-display-name="Web of Science (Lite)" id-at-source="WOS:001020142200001" last-modified-when="2024-04-25T02:18:31.023+01:00"><api:citation-count>2</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30919" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30919"/></api:links><api:last-name>Huang</api:last-name><api:initials>G</api:initials><api:first-names>Guanyu</api:first-names><api:separate-first-names><api:first-name>Guanyu</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="1173" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1173"/></api:links><api:last-name>Moore</api:last-name><api:initials>RK</api:initials><api:first-names>Roger K</api:first-names><api:separate-first-names><api:first-name>Roger</api:first-name><api:first-name>K</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="researcherid">B-1985-2016</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>https://www.webofscience.com/api/gateway?GWVersion=2&amp;SrcApp=sheffield_elements_live&amp;SrcAuth=WosAPI&amp;KeyUT=WOS:001020142200001&amp;DestLinkType=FullRecord&amp;DestApp=WOS_CPL</api:text></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.3389/frvir.2022.1020169</api:text><api:links><api:link type="doi" href="http://doi.org/10.3389/frvir.2022.1020169"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.3389/frvir.2022.1020169"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2673-4192</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1431234"/></api:links></api:field><api:field name="external-identifiers" type="identifier-list" display-name="External identifiers"><api:identifiers><api:identifier scheme="isidoc">L0HE2</api:identifier></api:identifiers></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>FRONTIERS IN VIRTUAL REALITY</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>social robot</api:keyword><api:keyword>affordance design</api:keyword><api:keyword>honest signals</api:keyword><api:keyword>use cases</api:keyword><api:keyword>internal capabilities</api:keyword></api:keywords></api:field><api:field name="number" type="text" display-name="Article number"><api:text>ARTN 1020169</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2022</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Is honesty the best policy for mismatched partners? Aligning multi-modal affordances of a social robot: An opinion paper</api:text></api:field><api:field name="types" type="list" display-name="Sub types"><api:items><api:item>Editorial Material</api:item></api:items></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>3</api:text></api:field></api:native></api:record></api:records><api:fields/><api:all-labels type="keyword-list"><api:keywords><api:keyword origin="record-data" source="eprints">social robot</api:keyword><api:keyword origin="record-data" source="eprints">affordance design</api:keyword><api:keyword origin="record-data" source="eprints">honest signals</api:keyword><api:keyword origin="record-data" source="eprints">use cases</api:keyword><api:keyword origin="record-data" source="eprints">internal capabilities</api:keyword><api:keyword origin="record-data" source="manual">social robot</api:keyword><api:keyword origin="record-data" source="manual">affordance design</api:keyword><api:keyword origin="record-data" source="manual">honest signals</api:keyword><api:keyword origin="record-data" source="manual">use cases</api:keyword><api:keyword origin="record-data" source="manual">internal capabilities</api:keyword><api:keyword scheme="for-2020" origin="record-data" source="dimensions">46 Information and Computing Sciences</api:keyword><api:keyword scheme="for-2020" origin="record-data" source="dimensions">4608 Human-Centred Computing</api:keyword><api:keyword origin="record-data" source="wos-lite">social robot</api:keyword><api:keyword origin="record-data" source="wos-lite">affordance design</api:keyword><api:keyword origin="record-data" source="wos-lite">honest signals</api:keyword><api:keyword origin="record-data" source="wos-lite">use cases</api:keyword><api:keyword origin="record-data" source="wos-lite">internal capabilities</api:keyword><api:keyword scheme="for-2020" origin="issn-inferred">4607 Graphics, augmented reality and games</api:keyword></api:keywords></api:all-labels><api:journal issn="2673-4192" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1431234" title="Frontiers in Virtual Reality"><api:records><api:record source-name="summary"><api:title>Frontiers in Virtual Reality</api:title></api:record></api:records></api:journal><api:relationships href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1435337/relationships"/></api:object></api:result></api:response>