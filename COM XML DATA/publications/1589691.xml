<?xml version="1.0" encoding="utf-8"?><api:response xmlns:api="http://www.symplectic.co.uk/publications/api"><api:version uri="https://mypublications.shef.ac.uk/" elements-version="6.17.0.4095" schema-version="6.13" product-name="myPublications"/><api:request href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1589691"/><api:result><api:object category="publication" id="1589691" last-affected-when="2024-04-25T03:31:18.713+01:00" last-modified-when="2024-04-25T03:31:18.713+01:00" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1589691" created-when="2024-01-31T10:37:37.313+00:00" type-id="4" type-display-name="Conference proceedings paper" type="conference"><api:privacy-level>Public</api:privacy-level><api:privacy-level-locked>false</api:privacy-level-locked><api:ever-approved>true</api:ever-approved><api:reporting-date-1>2019-01-01</api:reporting-date-1><api:allow-type-switching>true</api:allow-type-switching><api:records><api:record format="native" id="4540545" source-id="28" source-name="eprints" source-display-name="White Rose Research Online" id-at-source="209129" last-modified-when="2024-02-16T13:28:07.613+00:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Actor-critic methods, a type of model-free Reinforcement Learning, have been successfully applied to challenging tasks in continuous control, often achieving state-of-the art performance. However, wide-scale adoption of these methods in real-world domains is made difficult by their poor sample efficiency. We address this problem both theoretically and empirically. On the theoretical side, we identify two phenomena preventing efficient exploration in existing state-of-the-art algorithms such as Soft Actor Critic. First, combining a greedy actor update with a pessimistic estimate of the critic leads to the avoidance of actions that the agent does not know about, a phenomenon we call pessimistic underexploration. Second, current algorithms are directionally uninformed, sampling actions with equal probability in opposite directions from the current mean. This is wasteful, since we typically need actions taken along certain directions much more than others. To address both of these phenomena, we introduce a new algorithm, Optimistic Actor Critic, which approximates a lower and upper confidence bound on the state-action value function. This allows us to apply the principle of optimism in the face of uncertainty to perform directed exploration using the upper bound while still using the lower bound to avoid overestimation. We evaluate OAC in several challenging continuous control tasks, achieving state-of the art sample efficiency.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Ciosek</api:last-name><api:initials>K</api:initials><api:first-names>K</api:first-names><api:separate-first-names><api:first-name>K</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Vuong</api:last-name><api:initials>Q</api:initials><api:first-names>Q</api:first-names><api:separate-first-names><api:first-name>Q</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="37828" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/37828"/></api:links><api:last-name>Loftin</api:last-name><api:initials>R</api:initials><api:first-names>R</api:first-names><api:separate-first-names><api:first-name>R</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Hofmann</api:last-name><api:initials>K</api:initials><api:first-names>K</api:first-names><api:separate-first-names><api:first-name>K</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>https://www.webofscience.com/api/gateway?GWVersion=2&amp;SrcApp=sheffield_elements_live&amp;SrcAuth=WosAPI&amp;KeyUT=WOS:000534424301074&amp;DestLinkType=FullRecord&amp;DestApp=WOS</api:text></api:field><api:field name="c-data-accessibility" type="text" display-name="Data Accessibility"><api:text>DataN</api:text></api:field><api:field name="c-data-availability-statement" type="boolean" display-name="Data Availability Statement"><api:boolean>false</api:boolean></api:field><api:field name="c-goldoa" type="boolean" display-name="Gold Open Access?"><api:boolean>false</api:boolean></api:field><api:field name="c-licence-statement" type="boolean" display-name="Licence statement?"><api:boolean>false</api:boolean></api:field><api:field name="c-ref-no-issn" type="boolean" display-name="REF No ISSN"><api:boolean>false</api:boolean></api:field><api:field name="c-rights-retention-opt-out" type="boolean" display-name="Rights retention opt out"><api:boolean>false</api:boolean></api:field><api:field name="editors" type="person-list" display-name="Editors"><api:people><api:person><api:last-name>Wallach</api:last-name><api:initials>H</api:initials><api:first-names>H</api:first-names><api:separate-first-names><api:first-name>H</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Larochelle</api:last-name><api:initials>H</api:initials><api:first-names>H</api:first-names><api:separate-first-names><api:first-name>H</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Beygelzimer</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>d'Alché-Buc</api:last-name><api:initials>F</api:initials><api:first-names>F</api:first-names><api:separate-first-names><api:first-name>F</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Garnett</api:last-name><api:initials>R</api:initials><api:first-names>R</api:first-names><api:separate-first-names><api:first-name>R</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>8</api:day><api:month>12</api:month><api:year>2019</api:year></api:date></api:field><api:field name="isbn-13" type="text" display-name="ISBN-13"><api:text>9781713807933</api:text></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1049-5258</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/980491"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Advances in Neural Information Processing Systems 32 (NeurIPS 2019)</api:text></api:field><api:field name="location" type="text" display-name="Conference place"><api:text>Vancouver, Canada</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>33rd Conference on Neural Information Processing Systems (NeurIPS 2019)</api:text></api:field><api:field name="notes" type="text" display-name="Other information"><api:text>© 2019 The Author(s).</api:text></api:field><api:field name="oa-location-file-version" type="text" display-name="OA location file version"><api:text>Published version</api:text></api:field><api:field name="oa-location-url" type="text" display-name="OA location URL"><api:text>https://papers.nips.cc/paper_files/paper/2019/file/a34bacf839b923770b2c360eefa26748-Paper.pdf</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:month>6</api:month><api:year>2020</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="public-url" type="text" display-name="Public URL"><api:text>https://eprints.whiterose.ac.uk/id/eprint/209129</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Neural Information Processing Systems Foundation, Inc. (NeurIPS)</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>https://papers.nips.cc/paper_files/paper/2019/hash/a34bacf839b923770b2c360eefa26748-Abstract.html</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>13</api:day><api:month>2</api:month><api:year>2024</api:year></api:date></api:field><api:field name="record-made-public-at-source-date" type="date" display-name="Record made publicly available"><api:date><api:day>16</api:day><api:month>2</api:month><api:year>2024</api:year></api:date></api:field><api:field name="repository-status" type="text" display-name="Availability"><api:text>Public</api:text></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>8</api:day><api:month>12</api:month><api:year>2019</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Better exploration with optimistic actor-critic</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>32</api:text></api:field></api:native></api:record><api:record format="native" id="4531633" source-id="7" source-name="scopus" source-display-name="Scopus" id-at-source="2-s2.0-85090169825" last-modified-when="2024-04-24T19:04:26.763+01:00"><api:citation-count>62</api:citation-count><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Actor-critic methods, a type of model-free Reinforcement Learning, have been successfully applied to challenging tasks in continuous control, often achieving state-of-the art performance. However, wide-scale adoption of these methods in real-world domains is made difficult by their poor sample efficiency. We address this problem both theoretically and empirically. On the theoretical side, we identify two phenomena preventing efficient exploration in existing state-of-the-art algorithms such as Soft Actor Critic. First, combining a greedy actor update with a pessimistic estimate of the critic leads to the avoidance of actions that the agent does not know about, a phenomenon we call pessimistic underexploration. Second, current algorithms are directionally uninformed, sampling actions with equal probability in opposite directions from the current mean. This is wasteful, since we typically need actions taken along certain directions much more than others. To address both of these phenomena, we introduce a new algorithm, Optimistic Actor Critic, which approximates a lower and upper confidence bound on the state-action value function. This allows us to apply the principle of optimism in the face of uncertainty to perform directed exploration using the upper bound while still using the lower bound to avoid overestimation. We evaluate OAC in several challenging continuous control tasks, achieving state-of the art sample efficiency.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Ciosek</api:last-name><api:initials>K</api:initials><api:first-names>K</api:first-names><api:separate-first-names><api:first-name>K</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">Microsoft Research Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">27567565500</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="37828" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/37828"/></api:links><api:last-name>Loftin</api:last-name><api:initials>R</api:initials><api:first-names>R</api:first-names><api:separate-first-names><api:first-name>R</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">Microsoft Research Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">58514845500</api:identifier></api:identifiers></api:person><api:person><api:last-name>Vuong</api:last-name><api:initials>Q</api:initials><api:first-names>Q</api:first-names><api:separate-first-names><api:first-name>Q</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="US"><api:line type="organisation">University of California, San Diego</api:line><api:line type="city">La Jolla</api:line><api:line type="country">United States</api:line></api:address><api:address iso-country-code="GB"><api:line type="organisation">Microsoft Research Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">57210647081</api:identifier></api:identifiers></api:person><api:person><api:last-name>Hofmann</api:last-name><api:initials>K</api:initials><api:first-names>K</api:first-names><api:separate-first-names><api:first-name>K</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">Microsoft Research Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">23011906300</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1049-5258</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/980491"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Advances in Neural Information Processing Systems</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>1</api:month><api:year>2019</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Better exploration with optimistic actor-critic</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>32</api:text></api:field></api:native></api:record><api:record format="native" id="4531644" source-id="11" source-name="wos-lite" source-display-name="Web of Science (Lite)" id-at-source="WOS:000534424301074" last-modified-when="2024-04-25T03:31:18.72+01:00"><api:citation-count>18</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Ciosek</api:last-name><api:initials>K</api:initials><api:first-names>Kamil</api:first-names><api:separate-first-names><api:first-name>Kamil</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Quan</api:last-name><api:initials>V</api:initials><api:first-names>Vuong</api:first-names><api:separate-first-names><api:first-name>Vuong</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="37828" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/37828"/></api:links><api:last-name>Loftin</api:last-name><api:initials>R</api:initials><api:first-names>Robert</api:first-names><api:separate-first-names><api:first-name>Robert</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Hofmann</api:last-name><api:initials>K</api:initials><api:first-names>Katja</api:first-names><api:separate-first-names><api:first-name>Katja</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>https://www.webofscience.com/api/gateway?GWVersion=2&amp;SrcApp=sheffield_elements_live&amp;SrcAuth=WosAPI&amp;KeyUT=WOS:000534424301074&amp;DestLinkType=FullRecord&amp;DestApp=WOS_CPL</api:text></api:field><api:field name="external-identifiers" type="identifier-list" display-name="External identifiers"><api:identifiers><api:identifier scheme="isidoc">BP0ID</api:identifier></api:identifiers></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1049-5258</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/980491"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 32 (NIPS 2019)</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2019</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Better Exploration with Optimistic Actor-Critic</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>32</api:text></api:field></api:native></api:record></api:records><api:fields/><api:all-labels type="keyword-list"><api:keywords><api:keyword scheme="for" origin="issn-inferred">1701 Psychology</api:keyword><api:keyword scheme="for" origin="issn-inferred">1702 Cognitive Sciences</api:keyword><api:keyword scheme="for-2020" origin="issn-inferred">4611 Machine learning</api:keyword></api:keywords></api:all-labels><api:journal issn="1049-5258" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/980491" title="Advances in Neural Information Processing Systems"><api:records><api:record source-name="summary"><api:title>Advances in Neural Information Processing Systems</api:title></api:record></api:records></api:journal><api:relationships href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1589691/relationships"/><api:last-flagged-as-grant-not-listed>2024-02-13T09:41:30.383+00:00</api:last-flagged-as-grant-not-listed></api:object></api:result></api:response>