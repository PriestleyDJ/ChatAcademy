<?xml version="1.0" encoding="utf-8"?><api:response xmlns:api="http://www.symplectic.co.uk/publications/api"><api:version uri="https://mypublications.shef.ac.uk/" elements-version="6.17.0.4095" schema-version="6.13" product-name="myPublications"/><api:request href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1533467"/><api:result><api:object category="publication" id="1533467" last-affected-when="2024-04-26T19:32:37.687+01:00" last-modified-when="2024-04-26T19:32:37.687+01:00" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1533467" created-when="2023-03-30T13:35:49.527+01:00" type-id="4" type-display-name="Conference proceedings paper" type="conference"><api:privacy-level>Public</api:privacy-level><api:privacy-level-locked>false</api:privacy-level-locked><api:ever-approved>true</api:ever-approved><api:reporting-date-1>2023-05-13</api:reporting-date-1><api:allow-type-switching>true</api:allow-type-switching><api:records><api:record format="native" id="4282367" source-id="28" source-name="eprints" source-display-name="White Rose Research Online" id-at-source="197880" last-modified-when="2023-05-25T12:11:42.3+01:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Recent speech enhancement work, which makes use of neural networks trained with a loss derived in part using an adversarial metric prediction network, has shown to be very effective. However, by limiting the data used to train this metric prediction network to only the clean reference and the output of the speech enhancement network, only a limited range of the metric is learnt. Additionally, such speech enhancement systems are limited because they typically operate solely over magnitude spectrogram representations so they do not encode phase information.  
In this work, recent developments for phase-aware speech enhancement in such an adversarial framework are expanded in two ways to enable the metric prediction network to learn a full range of metric scores. Firstly, the metric predictor is also exposed to unenhanced 'noisy' data during training. Furthermore, an additional network is introduced and trained alongside which attempts to produce outputs with a fixed 'lower' target metric score, and expose the metric predictor to these 'de-enhanced' outputs. It is found that performance increases versus a baseline system utilising a magnitude spectrogram speech enhancement network.</api:text></api:field><api:field name="acceptance-date" type="date" display-name="Date of acceptance"><api:date><api:day>3</api:day><api:month>3</api:month><api:year>2023</api:year></api:date></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30896" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30896"/></api:links><api:last-name>Close</api:last-name><api:initials>G</api:initials><api:first-names>G</api:first-names><api:separate-first-names><api:first-name>G</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="493" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/493"/></api:links><api:last-name>Hain</api:last-name><api:initials>T</api:initials><api:first-names>T</api:first-names><api:separate-first-names><api:first-name>T</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="30214" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30214"/></api:links><api:last-name>Goetze</api:last-name><api:initials>S</api:initials><api:first-names>S</api:first-names><api:separate-first-names><api:first-name>S</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="c-data-accessibility" type="text" display-name="Data Accessibility"><api:text>DataN</api:text></api:field><api:field name="c-data-availability-statement" type="boolean" display-name="Data Availability Statement"><api:boolean>false</api:boolean></api:field><api:field name="c-goldoa" type="boolean" display-name="Gold Open Access?"><api:boolean>false</api:boolean></api:field><api:field name="c-licence-statement" type="boolean" display-name="Licence statement?"><api:boolean>false</api:boolean></api:field><api:field name="c-ref-no-issn" type="boolean" display-name="REF No ISSN"><api:boolean>false</api:boolean></api:field><api:field name="c-rights-retention-opt-out" type="boolean" display-name="Rights retention opt out"><api:boolean>false</api:boolean></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>13</api:day><api:month>5</api:month><api:year>2023</api:year></api:date></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>AES Convention Europe 2023: 154th Audio Engineering Society Conference</api:text></api:field><api:field name="location" type="text" display-name="Conference place"><api:text>Espoo, Helsinki, FInland</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>AES Europe 2023: 154th Engineering Society Convention</api:text></api:field><api:field name="notes" type="text" display-name="Other information"><api:text>© 2023 Audio Engineering Society.</api:text></api:field><api:field name="oa-location-file-version" type="text" display-name="OA location file version"><api:text>Published version</api:text></api:field><api:field name="oa-location-url" type="text" display-name="OA location URL"><api:text>https://www.aes.org/e-lib/browse.cfm?elib=22063</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>13</api:day><api:month>5</api:month><api:year>2023</api:year></api:date></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>10656</api:begin-page><api:page-count>9</api:page-count></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:month>5</api:month><api:year>2023</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="public-url" type="text" display-name="Public URL"><api:text>https://eprints.whiterose.ac.uk/id/eprint/197880</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Audio Engineering Society</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>https://www.aes.org/e-lib/browse.cfm?elib=22063</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>30</api:day><api:month>3</api:month><api:year>2023</api:year></api:date></api:field><api:field name="record-made-public-at-source-date" type="date" display-name="Record made publicly available"><api:date><api:day>21</api:day><api:month>4</api:month><api:year>2023</api:year></api:date></api:field><api:field name="repository-status" type="text" display-name="Availability"><api:text>Public</api:text></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>13</api:day><api:month>5</api:month><api:year>2023</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>PAMGAN+/-: Improving phase-aware speech enhancement
performance via expanded discriminator training</api:text></api:field></api:native></api:record><api:record format="native" id="4372740" source-id="7" source-name="scopus" source-display-name="Scopus" id-at-source="2-s2.0-85167953248" last-modified-when="2023-11-16T00:51:11.897+00:00"><api:citation-count>1</api:citation-count><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Recent speech enhancement work, which makes use of neural networks trained with a loss derived in part using an adversarial metric prediction network, has shown to be very effective. However, by limiting the data used to train this metric prediction network to only the clean reference and the output of the speech enhancement network, only a limited range of the metric is learnt. Additionally, such speech enhancement systems are limited because they typically operate solely over magnitude spectrogram representations so they do not encode phase information. In this work, recent developments for phase-aware speech enhancement in such an adversarial framework are expanded in two ways to enable the metric prediction network to learn a full range of metric scores. Firstly, the metric predictor is also exposed to unenhanced’noisy’ data during training. Furthermore, an additional network is introduced and trained alongside which attempts to produce outputs with a fixed’lower’ target metric score, and expose the metric predictor to these’de-enhanced’ outputs. It is found that performance increases versus a baseline system utilising a magnitude spectrogram speech enhancement network.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30896" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30896"/></api:links><api:last-name>Close</api:last-name><api:initials>G</api:initials><api:first-names>G</api:first-names><api:separate-first-names><api:first-name>G</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">The University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">57222232709</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="493" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/493"/></api:links><api:last-name>Hain</api:last-name><api:initials>T</api:initials><api:first-names>T</api:first-names><api:separate-first-names><api:first-name>T</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">The University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">14017969900</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="30214" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30214"/></api:links><api:last-name>Goetze</api:last-name><api:initials>S</api:initials><api:first-names>S</api:first-names><api:separate-first-names><api:first-name>S</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">The University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">21833521500</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="isbn-13" type="text" display-name="ISBN-13"><api:text>9781713877783</api:text></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>AES Europe 2023: 154th Audio Engineering Society Convention</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>1</api:month><api:year>2023</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>PAMGAN+/-: Improving Phase-Aware Speech Enhancement Performance via Expanded Discriminator Training</api:text></api:field></api:native></api:record><api:record format="native" id="4282366" source-id="1" source-name="manual" source-display-name="Manual" id-at-source="04B46A06-DBCF-4A5B-8E31-4C1A8F26D17B" last-modified-when="2023-03-30T13:35:49.527+01:00"><api:verification-status>unverified</api:verification-status><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Recent speech enhancement work, which makes use of neural networks trained with a loss derived in part using an adversarial metric prediction network, has shown to be very effective. However, by limiting the data used to train this metric prediction network to only the clean reference and the output of the speech enhancement network, only a limited range of the metric is learnt. Additionally, such speech enhancement systems are limited because they typically operate solely over magnitude spectrogram representations so they do not encode phase information.  
In this work, recent developments for phase-aware speech enhancement in such an adversarial framework are expanded in two ways to enable the metric prediction network to learn a full range of metric scores. Firstly, the metric predictor is also exposed to unenhanced 'noisy' data during training. Furthermore, an additional network is introduced and trained alongside which attempts to produce outputs with a fixed 'lower' target metric score, and expose the metric predictor to these 'de-enhanced' outputs. It is found that performance increases versus a baseline system utilising a magnitude spectrogram speech enhancement network.</api:text></api:field><api:field name="acceptance-date" type="date" display-name="Date of acceptance"><api:date><api:day>3</api:day><api:month>3</api:month><api:year>2023</api:year></api:date></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30896" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30896"/></api:links><api:last-name>Close</api:last-name><api:initials>G</api:initials><api:first-names>George</api:first-names><api:separate-first-names><api:first-name>George</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="493" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/493"/></api:links><api:last-name>Hain</api:last-name><api:initials>T</api:initials><api:first-names>Thomas</api:first-names><api:separate-first-names><api:first-name>Thomas</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="30214" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30214"/></api:links><api:last-name>Goetze</api:last-name><api:initials>S</api:initials><api:first-names>Stefan</api:first-names><api:separate-first-names><api:first-name>Stefan</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="c-data-availability-statement" type="boolean" display-name="Data Availability Statement"><api:boolean>false</api:boolean></api:field><api:field name="c-licence-statement" type="boolean" display-name="Licence statement?"><api:boolean>false</api:boolean></api:field><api:field name="c-ref-no-issn" type="boolean" display-name="REF No ISSN"><api:boolean>false</api:boolean></api:field><api:field name="c-ref-pre-2014" type="boolean" display-name="REF pre-2014"><api:boolean>false</api:boolean></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>AES Convention Europe 2023</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>AES Convention Europe 2023</api:text></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Accepted</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>30</api:day><api:month>3</api:month><api:year>2023</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>PAMGAN+/-: Improving Phase-Aware Speech Enhancement
Performance via Expanded Discriminator Training</api:text></api:field></api:native></api:record></api:records><api:fields/><api:relationships href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1533467/relationships"/></api:object></api:result></api:response>