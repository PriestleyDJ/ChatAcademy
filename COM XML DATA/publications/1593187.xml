<?xml version="1.0" encoding="utf-8"?><api:response xmlns:api="http://www.symplectic.co.uk/publications/api"><api:version uri="https://mypublications.shef.ac.uk/" elements-version="6.17.0.4095" schema-version="6.13" product-name="myPublications"/><api:request href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1593187"/><api:result><api:object category="publication" id="1593187" last-affected-when="2024-02-14T16:18:01.46+00:00" last-modified-when="2024-02-14T16:18:01.46+00:00" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1593187" created-when="2024-02-13T09:57:23.613+00:00" type-id="4" type-display-name="Conference proceedings paper" type="conference"><api:privacy-level>Public</api:privacy-level><api:privacy-level-locked>false</api:privacy-level-locked><api:ever-approved>true</api:ever-approved><api:reporting-date-1>2023-12-21</api:reporting-date-1><api:allow-type-switching>true</api:allow-type-switching><api:records><api:record format="native" id="4540548" source-id="28" source-name="eprints" source-display-name="White Rose Research Online" id-at-source="209131" last-modified-when="2024-02-14T16:18:01.48+00:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>In multi-agent problems requiring a high degree of cooperation, success often depends on the ability of the agents to adapt to each other’s behavior. A natural solution concept in such settings is the Stackelberg equilibrium, in which the “leader” agent selects the strategy that maximizes its own payoff given that the “follower” agent will choose their best response to this strategy. Recent work has extended this solution concept to two-player differentiable games, such as those arising from multi-agent deep reinforcement learning, in the form of the differential Stackelberg equilibrium.  While this previous work has presented learning dynamics which
converge to such equilibria, these dynamics are “coupled” in the sense that the learning updates for the leader’s strategy require some information about the follower’s payoff function. As such, these methods cannot be applied to truly decentralised multi-agent settings, particularly ad hoc cooperation, where each agent only has access to its own payoff function. In this work we present “uncoupled” learning dynamics based on zeroth-order gradient estimators, in which each agent’s strategy update depends only on their observations of the other’s behavior. We analyze the convergence of these dynamics in general-sum games, and prove that they converge to differential Stackelberg equilibria under the same conditions as previous coupled methods. Furthermore, we present an online mechanism by which symmetric learners can negotiate leader-follower roles. We conclude with a discussion of the implications of our work for multi-agent reinforcement learning and ad hoc collaboration more generally.</api:text></api:field><api:field name="acceptance-date" type="date" display-name="Date of acceptance"><api:date><api:day>21</api:day><api:month>12</api:month><api:year>2023</api:year></api:date></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="37828" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/37828"/></api:links><api:last-name>Loftin</api:last-name><api:initials>R</api:initials><api:first-names>R</api:first-names><api:separate-first-names><api:first-name>R</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Çelikok</api:last-name><api:initials>MM</api:initials><api:first-names>MM</api:first-names><api:separate-first-names><api:first-name>M</api:first-name><api:first-name>M</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>van Hoof</api:last-name><api:initials>H</api:initials><api:first-names>H</api:first-names><api:separate-first-names><api:first-name>H</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Kaski</api:last-name><api:initials>S</api:initials><api:first-names>S</api:first-names><api:separate-first-names><api:first-name>S</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Oliehoek</api:last-name><api:initials>FA</api:initials><api:first-names>FA</api:first-names><api:separate-first-names><api:first-name>F</api:first-name><api:first-name>A</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="c-data-accessibility" type="text" display-name="Data Accessibility"><api:text>DataN</api:text></api:field><api:field name="c-data-availability-statement" type="boolean" display-name="Data Availability Statement"><api:boolean>false</api:boolean></api:field><api:field name="c-goldoa" type="boolean" display-name="Gold Open Access?"><api:boolean>true</api:boolean></api:field><api:field name="c-licence-statement" type="boolean" display-name="Licence statement?"><api:boolean>false</api:boolean></api:field><api:field name="c-ref-no-issn" type="boolean" display-name="REF No ISSN"><api:boolean>false</api:boolean></api:field><api:field name="c-rights-retention-opt-out" type="boolean" display-name="Rights retention opt out"><api:boolean>false</api:boolean></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>6</api:day><api:month>5</api:month><api:year>2024</api:year></api:date></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2024)</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>multi-agent reinforcement learning</api:keyword><api:keyword>ad hoc collaboration</api:keyword><api:keyword>ad hoc teamwork</api:keyword><api:keyword>learning dynamics</api:keyword><api:keyword>differentiable games</api:keyword><api:keyword>differential stackelberg equilibrium</api:keyword></api:keywords></api:field><api:field name="location" type="text" display-name="Conference place"><api:text>Auckland, New Zealand</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>The 23rd International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2024)</api:text></api:field><api:field name="notes" type="text" display-name="Other information"><api:text>© 2024 International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)</api:text></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Accepted</api:text></api:field><api:field name="public-url" type="text" display-name="Public URL"><api:text>https://eprints.whiterose.ac.uk/id/eprint/209131</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)</api:text></api:field><api:field name="publisher-licence" type="text" display-name="Publisher licence"><api:text>CC BY</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>13</api:day><api:month>2</api:month><api:year>2024</api:year></api:date></api:field><api:field name="record-made-public-at-source-date" type="date" display-name="Record made publicly available"><api:date><api:day>14</api:day><api:month>2</api:month><api:year>2024</api:year></api:date></api:field><api:field name="repository-status" type="text" display-name="Availability"><api:text>Public</api:text></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>6</api:day><api:month>5</api:month><api:year>2024</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Uncoupled learning of differential Stackelberg equilibria with commitments</api:text></api:field></api:native></api:record><api:record format="native" id="4540547" source-id="1" source-name="manual" source-display-name="Manual" id-at-source="C30BE17D-3E7A-4B25-B867-C297F8FD78A0" last-modified-when="2024-02-13T09:57:23.617+00:00"><api:verification-status>unverified</api:verification-status><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>In multi-agent problems requiring a high degree of cooperation, success often depends on the ability of the agents to adapt to each other’s behavior. A natural solution concept in such settings is the Stackelberg equilibrium, in which the “leader” agent selects the strategy that maximizes its own payoff given that the “follower” agent will choose their best response to this strategy. Recent work has extended this solution concept to two-player differentiable games, such as those arising from multi-agent deep reinforcement learning, in the form of the differential Stackelberg equilibrium.  While this previous work has presented learning dynamics which
converge to such equilibria, these dynamics are “coupled” in the sense that the learning updates for the leader’s strategy require some information about the follower’s payoff function. As such, these methods cannot be applied to truly decentralised multi-agent settings, particularly ad hoc cooperation, where each agent only has access to its own payoff function. In this work we present “uncoupled” learning dynamics based on zeroth-order gradient estimators, in which each agent’s strategy update depends only on their observations of the other’s behavior. We analyze the convergence of these dynamics in general-sum games, and prove that they converge to differential Stackelberg equilibria under the same conditions as previous coupled methods. Furthermore, we present an online mechanism by which symmetric learners can negotiate leader-follower roles. We conclude with a discussion of the implications of our work for multi-agent reinforcement learning and ad hoc collaboration more generally.</api:text></api:field><api:field name="acceptance-date" type="date" display-name="Date of acceptance"><api:date><api:day>21</api:day><api:month>12</api:month><api:year>2023</api:year></api:date></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="37828" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/37828"/></api:links><api:last-name>Loftin</api:last-name><api:initials>R</api:initials><api:first-names>Robert</api:first-names><api:separate-first-names><api:first-name>Robert</api:first-name></api:separate-first-names><api:author-types><api:author-type>corresponding</api:author-type><api:author-type>first</api:author-type></api:author-types><api:roles><api:role type="contributor">Conceptualization</api:role><api:role type="contributor">Formal Analysis</api:role><api:role type="contributor">Software</api:role><api:role type="contributor">Visualization</api:role><api:role type="contributor">Writing – Original Draft</api:role><api:role type="contributor">Writing – Review &amp; Editing</api:role></api:roles></api:person><api:person><api:last-name>Çelikok</api:last-name><api:initials>MM</api:initials><api:first-names>Mustafa Mert</api:first-names><api:separate-first-names><api:first-name>Mustafa</api:first-name><api:first-name>Mert</api:first-name></api:separate-first-names><api:author-types><api:author-type>corresponding</api:author-type><api:author-type>first</api:author-type></api:author-types><api:roles><api:role type="contributor">Conceptualization</api:role><api:role type="contributor">Formal Analysis</api:role><api:role type="contributor">Writing – Original Draft</api:role></api:roles></api:person><api:person><api:last-name>van Hoof</api:last-name><api:initials>H</api:initials><api:first-names>Herke</api:first-names><api:separate-first-names><api:first-name>Herke</api:first-name></api:separate-first-names><api:roles><api:role type="contributor">Conceptualization</api:role></api:roles></api:person><api:person><api:last-name>Kaski</api:last-name><api:initials>S</api:initials><api:first-names>Samuel</api:first-names><api:separate-first-names><api:first-name>Samuel</api:first-name></api:separate-first-names><api:roles><api:role type="contributor">Conceptualization</api:role></api:roles></api:person><api:person><api:last-name>Oliehoek</api:last-name><api:initials>FA</api:initials><api:first-names>Frans A</api:first-names><api:separate-first-names><api:first-name>Frans</api:first-name><api:first-name>A</api:first-name></api:separate-first-names><api:author-types><api:author-type>last</api:author-type></api:author-types><api:roles><api:role type="contributor">Conceptualization</api:role><api:role type="contributor">Writing – Review &amp; Editing</api:role></api:roles></api:person></api:people></api:field><api:field name="c-data-availability-statement" type="boolean" display-name="Data Availability Statement"><api:boolean>false</api:boolean></api:field><api:field name="c-goldoa" type="boolean" display-name="Gold Open Access?"><api:boolean>false</api:boolean></api:field><api:field name="c-licence-statement" type="boolean" display-name="Licence statement?"><api:boolean>false</api:boolean></api:field><api:field name="c-ref-no-issn" type="boolean" display-name="REF No ISSN"><api:boolean>false</api:boolean></api:field><api:field name="c-ref-pre-2014" type="boolean" display-name="REF pre-2014"><api:boolean>false</api:boolean></api:field><api:field name="c-rights-retention-opt-out" type="boolean" display-name="Rights retention opt out"><api:boolean>false</api:boolean></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>10</api:day><api:month>5</api:month><api:year>2024</api:year></api:date></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2024)</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>multi-agent reinforcement learning</api:keyword><api:keyword>ad hoc collaboration</api:keyword><api:keyword>ad hoc teamwork</api:keyword><api:keyword>learning dynamics</api:keyword><api:keyword>differentiable games</api:keyword><api:keyword>differential stackelberg equilibrium</api:keyword></api:keywords></api:field><api:field name="location" type="text" display-name="Conference place"><api:text>Auckland, New Zealand</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>Autonomous Agents and Multiagent Systems</api:text></api:field><api:field name="notes" type="text" display-name="Other information"><api:text>Oral presentation</api:text></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Accepted</api:text></api:field><api:field name="publisher-licence" type="text" display-name="Publisher licence"><api:text>CC BY</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>13</api:day><api:month>2</api:month><api:year>2024</api:year></api:date></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>6</api:day><api:month>5</api:month><api:year>2024</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Uncoupled Learning of Differential Stackelberg Equilibria with Commitments</api:text></api:field></api:native></api:record></api:records><api:fields/><api:all-labels type="keyword-list"><api:keywords><api:keyword origin="record-data" source="eprints">multi-agent reinforcement learning</api:keyword><api:keyword origin="record-data" source="eprints">ad hoc collaboration</api:keyword><api:keyword origin="record-data" source="eprints">ad hoc teamwork</api:keyword><api:keyword origin="record-data" source="eprints">learning dynamics</api:keyword><api:keyword origin="record-data" source="eprints">differentiable games</api:keyword><api:keyword origin="record-data" source="eprints">differential stackelberg equilibrium</api:keyword><api:keyword origin="record-data" source="manual">multi-agent reinforcement learning</api:keyword><api:keyword origin="record-data" source="manual">ad hoc collaboration</api:keyword><api:keyword origin="record-data" source="manual">ad hoc teamwork</api:keyword><api:keyword origin="record-data" source="manual">learning dynamics</api:keyword><api:keyword origin="record-data" source="manual">differentiable games</api:keyword><api:keyword origin="record-data" source="manual">differential stackelberg equilibrium</api:keyword></api:keywords></api:all-labels><api:relationships href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1593187/relationships"/><api:last-flagged-as-grant-not-listed>2024-02-13T09:57:35.043+00:00</api:last-flagged-as-grant-not-listed></api:object></api:result></api:response>