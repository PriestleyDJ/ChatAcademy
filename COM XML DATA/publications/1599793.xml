<?xml version="1.0" encoding="utf-8"?><api:response xmlns:api="http://www.symplectic.co.uk/publications/api"><api:version uri="https://mypublications.shef.ac.uk/" elements-version="6.17.0.4095" schema-version="6.13" product-name="myPublications"/><api:request href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1599793"/><api:result><api:object category="publication" id="1599793" last-affected-when="2024-05-06T15:10:04.49+01:00" last-modified-when="2024-05-06T15:10:04.49+01:00" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1599793" created-when="2024-03-23T14:32:12.697+00:00" type-id="5" type-display-name="Journal article" type="journal-article"><api:privacy-level>Public</api:privacy-level><api:privacy-level-locked>false</api:privacy-level-locked><api:ever-approved>true</api:ever-approved><api:reporting-date-1>2024-03-18</api:reporting-date-1><api:allow-type-switching>true</api:allow-type-switching><api:records><api:record format="native" id="4563006" source-id="28" source-name="eprints" source-display-name="White Rose Research Online" id-at-source="211254" last-modified-when="2024-04-08T12:21:27.893+01:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Along with the development of speech and language technologies, the market for speech-enabled human-robot interactions (HRI) has grown in recent years. However, it is found that people feel their conversational interactions with such robots are far from satisfactory. One of the reasons is the habitability gap, where the usability of a speech-enabled agent drops when its flexibility increases. For social robots, such flexibility is reflected in the diverse choice of robots’ appearances, sounds and behaviours, which shape a robot’s ‘affordance’. Whilst designers or users have enjoyed the freedom of constructing a social robot by integrating off-the-shelf technologies, such freedom comes at a potential cost: the users’ perceptions and satisfaction. Designing appropriate affordances is essential for the quality of HRI. It is hypothesised that a social robot with aligned affordances could create an appropriate perception of the robot and increase users’ satisfaction when speaking with it. Given that previous studies of affordance alignment mainly focus on one interface’s characteristics and face-voice match, we aim to deepen our understanding of affordance alignment with a robot’s behaviours and use cases. In particular, we investigate how a robot’s affordances affect users’ perceptions in different types of use cases. For this purpose, we conducted an exploratory experiment that included three different affordance settings (adult-like, child-like, and robot-like) and three use cases (informative, emotional, and hybrid). Participants were invited to talk to social robots in person. A mixed-methods approach was employed for quantitative and qualitative analysis of 156 interaction samples. The results show that static affordance (face and voice) has a statistically significant effect on the perceived warmth of the first impression; use cases affect people’s perceptions more on perceived competence and warmth before and after interactions. In addition, it shows the importance of aligning static affordance with behavioural affordance. General design principles of behavioural affordances are proposed. We anticipate that our empirical evidence will provide a clearer guideline for speech-enabled social robots’ affordance design. It will be a starting point for more sophisticated design guidelines. For example, personalised affordance design for individual or group users in different contexts.</api:text></api:field><api:field name="acceptance-date" type="date" display-name="Date of acceptance"><api:date><api:day>26</api:day><api:month>2</api:month><api:year>2024</api:year></api:date></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30919" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30919"/></api:links><api:last-name>Huang</api:last-name><api:initials>G</api:initials><api:first-names>G</api:first-names><api:separate-first-names><api:first-name>G</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="1173" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1173"/></api:links><api:last-name>Moore</api:last-name><api:initials>RK</api:initials><api:first-names>RK</api:first-names><api:separate-first-names><api:first-name>R</api:first-name><api:first-name>K</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="c-data-accessibility" type="text" display-name="Data Accessibility"><api:text>Data1</api:text></api:field><api:field name="c-data-availability-statement" type="boolean" display-name="Data Availability Statement"><api:boolean>true</api:boolean></api:field><api:field name="c-goldoa" type="boolean" display-name="Gold Open Access?"><api:boolean>true</api:boolean></api:field><api:field name="c-licence-statement" type="boolean" display-name="Licence statement?"><api:boolean>false</api:boolean></api:field><api:field name="c-ref-no-issn" type="boolean" display-name="REF No ISSN"><api:boolean>false</api:boolean></api:field><api:field name="c-rights-retention-opt-out" type="boolean" display-name="Rights retention opt out"><api:boolean>false</api:boolean></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.3389/frobt.2024.1288818</api:text><api:links><api:link type="doi" href="http://doi.org/10.3389/frobt.2024.1288818"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.3389/frobt.2024.1288818"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2296-9144</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989440"/></api:links></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2296-9144</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989440"/></api:links></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>Frontiers in Robotics and AI</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>affordance</api:keyword><api:keyword>anthropomorphism</api:keyword><api:keyword>human-robot interaction (HRI)</api:keyword><api:keyword>mixed-method approach</api:keyword><api:keyword>spoken interaction</api:keyword><api:keyword>use cases</api:keyword></api:keywords></api:field><api:field name="location" type="text" display-name="Country"><api:text>Switzerland</api:text></api:field><api:field name="medium" type="text" display-name="Medium"><api:text>Electronic-eCollection</api:text></api:field><api:field name="notes" type="text" display-name="Other information"><api:text>© 2024 Huang and Moore. This is an open-access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</api:text></api:field><api:field name="number" type="text" display-name="Article number"><api:text>1288818</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>18</api:day><api:month>3</api:month><api:year>2024</api:year></api:date></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>18</api:day><api:month>3</api:month><api:year>2024</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="public-url" type="text" display-name="Public URL"><api:text>https://eprints.whiterose.ac.uk/id/eprint/211254</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Frontiers Media SA</api:text></api:field><api:field name="publisher-licence" type="text" display-name="Publisher licence"><api:text>CC BY</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>8</api:day><api:month>4</api:month><api:year>2024</api:year></api:date></api:field><api:field name="record-made-public-at-source-date" type="date" display-name="Record made publicly available"><api:date><api:day>8</api:day><api:month>4</api:month><api:year>2024</api:year></api:date></api:field><api:field name="repository-status" type="text" display-name="Availability"><api:text>Public</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Freedom comes at a cost?: An exploratory study on affordances’ impact on users’ perception of a social robot</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>11</api:text></api:field><api:files><api:file proprietary-id="https://eprints.whiterose.ac.uk/id/file/7004041"><api:filename>frobt-11-1288818.pdf</api:filename><api:file-url>https://eprints.whiterose.ac.uk/211254/1/frobt-11-1288818.pdf</api:file-url><api:extension>pdf</api:extension><api:file-size>43880493</api:file-size><api:mime-type>application/pdf</api:mime-type><api:checksum algorithm="md5">3A347D3FD69E6C46A1324E604832B7D3</api:checksum><api:file-version>Published version</api:file-version></api:file></api:files></api:native></api:record><api:record format="native" id="4557405" source-id="13" source-name="crossref" source-display-name="Crossref" id-at-source="10.3389/frobt.2024.1288818" last-modified-when="2024-04-07T04:29:37.39+01:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>&lt;jats:p&gt;Along with the development of speech and language technologies, the market for speech-enabled human-robot interactions (HRI) has grown in recent years. However, it is found that people feel their conversational interactions with such robots are far from satisfactory. One of the reasons is the habitability gap, where the usability of a speech-enabled agent drops when its flexibility increases. For social robots, such flexibility is reflected in the diverse choice of robots’ appearances, sounds and behaviours, which shape a robot’s ‘affordance’. Whilst designers or users have enjoyed the freedom of constructing a social robot by integrating off-the-shelf technologies, such freedom comes at a potential cost: the users’ perceptions and satisfaction. Designing appropriate affordances is essential for the quality of HRI. It is hypothesised that a social robot with aligned affordances could create an appropriate perception of the robot and increase users’ satisfaction when speaking with it. Given that previous studies of affordance alignment mainly focus on one interface’s characteristics and face-voice match, we aim to deepen our understanding of affordance alignment with a robot’s behaviours and use cases. In particular, we investigate how a robot’s affordances affect users’ perceptions in different types of use cases. For this purpose, we conducted an exploratory experiment that included three different affordance settings (adult-like, child-like, and robot-like) and three use cases (informative, emotional, and hybrid). Participants were invited to talk to social robots in person. A mixed-methods approach was employed for quantitative and qualitative analysis of 156 interaction samples. The results show that static affordance (face and voice) has a statistically significant effect on the perceived warmth of the first impression; use cases affect people’s perceptions more on perceived competence and warmth before and after interactions. In addition, it shows the importance of aligning static affordance with behavioural affordance. General design principles of behavioural affordances are proposed. We anticipate that our empirical evidence will provide a clearer guideline for speech-enabled social robots’ affordance design. It will be a starting point for more sophisticated design guidelines. For example, personalised affordance design for individual or group users in different contexts.&lt;/jats:p&gt;</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30919" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30919"/></api:links><api:last-name>Huang</api:last-name><api:initials>G</api:initials><api:first-names>Guanyu</api:first-names><api:separate-first-names><api:first-name>Guanyu</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="1173" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1173"/></api:links><api:last-name>Moore</api:last-name><api:initials>RK</api:initials><api:first-names>Roger K</api:first-names><api:separate-first-names><api:first-name>Roger</api:first-name><api:first-name>K</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.3389/frobt.2024.1288818</api:text><api:links><api:link type="doi" href="http://doi.org/10.3389/frobt.2024.1288818"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.3389/frobt.2024.1288818"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2296-9144</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989440"/></api:links></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>Frontiers in Robotics and AI</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>18</api:day><api:month>3</api:month><api:year>2024</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published online</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Frontiers Media SA</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>http://dx.doi.org/10.3389/frobt.2024.1288818</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>18</api:day><api:month>3</api:month><api:year>2024</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Freedom comes at a cost?: An exploratory study on affordances’ impact on users’ perception of a social robot</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>11</api:text></api:field></api:native></api:record><api:record format="native" id="4562929" source-id="7" source-name="scopus" source-display-name="Scopus" id-at-source="2-s2.0-85189087974" last-modified-when="2024-04-20T16:13:07.773+01:00"><api:citation-count>0</api:citation-count><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Along with the development of speech and language technologies, the market for speech-enabled human-robot interactions (HRI) has grown in recent years. However, it is found that people feel their conversational interactions with such robots are far from satisfactory. One of the reasons is the habitability gap, where the usability of a speech-enabled agent drops when its flexibility increases. For social robots, such flexibility is reflected in the diverse choice of robots’ appearances, sounds and behaviours, which shape a robot’s ‘affordance’. Whilst designers or users have enjoyed the freedom of constructing a social robot by integrating off-the-shelf technologies, such freedom comes at a potential cost: the users’ perceptions and satisfaction. Designing appropriate affordances is essential for the quality of HRI. It is hypothesised that a social robot with aligned affordances could create an appropriate perception of the robot and increase users’ satisfaction when speaking with it. Given that previous studies of affordance alignment mainly focus on one interface’s characteristics and face-voice match, we aim to deepen our understanding of affordance alignment with a robot’s behaviours and use cases. In particular, we investigate how a robot’s affordances affect users’ perceptions in different types of use cases. For this purpose, we conducted an exploratory experiment that included three different affordance settings (adult-like, child-like, and robot-like) and three use cases (informative, emotional, and hybrid). Participants were invited to talk to social robots in person. A mixed-methods approach was employed for quantitative and qualitative analysis of 156 interaction samples. The results show that static affordance (face and voice) has a statistically significant effect on the perceived warmth of the first impression; use cases affect people’s perceptions more on perceived competence and warmth before and after interactions. In addition, it shows the importance of aligning static affordance with behavioural affordance. General design principles of behavioural affordances are proposed. We anticipate that our empirical evidence will provide a clearer guideline for speech-enabled social robots’ affordance design. It will be a starting point for more sophisticated design guidelines. For example, personalised affordance design for individual or group users in different contexts.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30919" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30919"/></api:links><api:last-name>Huang</api:last-name><api:initials>G</api:initials><api:first-names>G</api:first-names><api:separate-first-names><api:first-name>G</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">The University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">57913770200</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="1173" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1173"/></api:links><api:last-name>Moore</api:last-name><api:initials>RK</api:initials><api:first-names>RK</api:first-names><api:separate-first-names><api:first-name>R</api:first-name><api:first-name>K</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">The University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">58963442200</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.3389/frobt.2024.1288818</api:text><api:links><api:link type="doi" href="http://doi.org/10.3389/frobt.2024.1288818"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.3389/frobt.2024.1288818"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2296-9144</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989440"/></api:links></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>Frontiers in Robotics and AI</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>1</api:month><api:year>2024</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Freedom comes at a cost?: An exploratory study on affordances’ impact on users’ perception of a social robot</api:text></api:field><api:field name="types" type="list" display-name="Sub types"><api:items><api:item>Journal Article</api:item></api:items></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>11</api:text></api:field></api:native></api:record><api:record format="native" id="4561453" source-id="2" source-name="pubmed" source-display-name="PubMed" id-at-source="38562409" last-modified-when="2024-04-17T11:31:16.677+01:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Along with the development of speech and language technologies, the market for speech-enabled human-robot interactions (HRI) has grown in recent years. However, it is found that people feel their conversational interactions with such robots are far from satisfactory. One of the reasons is the habitability gap, where the usability of a speech-enabled agent drops when its flexibility increases. For social robots, such flexibility is reflected in the diverse choice of robots' appearances, sounds and behaviours, which shape a robot's 'affordance'. Whilst designers or users have enjoyed the freedom of constructing a social robot by integrating off-the-shelf technologies, such freedom comes at a potential cost: the users' perceptions and satisfaction. Designing appropriate affordances is essential for the quality of HRI. It is hypothesised that a social robot with aligned affordances could create an appropriate perception of the robot and increase users' satisfaction when speaking with it. Given that previous studies of affordance alignment mainly focus on one interface's characteristics and face-voice match, we aim to deepen our understanding of affordance alignment with a robot's behaviours and use cases. In particular, we investigate how a robot's affordances affect users' perceptions in different types of use cases. For this purpose, we conducted an exploratory experiment that included three different affordance settings (adult-like, child-like, and robot-like) and three use cases (informative, emotional, and hybrid). Participants were invited to talk to social robots in person. A mixed-methods approach was employed for quantitative and qualitative analysis of 156 interaction samples. The results show that static affordance (face and voice) has a statistically significant effect on the perceived warmth of the first impression; use cases affect people's perceptions more on perceived competence and warmth before and after interactions. In addition, it shows the importance of aligning static affordance with behavioural affordance. General design principles of behavioural affordances are proposed. We anticipate that our empirical evidence will provide a clearer guideline for speech-enabled social robots' affordance design. It will be a starting point for more sophisticated design guidelines. For example, personalised affordance design for individual or group users in different contexts.</api:text></api:field><api:field name="acceptance-date" type="date" display-name="Date of acceptance"><api:date><api:day>26</api:day><api:month>2</api:month><api:year>2024</api:year></api:date></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30919" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30919"/></api:links><api:last-name>Huang</api:last-name><api:initials>G</api:initials><api:first-names>Guanyu</api:first-names><api:separate-first-names><api:first-name>Guanyu</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="full">The Speech and Hearing Research Group (SpandH), Department of Computer Science, University of Sheffield, Sheffield, United Kingdom.</api:line></api:address></api:addresses></api:person><api:person><api:links><api:link type="elements/user" id="1173" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1173"/></api:links><api:last-name>Moore</api:last-name><api:initials>RK</api:initials><api:first-names>Roger K</api:first-names><api:separate-first-names><api:first-name>Roger</api:first-name><api:first-name>K</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="full">The Speech and Hearing Research Group (SpandH), Department of Computer Science, University of Sheffield, Sheffield, United Kingdom.</api:line></api:address></api:addresses></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>https://www.ncbi.nlm.nih.gov/pubmed/38562409</api:text></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.3389/frobt.2024.1288818</api:text><api:links><api:link type="doi" href="http://doi.org/10.3389/frobt.2024.1288818"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.3389/frobt.2024.1288818"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2296-9144</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989440"/></api:links></api:field><api:field name="external-identifiers" type="identifier-list" display-name="External identifiers"><api:identifiers><api:identifier scheme="pmc">PMC10983813</api:identifier></api:identifiers></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>Front Robot AI</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>affordance</api:keyword><api:keyword>anthropomorphism</api:keyword><api:keyword>human-robot interaction (HRI)</api:keyword><api:keyword>mixed-method approach</api:keyword><api:keyword>spoken interaction</api:keyword><api:keyword>use cases</api:keyword></api:keywords></api:field><api:field name="language" type="text" display-name="Language"><api:text>eng</api:text></api:field><api:field name="location" type="text" display-name="Country"><api:text>Switzerland</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1288818</api:begin-page></api:pagination></api:field><api:field name="pii" type="text" display-name="PII"><api:text>1288818</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2024</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published online</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Freedom comes at a cost?: An exploratory study on affordances' impact on users' perception of a social robot.</api:text></api:field><api:field name="types" type="list" display-name="Sub types"><api:items><api:item>Journal Article</api:item></api:items></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>11</api:text></api:field></api:native></api:record><api:record format="native" id="4562329" source-id="18" source-name="epmc" source-display-name="Europe PubMed Central" id-at-source="MED:38562409" last-modified-when="2024-05-03T02:25:07.1+01:00"><api:citation-count>0</api:citation-count><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Along with the development of speech and language technologies, the market for speech-enabled human-robot interactions (HRI) has grown in recent years. However, it is found that people feel their conversational interactions with such robots are far from satisfactory. One of the reasons is the habitability gap, where the usability of a speech-enabled agent drops when its flexibility increases. For social robots, such flexibility is reflected in the diverse choice of robots' appearances, sounds and behaviours, which shape a robot's 'affordance'. Whilst designers or users have enjoyed the freedom of constructing a social robot by integrating off-the-shelf technologies, such freedom comes at a potential cost: the users' perceptions and satisfaction. Designing appropriate affordances is essential for the quality of HRI. It is hypothesised that a social robot with aligned affordances could create an appropriate perception of the robot and increase users' satisfaction when speaking with it. Given that previous studies of affordance alignment mainly focus on one interface's characteristics and face-voice match, we aim to deepen our understanding of affordance alignment with a robot's behaviours and use cases. In particular, we investigate how a robot's affordances affect users' perceptions in different types of use cases. For this purpose, we conducted an exploratory experiment that included three different affordance settings (adult-like, child-like, and robot-like) and three use cases (informative, emotional, and hybrid). Participants were invited to talk to social robots in person. A mixed-methods approach was employed for quantitative and qualitative analysis of 156 interaction samples. The results show that static affordance (face and voice) has a statistically significant effect on the perceived warmth of the first impression; use cases affect people's perceptions more on perceived competence and warmth before and after interactions. In addition, it shows the importance of aligning static affordance with behavioural affordance. General design principles of behavioural affordances are proposed. We anticipate that our empirical evidence will provide a clearer guideline for speech-enabled social robots' affordance design. It will be a starting point for more sophisticated design guidelines. For example, personalised affordance design for individual or group users in different contexts.</api:text></api:field><api:field name="addresses" type="address-list" display-name="Addresses"><api:addresses><api:address iso-country-code="GB"><api:line type="full">The Speech and Hearing Research Group (SpandH), Department of Computer Science, University of Sheffield, Sheffield, United Kingdom.</api:line></api:address></api:addresses></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30919" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30919"/></api:links><api:last-name>Huang</api:last-name><api:initials>G</api:initials><api:first-names>Guanyu</api:first-names><api:separate-first-names><api:first-name>Guanyu</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="1173" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1173"/></api:links><api:last-name>Moore</api:last-name><api:initials>RK</api:initials><api:first-names>Roger K</api:first-names><api:separate-first-names><api:first-name>Roger</api:first-name><api:first-name>K</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="orcid">0000-0003-0065-3311</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.3389/frobt.2024.1288818</api:text><api:links><api:link type="doi" href="http://doi.org/10.3389/frobt.2024.1288818"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.3389/frobt.2024.1288818"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2296-9144</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989440"/></api:links></api:field><api:field name="external-identifiers" type="identifier-list" display-name="External identifiers"><api:identifiers><api:identifier scheme="pubmed">38562409</api:identifier><api:identifier scheme="pmc">PMC10983813</api:identifier></api:identifiers></api:field><api:field name="is-open-access" type="boolean" display-name="Open access"><api:boolean>true</api:boolean></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2296-9144</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989440"/></api:links></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>Frontiers in robotics and AI</api:text></api:field><api:field name="language" type="text" display-name="Language"><api:text>eng</api:text></api:field><api:field name="medium" type="text" display-name="Medium"><api:text>Electronic-eCollection</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>18</api:day><api:month>3</api:month><api:year>2024</api:year></api:date></api:field><api:field name="open-access-status" type="text" display-name="Open access status"><api:text>Open Access</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1288818</api:begin-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:month>1</api:month><api:year>2024</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="publisher-licence" type="text" display-name="Publisher licence"><api:text>CC BY</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>2</api:day><api:month>4</api:month><api:year>2024</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Freedom comes at a cost?: An exploratory study on affordances' impact on users' perception of a social robot.</api:text></api:field><api:field name="types" type="list" display-name="Sub types"><api:items><api:item>research-article</api:item><api:item>Journal Article</api:item></api:items></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>11</api:text></api:field><api:files><api:file proprietary-id="https://europepmc.org/articles/PMC10983813?pdf=render"><api:file-url>https://europepmc.org/articles/PMC10983813?pdf=render</api:file-url><api:extension>pdf</api:extension><api:is-open-access>true</api:is-open-access><api:file-version>Published version</api:file-version></api:file></api:files></api:native></api:record><api:record format="native" id="4557404" source-id="10" source-name="dimensions" source-display-name="Dimensions" id-at-source="pub.1169839628" last-modified-when="2024-04-20T14:32:33.103+01:00"><api:citation-count>0</api:citation-count><api:native><api:field name="altmetric-attention-score" type="integer" display-name="Altmetric attention score"><api:integer>1</api:integer></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30919" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30919"/></api:links><api:last-name>Huang</api:last-name><api:initials>G</api:initials><api:first-names>Guanyu</api:first-names><api:separate-first-names><api:first-name>Guanyu</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.016667704324.18</api:identifier></api:identifiers><api:author-types><api:author-type>corresponding</api:author-type></api:author-types></api:person><api:person><api:links><api:link type="elements/user" id="1173" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1173"/></api:links><api:last-name>Moore</api:last-name><api:initials>RK</api:initials><api:first-names>Roger K</api:first-names><api:separate-first-names><api:first-name>Roger</api:first-name><api:first-name>K</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.012553154205.25</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.3389/frobt.2024.1288818</api:text><api:links><api:link type="doi" href="http://doi.org/10.3389/frobt.2024.1288818"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.3389/frobt.2024.1288818"/></api:links></api:field><api:field name="external-identifiers" type="identifier-list" display-name="External identifiers"><api:identifiers><api:identifier scheme="pubmed">38562409</api:identifier><api:identifier scheme="pmc">PMC10983813</api:identifier></api:identifiers></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2296-9144</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989440"/></api:links></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>Frontiers in Robotics and AI</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword scheme="for-2020">46 Information and Computing Sciences</api:keyword><api:keyword scheme="for-2020">4608 Human-Centred Computing</api:keyword></api:keywords></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>18</api:day><api:month>3</api:month><api:year>2024</api:year></api:date></api:field><api:field name="open-access-status" type="text" display-name="Open access status"><api:text>Gold OA</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1288818</api:begin-page></api:pagination></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Frontiers</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>19</api:day><api:month>3</api:month><api:year>2024</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Freedom comes at a cost?: An exploratory study on affordances’ impact on users’ perception of a social robot</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>11</api:text></api:field></api:native></api:record><api:record format="native" id="4566386" source-id="11" source-name="wos-lite" source-display-name="Web of Science (Lite)" id-at-source="WOS:001194509600001" last-modified-when="2024-05-02T21:00:07.563+01:00"><api:citation-count>0</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="30919" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/30919"/></api:links><api:last-name>Huang</api:last-name><api:initials>G</api:initials><api:first-names>Guanyu</api:first-names><api:separate-first-names><api:first-name>Guanyu</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="1173" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1173"/></api:links><api:last-name>Moore</api:last-name><api:initials>RK</api:initials><api:first-names>Roger K</api:first-names><api:separate-first-names><api:first-name>Roger</api:first-name><api:first-name>K</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="researcherid">B-1985-2016</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>https://www.webofscience.com/api/gateway?GWVersion=2&amp;SrcApp=sheffield_elements_live&amp;SrcAuth=WosAPI&amp;KeyUT=WOS:001194509600001&amp;DestLinkType=FullRecord&amp;DestApp=WOS_CPL</api:text></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.3389/frobt.2024.1288818</api:text><api:links><api:link type="doi" href="http://doi.org/10.3389/frobt.2024.1288818"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.3389/frobt.2024.1288818"/></api:links></api:field><api:field name="external-identifiers" type="identifier-list" display-name="External identifiers"><api:identifiers><api:identifier scheme="isidoc">MO2Y0</api:identifier><api:identifier scheme="pubmed">38562409</api:identifier></api:identifiers></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2296-9144</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989440"/></api:links></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>FRONTIERS IN ROBOTICS AND AI</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>human-robot interaction (HRI)</api:keyword><api:keyword>affordance</api:keyword><api:keyword>anthropomorphism</api:keyword><api:keyword>spoken interaction</api:keyword><api:keyword>use cases</api:keyword><api:keyword>mixed-method approach</api:keyword></api:keywords></api:field><api:field name="number" type="text" display-name="Article number"><api:text>ARTN 1288818</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2024</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Freedom comes at a cost?: An exploratory study on affordances' impact on users' perception of a social robot</api:text></api:field><api:field name="types" type="list" display-name="Sub types"><api:items><api:item>Article</api:item></api:items></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>11</api:text></api:field></api:native></api:record></api:records><api:fields/><api:all-labels type="keyword-list"><api:keywords><api:keyword origin="record-data" source="eprints">affordance</api:keyword><api:keyword origin="record-data" source="eprints">anthropomorphism</api:keyword><api:keyword origin="record-data" source="eprints">human-robot interaction (HRI)</api:keyword><api:keyword origin="record-data" source="eprints">mixed-method approach</api:keyword><api:keyword origin="record-data" source="eprints">spoken interaction</api:keyword><api:keyword origin="record-data" source="eprints">use cases</api:keyword><api:keyword origin="record-data" source="pubmed">affordance</api:keyword><api:keyword origin="record-data" source="pubmed">anthropomorphism</api:keyword><api:keyword origin="record-data" source="pubmed">human-robot interaction (HRI)</api:keyword><api:keyword origin="record-data" source="pubmed">mixed-method approach</api:keyword><api:keyword origin="record-data" source="pubmed">spoken interaction</api:keyword><api:keyword origin="record-data" source="pubmed">use cases</api:keyword><api:keyword scheme="for-2020" origin="record-data" source="dimensions">46 Information and Computing Sciences</api:keyword><api:keyword scheme="for-2020" origin="record-data" source="dimensions">4608 Human-Centred Computing</api:keyword><api:keyword origin="record-data" source="wos-lite">human-robot interaction (HRI)</api:keyword><api:keyword origin="record-data" source="wos-lite">affordance</api:keyword><api:keyword origin="record-data" source="wos-lite">anthropomorphism</api:keyword><api:keyword origin="record-data" source="wos-lite">spoken interaction</api:keyword><api:keyword origin="record-data" source="wos-lite">use cases</api:keyword><api:keyword origin="record-data" source="wos-lite">mixed-method approach</api:keyword><api:keyword scheme="for" origin="issn-inferred">0801 Artificial Intelligence and Image Processing</api:keyword><api:keyword scheme="for" origin="issn-inferred">0906 Electrical and Electronic Engineering</api:keyword><api:keyword scheme="for-2020" origin="issn-inferred">40 Engineering</api:keyword><api:keyword scheme="for-2020" origin="issn-inferred">46 Information and computing sciences</api:keyword></api:keywords></api:all-labels><api:journal issn="2296-9144" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989440" title="Frontiers in Robotics and AI"><api:records><api:record source-name="summary"><api:title>Frontiers in Robotics and AI</api:title></api:record></api:records></api:journal><api:relationships href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1599793/relationships"/></api:object></api:result></api:response>