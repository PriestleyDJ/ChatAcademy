<?xml version="1.0" encoding="utf-8"?><api:response xmlns:api="http://www.symplectic.co.uk/publications/api"><api:version uri="https://mypublications.shef.ac.uk/" elements-version="6.17.0.4095" schema-version="6.13" product-name="myPublications"/><api:request href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254688"/><api:result><api:object category="publication" id="1254688" last-affected-when="2024-04-23T14:06:51.007+01:00" last-modified-when="2024-04-23T14:06:51.007+01:00" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254688" created-when="2019-09-03T05:07:17.7+01:00" type-id="4" type-display-name="Conference proceedings paper" type="conference"><api:privacy-level>Public</api:privacy-level><api:privacy-level-locked>false</api:privacy-level-locked><api:ever-approved>true</api:ever-approved><api:reporting-date-1>2014-09-14</api:reporting-date-1><api:allow-type-switching>true</api:allow-type-switching><api:records><api:record format="native" id="4224910" source-id="28" source-name="eprints" source-display-name="White Rose Research Online" id-at-source="152842" last-modified-when="2022-12-29T15:33:56.417+00:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Developing high-performance speech processing systems for low-resource languages is very challenging. One approach to address the lack of resources is to make use of data from multiple languages. A popular direction in recent years is to train a multi-language bottleneck DNN. Language dependent and/or multi-language (all training languages) Tandem acoustic models (AM) are then trained. This work considers a particular scenario where the target language is unseen in multi-language training and has limited language model training data, a limited lexicon, and acoustic training data without transcriptions. A zero acoustic resources case is first described where a multilanguage AM is directly applied, as a language independent AM (LIAM), to an unseen language. Secondly, in an unsupervised approach a LIAM is used to obtain hypotheses for the target language acoustic data transcriptions which are then used in training a language dependent AM. 3 languages from the IARPA Babel project are used for assessment: Vietnamese, Haitian Creole and Bengali. Performance of the zero acoustic resources system is found to be poor, with keyword spotting at best 60% of language dependent performance. Unsupervised language dependent training yields performance gains. For one language (Haitian Creole) the Babel target is achieved on the in-vocabulary data.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Knill</api:last-name><api:initials>KM</api:initials><api:first-names>KM</api:first-names><api:separate-first-names><api:first-name>K</api:first-name><api:first-name>M</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>MJF</api:first-names><api:separate-first-names><api:first-name>M</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Rath</api:last-name><api:initials>SP</api:initials><api:first-names>SP</api:first-names><api:separate-first-names><api:first-name>S</api:first-name><api:first-name>P</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;SrcApp=PARTNER_APP&amp;SrcAuth=LinksAMR&amp;KeyUT=WOS:000395050100004&amp;DestLinkType=FullRecord&amp;DestApp=ALL_WOS&amp;UsrCustomerID=0bfafa3ff357b450f062b62b10c587b7</api:text></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>INTERSPEECH 2014 : 15th Annual Conference of the International Speech Communication Association</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>speech recognition</api:keyword><api:keyword>low resource</api:keyword><api:keyword>multilingual</api:keyword></api:keywords></api:field><api:field name="location" type="text" display-name="Conference place"><api:text>Singapore</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>INTERSPEECH 2014 : 15th Annual Conference of the International Speech Communication Association</api:text></api:field><api:field name="notes" type="text" display-name="Other information"><api:text>Â© 2014 International Speech Communication Association. Reproduced in accordance with the publisher's self-archiving policy.</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="public-url" type="text" display-name="Public URL"><api:text>https://eprints.whiterose.ac.uk/id/eprint/152842</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>International Speech Communication Association (ISCA)</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>https://www.isca-speech.org/archive/interspeech_2014/i14_0016.html</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>30</api:day><api:month>10</api:month><api:year>2019</api:year></api:date></api:field><api:field name="record-made-public-at-source-date" type="date" display-name="Record made publicly available"><api:date><api:day>12</api:day><api:month>11</api:month><api:year>2019</api:year></api:date></api:field><api:field name="repository-status" type="text" display-name="Availability"><api:text>Public</api:text></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Language independent and unsupervised acoustic models for speech recognition and keyword spotting</api:text></api:field><api:files><api:file proprietary-id="https://eprints.whiterose.ac.uk/id/file/4007127"><api:filename>Knill et al 2014 Language Independent and Unsupervised Acoustic Models for Speech ISCA.pdf</api:filename><api:file-url>https://eprints.whiterose.ac.uk/152842/8/Knill et al 2014 Language Independent and Unsupervised Acoustic Models for Speech ISCA.pdf</api:file-url><api:extension>pdf</api:extension><api:file-size>244477</api:file-size><api:mime-type>application/pdf</api:mime-type><api:checksum algorithm="md5">551006578C6AF87214B191BB28B44FC9</api:checksum><api:file-version>Published version</api:file-version></api:file></api:files></api:native></api:record><api:record format="native" id="3407923" source-id="1" source-name="manual" source-display-name="Manual" id-at-source="58E650A4-0328-49E5-847F-6B0F059CCF27" last-modified-when="2019-11-12T15:41:04.573+00:00" is-locked="true"><api:verification-status>verified</api:verification-status><api:verification-comment>12/11/2019 AJ</api:verification-comment><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Developing high-performance speech processing systems for low-resource languages is very challenging. One approach to address the lack of resources is to make use of data from multiple languages. A popular direction in recent years is to train a multi-language bottleneck DNN. Language dependent and/or multi-language (all training languages) Tandem acoustic models (AM) are then trained. This work considers a particular scenario where the target language is unseen in multi-language training and has limited language model training data, a limited lexicon, and acoustic training data without transcriptions. A zero acoustic resources case is first described where a multilanguage AM is directly applied, as a language independent AM (LIAM), to an unseen language. Secondly, in an unsupervised approach a LIAM is used to obtain hypotheses for the target language acoustic data transcriptions which are then used in training a language dependent AM. 3 languages from the IARPA Babel project are used for assessment: Vietnamese, Haitian Creole and Bengali. Performance of the zero acoustic resources system is found to be poor, with keyword spotting at best 60% of language dependent performance. Unsupervised language dependent training yields performance gains. For one language (Haitian Creole) the Babel target is achieved on the in-vocabulary data.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Knill</api:last-name><api:initials>KM</api:initials><api:first-names>KM</api:first-names><api:separate-first-names><api:first-name>K</api:first-name><api:first-name>M</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>MJF</api:first-names><api:separate-first-names><api:first-name>M</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses></api:person><api:person><api:last-name>Rath</api:last-name><api:initials>SP</api:initials><api:first-names>SP</api:first-names><api:separate-first-names><api:first-name>S</api:first-name><api:first-name>P</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses></api:person></api:people></api:field><api:field name="c-goldoa" type="boolean" display-name="Gold Open Access?"><api:boolean>false</api:boolean></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>18</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>INTERSPEECH 2014 : 15th Annual Conference of the International Speech Communication Association</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>speech recognition</api:keyword><api:keyword>low resource</api:keyword><api:keyword>multilingual</api:keyword></api:keywords></api:field><api:field name="location" type="text" display-name="Conference place"><api:text>Singapore</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>INTERSPEECH 2014 : 15th Annual Conference of the International Speech Communication Association</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>International Speech Communication Association (ISCA)</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>12</api:day><api:month>11</api:month><api:year>2019</api:year></api:date></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Language independent and unsupervised acoustic models for speech recognition and keyword spotting</api:text></api:field></api:native></api:record><api:record format="native" id="3723492" source-id="13" source-name="crossref" source-display-name="Crossref" id-at-source="10.21437/interspeech.2014-4" last-modified-when="2024-01-27T18:19:02.843+00:00"><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Knill</api:last-name><api:initials>KM</api:initials><api:first-names>Kate M</api:first-names><api:separate-first-names><api:first-name>Kate</api:first-name><api:first-name>M</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Rath</api:last-name><api:initials>SP</api:initials><api:first-names>Shakti P</api:first-names><api:separate-first-names><api:first-name>Shakti</api:first-name><api:first-name>P</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.21437/interspeech.2014-4</api:text><api:links><api:link type="doi" href="http://doi.org/10.21437/interspeech.2014-4"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.21437/interspeech.2014-4"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Interspeech 2014</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>Interspeech 2014</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published online</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>ISCA</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>http://dx.doi.org/10.21437/interspeech.2014-4</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>16</api:day><api:month>1</api:month><api:year>2024</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Language independent and unsupervised acoustic models for speech recognition and keyword spotting</api:text></api:field></api:native></api:record><api:record format="native" id="3347088" source-id="7" source-name="scopus" source-display-name="Scopus" id-at-source="2-s2.0-84910067354" last-modified-when="2024-02-27T12:32:09.623+00:00"><api:citation-count>39</api:citation-count><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Developing high-performance speech processing systems for low-resource languages is very challenging. One approach to address the lack of resources is to make use of data from multiple languages. A popular direction in recent years is to train a multi-language bottleneck DNN. Language dependent and/or multi-language (all training languages) Tandem acoustic models (AM) are then trained. This work considers a particular scenario where the target language is unseen in multi-language training and has limited language model training data, a limited lexicon, and acoustic training data without transcriptions. A zero acoustic resources case is first described where a multilanguage AM is directly applied, as a language independent AM (LIAM), to an unseen language. Secondly, in an unsupervised approach a LIAM is used to obtain hypotheses for the target language acoustic data transcriptions which are then used in training a language dependent AM. 3 languages from the IARPA Babel project are used for assessment: Vietnamese, Haitian Creole and Bengali. Performance of the zero acoustic resources system is found to be poor, with keyword spotting at best 60% of language dependent performance. Unsupervised language dependent training yields performance gains. For one language (Haitian Creole) the Babel target is achieved on the in-vocabulary data.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Knill</api:last-name><api:initials>KM</api:initials><api:first-names>KM</api:first-names><api:separate-first-names><api:first-name>K</api:first-name><api:first-name>M</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">6602379640</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>MJF</api:first-names><api:separate-first-names><api:first-name>M</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">7004447872</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">35743526400</api:identifier></api:identifiers></api:person><api:person><api:last-name>Rath</api:last-name><api:initials>SP</api:initials><api:first-names>SP</api:first-names><api:separate-first-names><api:first-name>S</api:first-name><api:first-name>P</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">55752455200</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>1990-9772</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1001168"/></api:links></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2308-457X</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1029834"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>16</api:begin-page><api:end-page>20</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>1</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Language independent and unsupervised acoustic models for speech recognition and keyword spotting</api:text></api:field></api:native></api:record><api:record format="native" id="3723486" source-id="10" source-name="dimensions" source-display-name="Dimensions" id-at-source="pub.1140719341" last-modified-when="2024-03-03T06:37:26.617+00:00"><api:citation-count>22</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Knill</api:last-name><api:initials>KM</api:initials><api:first-names>Kate M</api:first-names><api:separate-first-names><api:first-name>Kate</api:first-name><api:first-name>M</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.07421230655.29</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.015135510264.46</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.011072730015.33</api:identifier></api:identifiers></api:person><api:person><api:last-name>Rath</api:last-name><api:initials>SP</api:initials><api:first-names>Shakti P</api:first-names><api:separate-first-names><api:first-name>Shakti</api:first-name><api:first-name>P</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.014327554451.95</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.21437/interspeech.2014-4</api:text><api:links><api:link type="doi" href="http://doi.org/10.21437/interspeech.2014-4"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.21437/interspeech.2014-4"/></api:links></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>Interspeech 2014</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="open-access-status" type="text" display-name="Open access status"><api:text>Green OA</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>16</api:begin-page><api:end-page>20</api:end-page></api:pagination></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>International Speech Communication Association</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>30</api:day><api:month>8</api:month><api:year>2021</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Language independent and unsupervised acoustic models for speech recognition and keyword spotting</api:text></api:field></api:native></api:record><api:record format="native" id="3346676" source-id="11" source-name="wos-lite" source-display-name="Web of Science (Lite)" id-at-source="WOS:000395050100004" last-modified-when="2024-04-23T14:06:51.04+01:00"><api:citation-count>39</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Knill</api:last-name><api:initials>KM</api:initials><api:first-names>Kate M</api:first-names><api:separate-first-names><api:first-name>Kate</api:first-name><api:first-name>M</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Rath</api:last-name><api:initials>SP</api:initials><api:first-names>Shakti P</api:first-names><api:separate-first-names><api:first-name>Shakti</api:first-name><api:first-name>P</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>https://www.webofscience.com/api/gateway?GWVersion=2&amp;SrcApp=sheffield_elements_live&amp;SrcAuth=WosAPI&amp;KeyUT=WOS:000395050100004&amp;DestLinkType=FullRecord&amp;DestApp=WOS_CPL</api:text></api:field><api:field name="external-identifiers" type="identifier-list" display-name="External identifiers"><api:identifiers><api:identifier scheme="isidoc">BH0HY</api:identifier></api:identifiers></api:field><api:field name="isbn-13" type="text" display-name="ISBN-13"><api:text>978-1-63439-435-2</api:text></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2308-457X</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1029834"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>15TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2014), VOLS 1-4</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>speech recognition</api:keyword><api:keyword>low resource</api:keyword><api:keyword>multilingual</api:keyword></api:keywords></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>16</api:begin-page><api:end-page>20</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Language Independent and Unsupervised Acoustic Models for Speech Recognition and Keyword Spotting</api:text></api:field></api:native></api:record><api:record format="native" id="3349093" source-id="6" source-name="dblp" source-display-name="DBLP" id-at-source="conf/interspeech/KnillGRR14" last-modified-when="2020-04-28T11:29:22.873+01:00"><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Knill</api:last-name><api:initials>K</api:initials><api:first-names>Kate</api:first-names><api:separate-first-names><api:first-name>Kate</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Rath</api:last-name><api:initials>SP</api:initials><api:first-names>Shakti P</api:first-names><api:separate-first-names><api:first-name>Shakti</api:first-name><api:first-name>P</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="editors" type="person-list" display-name="Editors"><api:people><api:person><api:last-name>Li</api:last-name><api:initials>H</api:initials><api:first-names>Haizhou</api:first-names><api:separate-first-names><api:first-name>Haizhou</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Meng</api:last-name><api:initials>HM</api:initials><api:first-names>Helen M</api:first-names><api:separate-first-names><api:first-name>Helen</api:first-name><api:first-name>M</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Ma</api:last-name><api:initials>B</api:initials><api:first-names>Bin</api:first-names><api:separate-first-names><api:first-name>Bin</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Chng</api:last-name><api:initials>E</api:initials><api:first-names>Engsiong</api:first-names><api:separate-first-names><api:first-name>Engsiong</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Xie</api:last-name><api:initials>L</api:initials><api:first-names>Lei</api:first-names><api:separate-first-names><api:first-name>Lei</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>INTERSPEECH</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>16</api:begin-page><api:end-page>20</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2014</api:year></api:date></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>ISCA</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>http://www.isca-speech.org/archive/interspeech_2014</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Language independent and unsupervised acoustic models for speech recognition and keyword spotting.</api:text></api:field></api:native></api:record></api:records><api:fields/><api:all-labels type="keyword-list"><api:keywords><api:keyword origin="record-data" source="eprints">speech recognition</api:keyword><api:keyword origin="record-data" source="eprints">low resource</api:keyword><api:keyword origin="record-data" source="eprints">multilingual</api:keyword><api:keyword origin="record-data" source="manual">speech recognition</api:keyword><api:keyword origin="record-data" source="manual">low resource</api:keyword><api:keyword origin="record-data" source="manual">multilingual</api:keyword><api:keyword origin="record-data" source="wos-lite">speech recognition</api:keyword><api:keyword origin="record-data" source="wos-lite">low resource</api:keyword><api:keyword origin="record-data" source="wos-lite">multilingual</api:keyword></api:keywords></api:all-labels><api:journal issn="2308-457X" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1029834" title="Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH"><api:records><api:record source-name="summary"><api:title>Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</api:title></api:record></api:records></api:journal><api:relationships href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254688/relationships"/></api:object></api:result></api:response>