<?xml version="1.0" encoding="utf-8"?><api:response xmlns:api="http://www.symplectic.co.uk/publications/api"><api:version uri="https://mypublications.shef.ac.uk/" elements-version="6.17.0.4095" schema-version="6.13" product-name="myPublications"/><api:request href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254686"/><api:result><api:object category="publication" id="1254686" last-affected-when="2024-03-31T07:23:35.82+01:00" last-modified-when="2024-03-31T07:23:35.82+01:00" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254686" created-when="2019-09-03T05:07:17.147+01:00" type-id="4" type-display-name="Conference proceedings paper" type="conference"><api:privacy-level>Public</api:privacy-level><api:privacy-level-locked>false</api:privacy-level-locked><api:ever-approved>true</api:ever-approved><api:reporting-date-1>2014-09-14</api:reporting-date-1><api:allow-type-switching>true</api:allow-type-switching><api:records><api:record format="native" id="4224913" source-id="28" source-name="eprints" source-display-name="White Rose Research Online" id-at-source="152845" last-modified-when="2022-12-29T15:34:05.56+00:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>In recent years there has been significant interest in Automatic Speech Recognition (ASR) and KeyWord Spotting (KWS) systems for low resource languages. One of the driving forces for this research direction is the IARPA Babel project. This paper examines the performance gains that can be obtained by combining two forms of deep neural network ASR systems, Tandem and Hybrid, for both ASR and KWS using data released under the Babel project. Baseline systems are described for the five option period 1 languages: Assamese; Bengali; Haitian Creole; Lao; and Zulu. All the ASR systems share common attributes, for example deep neural network configurations, and decision trees based on rich phonetic questions and state-position root nodes. The baseline ASR and KWS performance of Hybrid and Tandem systems are compared for both the "full", approximately 80 hours of training data, and limited, approximately 10 hours of training data, language packs. By combining the two systems together consistent performance gains can be obtained for KWS in all configurations.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Rath</api:last-name><api:initials>SP</api:initials><api:first-names>SP</api:first-names><api:separate-first-names><api:first-name>S</api:first-name><api:first-name>P</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Knill</api:last-name><api:initials>KM</api:initials><api:first-names>KM</api:first-names><api:separate-first-names><api:first-name>K</api:first-name><api:first-name>M</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>MJF</api:first-names><api:separate-first-names><api:first-name>M</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;SrcApp=PARTNER_APP&amp;SrcAuth=LinksAMR&amp;KeyUT=WOS:000395050100170&amp;DestLinkType=FullRecord&amp;DestApp=ALL_WOS&amp;UsrCustomerID=0bfafa3ff357b450f062b62b10c587b7</api:text></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>1990-9772</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1001168"/></api:links></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>INTERSPEECH 2014 : 15th Annual Conference of the International Speech Communication Association</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>keyword spotting</api:keyword><api:keyword>deep neural network</api:keyword><api:keyword>Tandem</api:keyword><api:keyword>Hybrid</api:keyword></api:keywords></api:field><api:field name="location" type="text" display-name="Conference place"><api:text>Singapore</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>INTERSPEECH 2014 : 15th Annual Conference of the International Speech Communication Association</api:text></api:field><api:field name="notes" type="text" display-name="Other information"><api:text>Â© 2014 International Speech Communication Association (ISCA). Reproduced in accordance with the publisher's self-archiving policy.</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>835</api:begin-page><api:end-page>839</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="public-url" type="text" display-name="Public URL"><api:text>https://eprints.whiterose.ac.uk/id/eprint/152845</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>International Speech Communication Association (ISCA)</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>https://www.isca-speech.org/archive/interspeech_2014/i14_0835.html</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>30</api:day><api:month>10</api:month><api:year>2019</api:year></api:date></api:field><api:field name="record-made-public-at-source-date" type="date" display-name="Record made publicly available"><api:date><api:day>13</api:day><api:month>11</api:month><api:year>2019</api:year></api:date></api:field><api:field name="repository-status" type="text" display-name="Availability"><api:text>Public</api:text></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Combining tandem and hybrid systems for improved speech recognition and keyword spotting on low resource languages</api:text></api:field><api:files><api:file proprietary-id="https://eprints.whiterose.ac.uk/id/file/4010285"><api:filename>Rath et al 2014 Combining Tandem and Hybrid Systems for Improved Speech Recognition and Keyword Spotting on Low Resource Languages.pdf</api:filename><api:file-url>https://eprints.whiterose.ac.uk/152845/8/Rath et al 2014 Combining Tandem and Hybrid Systems for Improved Speech Recognition and Keyword Spotting on Low Resource Languages.pdf</api:file-url><api:extension>pdf</api:extension><api:file-size>326077</api:file-size><api:mime-type>application/pdf</api:mime-type><api:checksum algorithm="md5">5BB519C7FD1D4E9F837729B1FEABA7B7</api:checksum><api:file-version>Published version</api:file-version></api:file></api:files></api:native></api:record><api:record format="native" id="3409174" source-id="1" source-name="manual" source-display-name="Manual" id-at-source="07D918E4-3D92-4834-B28E-9E6D04F34B06" last-modified-when="2019-11-13T10:42:40.43+00:00" is-locked="true"><api:verification-status>verified</api:verification-status><api:verification-comment>13/11/2019 AJ</api:verification-comment><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>In recent years there has been significant interest in Automatic Speech Recognition (ASR) and KeyWord Spotting (KWS) systems for low resource languages. One of the driving forces for this research direction is the IARPA Babel project. This paper examines the performance gains that can be obtained by combining two forms of deep neural network ASR systems, Tandem and Hybrid, for both ASR and KWS using data released under the Babel project. Baseline systems are described for the five option period 1 languages: Assamese; Bengali; Haitian Creole; Lao; and Zulu. All the ASR systems share common attributes, for example deep neural network configurations, and decision trees based on rich phonetic questions and state-position root nodes. The baseline ASR and KWS performance of Hybrid and Tandem systems are compared for both the "full", approximately 80 hours of training data, and limited, approximately 10 hours of training data, language packs. By combining the two systems together consistent performance gains can be obtained for KWS in all configurations.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Rath</api:last-name><api:initials>SP</api:initials><api:first-names>SP</api:first-names><api:separate-first-names><api:first-name>S</api:first-name><api:first-name>P</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses></api:person><api:person><api:last-name>Knill</api:last-name><api:initials>KM</api:initials><api:first-names>KM</api:first-names><api:separate-first-names><api:first-name>K</api:first-name><api:first-name>M</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>MJF</api:first-names><api:separate-first-names><api:first-name>M</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses></api:person></api:people></api:field><api:field name="c-goldoa" type="boolean" display-name="Gold Open Access?"><api:boolean>false</api:boolean></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>1990-9772</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1001168"/></api:links></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>18</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>INTERSPEECH 2014 : 15th Annual Conference of the International Speech Communication Association</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>keyword spotting</api:keyword><api:keyword>deep neural network</api:keyword><api:keyword>Tandem</api:keyword><api:keyword>Hybrid</api:keyword></api:keywords></api:field><api:field name="location" type="text" display-name="Conference place"><api:text>Singapore</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>INTERSPEECH 2014 : 15th Annual Conference of the International Speech Communication Association</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>835</api:begin-page><api:end-page>839</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>International Speech Communication Association (ISCA)</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>13</api:day><api:month>11</api:month><api:year>2019</api:year></api:date></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Combining tandem and hybrid systems for improved speech recognition and keyword spotting on low resource languages</api:text></api:field></api:native></api:record><api:record format="native" id="3723490" source-id="13" source-name="crossref" source-display-name="Crossref" id-at-source="10.21437/interspeech.2014-212" last-modified-when="2024-01-27T18:19:03.703+00:00"><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Rath</api:last-name><api:initials>SP</api:initials><api:first-names>Shakti P</api:first-names><api:separate-first-names><api:first-name>Shakti</api:first-name><api:first-name>P</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Knill</api:last-name><api:initials>KM</api:initials><api:first-names>Kate M</api:first-names><api:separate-first-names><api:first-name>Kate</api:first-name><api:first-name>M</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.21437/interspeech.2014-212</api:text><api:links><api:link type="doi" href="http://doi.org/10.21437/interspeech.2014-212"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.21437/interspeech.2014-212"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Interspeech 2014</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>Interspeech 2014</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published online</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>ISCA</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>http://dx.doi.org/10.21437/interspeech.2014-212</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>16</api:day><api:month>1</api:month><api:year>2024</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Combining tandem and hybrid systems for improved speech recognition and keyword spotting on low resource languages</api:text></api:field></api:native></api:record><api:record format="native" id="3347087" source-id="7" source-name="scopus" source-display-name="Scopus" id-at-source="2-s2.0-84910068314" last-modified-when="2023-04-25T11:58:52.83+01:00"><api:citation-count>20</api:citation-count><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>In recent years there has been significant interest in Automatic Speech Recognition (ASR) and KeyWord Spotting (KWS) systems for low resource languages. One of the driving forces for this research direction is the IARPA Babel project. This paper examines the performance gains that can be obtained by combining two forms of deep neural network ASR systems, Tandem and Hybrid, for both ASR and KWS using data released under the Babel project. Baseline systems are described for the five option period 1 languages: Assamese; Bengali; Haitian Creole; Lao; and Zulu. All the ASR systems share common attributes, for example deep neural network configurations, and decision trees based on rich phonetic questions and state-position root nodes. The baseline ASR and KWS performance of Hybrid and Tandem systems are compared for both the "full", approximately 80 hours of training data, and limited, approximately 10 hours of training data, language packs. By combining the two systems together consistent performance gains can be obtained for KWS in all configurations.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Rath</api:last-name><api:initials>SP</api:initials><api:first-names>SP</api:first-names><api:separate-first-names><api:first-name>S</api:first-name><api:first-name>P</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">55752455200</api:identifier></api:identifiers></api:person><api:person><api:last-name>Knill</api:last-name><api:initials>KM</api:initials><api:first-names>KM</api:first-names><api:separate-first-names><api:first-name>K</api:first-name><api:first-name>M</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">6602379640</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">35743526400</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>MJF</api:first-names><api:separate-first-names><api:first-name>M</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">7004447872</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>1990-9772</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1001168"/></api:links></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2308-457X</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1029834"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>835</api:begin-page><api:end-page>839</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>1</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Combining tandem and hybrid systems for improved speech recognition and keyword spotting on low resource languages</api:text></api:field></api:native></api:record><api:record format="native" id="3723487" source-id="10" source-name="dimensions" source-display-name="Dimensions" id-at-source="pub.1140719134" last-modified-when="2024-03-31T07:23:35.827+01:00"><api:citation-count>7</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Rath</api:last-name><api:initials>SP</api:initials><api:first-names>Shakti P</api:first-names><api:separate-first-names><api:first-name>Shakti</api:first-name><api:first-name>P</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.014327554451.95</api:identifier></api:identifiers></api:person><api:person><api:last-name>Knill</api:last-name><api:initials>KM</api:initials><api:first-names>Kate M</api:first-names><api:separate-first-names><api:first-name>Kate</api:first-name><api:first-name>M</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.07421230655.29</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.011072730015.33</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.015135510264.46</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.21437/interspeech.2014-212</api:text><api:links><api:link type="doi" href="http://doi.org/10.21437/interspeech.2014-212"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.21437/interspeech.2014-212"/></api:links></api:field><api:field name="field-citation-ratio" type="decimal" display-name="Field citation ratio"><api:decimal>1.69</api:decimal></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword scheme="for-2020">46 Information and Computing Sciences</api:keyword><api:keyword scheme="for-2020">32 Biomedical and Clinical Sciences</api:keyword><api:keyword scheme="for-2020">4602 Artificial Intelligence</api:keyword></api:keywords></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>Interspeech 2014</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>14</api:day><api:month>9</api:month><api:year>2014</api:year></api:date></api:field><api:field name="open-access-status" type="text" display-name="Open access status"><api:text>Green OA</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>835</api:begin-page><api:end-page>839</api:end-page></api:pagination></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>International Speech Communication Association</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>30</api:day><api:month>8</api:month><api:year>2021</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Combining tandem and hybrid systems for improved speech recognition and keyword spotting on low resource languages</api:text></api:field></api:native></api:record><api:record format="native" id="3346674" source-id="11" source-name="wos-lite" source-display-name="Web of Science (Lite)" id-at-source="WOS:000395050100170" last-modified-when="2024-03-13T20:56:03.93+00:00"><api:citation-count>9</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Rath</api:last-name><api:initials>SP</api:initials><api:first-names>Shakti P</api:first-names><api:separate-first-names><api:first-name>Shakti</api:first-name><api:first-name>P</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Knill</api:last-name><api:initials>KM</api:initials><api:first-names>Kate M</api:first-names><api:separate-first-names><api:first-name>Kate</api:first-name><api:first-name>M</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJE</api:initials><api:first-names>Mark JE</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>E</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>https://www.webofscience.com/api/gateway?GWVersion=2&amp;SrcApp=sheffield_elements_live&amp;SrcAuth=WosAPI&amp;KeyUT=WOS:000395050100170&amp;DestLinkType=FullRecord&amp;DestApp=WOS_CPL</api:text></api:field><api:field name="external-identifiers" type="identifier-list" display-name="External identifiers"><api:identifiers><api:identifier scheme="isidoc">BH0HY</api:identifier></api:identifiers></api:field><api:field name="isbn-13" type="text" display-name="ISBN-13"><api:text>978-1-63439-435-2</api:text></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2308-457X</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1029834"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>15TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2014), VOLS 1-4</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>keyword spotting</api:keyword><api:keyword>deep neural network</api:keyword><api:keyword>Tandem</api:keyword><api:keyword>Hybrid</api:keyword></api:keywords></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>835</api:begin-page><api:end-page>839</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Combining Tandem and Hybrid Systems for Improved Speech Recognition and Keyword Spotting on Low Resource Languages</api:text></api:field></api:native></api:record><api:record format="native" id="3349089" source-id="6" source-name="dblp" source-display-name="DBLP" id-at-source="conf/interspeech/RathKRG14" last-modified-when="2020-04-28T11:29:23.5+01:00"><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Rath</api:last-name><api:initials>SP</api:initials><api:first-names>Shakti P</api:first-names><api:separate-first-names><api:first-name>Shakti</api:first-name><api:first-name>P</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Knill</api:last-name><api:initials>KM</api:initials><api:first-names>Kate M</api:first-names><api:separate-first-names><api:first-name>Kate</api:first-name><api:first-name>M</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="editors" type="person-list" display-name="Editors"><api:people><api:person><api:last-name>Li</api:last-name><api:initials>H</api:initials><api:first-names>Haizhou</api:first-names><api:separate-first-names><api:first-name>Haizhou</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Meng</api:last-name><api:initials>HM</api:initials><api:first-names>Helen M</api:first-names><api:separate-first-names><api:first-name>Helen</api:first-name><api:first-name>M</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Ma</api:last-name><api:initials>B</api:initials><api:first-names>Bin</api:first-names><api:separate-first-names><api:first-name>Bin</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Chng</api:last-name><api:initials>E</api:initials><api:first-names>Engsiong</api:first-names><api:separate-first-names><api:first-name>Engsiong</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Xie</api:last-name><api:initials>L</api:initials><api:first-names>Lei</api:first-names><api:separate-first-names><api:first-name>Lei</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>INTERSPEECH</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>835</api:begin-page><api:end-page>839</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2014</api:year></api:date></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>ISCA</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>http://www.isca-speech.org/archive/interspeech_2014</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Combining tandem and hybrid systems for improved speech recognition and keyword spotting on low resource languages.</api:text></api:field></api:native></api:record></api:records><api:fields/><api:all-labels type="keyword-list"><api:keywords><api:keyword origin="record-data" source="eprints">keyword spotting</api:keyword><api:keyword origin="record-data" source="eprints">deep neural network</api:keyword><api:keyword origin="record-data" source="eprints">Tandem</api:keyword><api:keyword origin="record-data" source="eprints">Hybrid</api:keyword><api:keyword origin="record-data" source="manual">keyword spotting</api:keyword><api:keyword origin="record-data" source="manual">deep neural network</api:keyword><api:keyword origin="record-data" source="manual">Tandem</api:keyword><api:keyword origin="record-data" source="manual">Hybrid</api:keyword><api:keyword scheme="for-2020" origin="record-data" source="dimensions">46 Information and Computing Sciences</api:keyword><api:keyword scheme="for-2020" origin="record-data" source="dimensions">32 Biomedical and Clinical Sciences</api:keyword><api:keyword scheme="for-2020" origin="record-data" source="dimensions">4602 Artificial Intelligence</api:keyword><api:keyword origin="record-data" source="wos-lite">keyword spotting</api:keyword><api:keyword origin="record-data" source="wos-lite">deep neural network</api:keyword><api:keyword origin="record-data" source="wos-lite">Tandem</api:keyword><api:keyword origin="record-data" source="wos-lite">Hybrid</api:keyword></api:keywords></api:all-labels><api:journal issn="1990-9772" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1001168" title="Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH"><api:records><api:record source-name="summary"><api:title>Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</api:title></api:record></api:records></api:journal><api:relationships href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254686/relationships"/></api:object></api:result></api:response>