<?xml version="1.0" encoding="utf-8"?><api:response xmlns:api="http://www.symplectic.co.uk/publications/api"><api:version uri="https://mypublications.shef.ac.uk/" elements-version="6.17.0.4095" schema-version="6.13" product-name="myPublications"/><api:request href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1550207"/><api:result><api:object category="publication" id="1550207" last-affected-when="2024-05-03T12:19:55.823+01:00" last-modified-when="2024-05-03T12:19:55.823+01:00" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1550207" created-when="2023-07-17T19:32:06.01+01:00" type-id="5" type-display-name="Journal article" type="journal-article"><api:privacy-level>Public</api:privacy-level><api:privacy-level-locked>false</api:privacy-level-locked><api:ever-approved>true</api:ever-approved><api:reporting-date-1>2023-07-18</api:reporting-date-1><api:allow-type-switching>true</api:allow-type-switching><api:records><api:record format="native" id="4329489" source-id="28" source-name="eprints" source-display-name="White Rose Research Online" id-at-source="201658" last-modified-when="2023-09-04T13:41:48.887+01:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Due to their imaging mechanisms and techniques, some depth images inevitably have low visual qualities or have some inconsistent foregrounds with their corresponding RGB images. Directly using such depth images will deteriorate the performance of RGB-D SOD. In view of this, a novel RGB-D salient object detection model is presented, which follows the principle of calibration-then-fusion to effectively suppress the influence of such two types of depth images on final saliency prediction. Specifically, the proposed model is composed of two stages, i.e., an image generation stage and a saliency reasoning stage. The former generates high-quality and foreground-consistent pseudo depth images via an image generation network. While the latter first calibrates the original depth information with the aid of those newly generated pseudo depth images and then performs cross-modal feature fusion for the final saliency reasoning. Especially, in the first stage, a Two-steps Sample Selection (TSS) strategy is employed to select such reliable depth images from the original RGB-D image pairs as supervision information to optimize the image generation network. Afterwards, in the second stage, a Feature Calibrating and Fusing Network (FCFNet) is proposed to achieve the calibration-then-fusion of cross-modal information for the final saliency prediction, which is achieved by a Depth Feature Calibration (DFC) module, a Shallow-level Feature Injection (SFI) module and a Multi-modal Multi-scale Fusion (MMF) module. Moreover, a loss function, i.e., Region Consistency Aware (RCA) loss, is presented as an auxiliary loss for FCFNet to facilitate the completeness of salient objects together with the reduction of background interference by considering the local regional consistency in the saliency maps. Experiments on six benchmark datasets demonstrate the superiorities of our proposed RGB-D SOD model over some state-of-the-arts.</api:text></api:field><api:field name="acceptance-date" type="date" display-name="Date of acceptance"><api:date><api:day>10</api:day><api:month>7</api:month><api:year>2023</api:year></api:date></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Zhang</api:last-name><api:initials>Q</api:initials><api:first-names>Q</api:first-names><api:separate-first-names><api:first-name>Q</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Qin</api:last-name><api:initials>Q</api:initials><api:first-names>Q</api:first-names><api:separate-first-names><api:first-name>Q</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Yang</api:last-name><api:initials>Y</api:initials><api:first-names>Y</api:first-names><api:separate-first-names><api:first-name>Y</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Jian</api:last-name><api:initials>Q</api:initials><api:first-names>Q</api:first-names><api:separate-first-names><api:first-name>Q</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="36768" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/36768"/></api:links><api:last-name>Han</api:last-name><api:initials>J</api:initials><api:first-names>J</api:first-names><api:separate-first-names><api:first-name>J</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="c-data-accessibility" type="text" display-name="Data Accessibility"><api:text>DataN</api:text></api:field><api:field name="c-data-availability-statement" type="boolean" display-name="Data Availability Statement"><api:boolean>false</api:boolean></api:field><api:field name="c-goldoa" type="boolean" display-name="Gold Open Access?"><api:boolean>false</api:boolean></api:field><api:field name="c-licence-statement" type="boolean" display-name="Licence statement?"><api:boolean>false</api:boolean></api:field><api:field name="c-ref-no-issn" type="boolean" display-name="REF No ISSN"><api:boolean>false</api:boolean></api:field><api:field name="c-rights-retention-opt-out" type="boolean" display-name="Rights retention opt out"><api:boolean>false</api:boolean></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/TCSVT.2023.3296581</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/TCSVT.2023.3296581"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/TCSVT.2023.3296581"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>1558-2205</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/967183"/></api:links></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1051-8215</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/967183"/></api:links></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>IEEE Transactions on Circuits and Systems for Video Technology</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>Salient object detection</api:keyword><api:keyword>RGB-D images</api:keyword><api:keyword>twosteps sample selection</api:keyword><api:keyword>calibration-then-fusion</api:keyword><api:keyword>region consistency aware loss</api:keyword></api:keywords></api:field><api:field name="notes" type="text" display-name="Other information"><api:text>Â© 2023 The Author(s). Except as otherwise noted, this author-accepted version of a journal article published in IEEE Transactions on Circuits and Systems for Video Technology is made available via the University of Sheffield Research Publications and Copyright Policy under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution and reproduction in any medium, provided the original work is properly cited. To view a copy of this licence, visit  http://creativecommons.org/licenses/by/4.0/</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>18</api:day><api:month>7</api:month><api:year>2023</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published online</api:text></api:field><api:field name="public-url" type="text" display-name="Public URL"><api:text>https://eprints.whiterose.ac.uk/id/eprint/201658</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Institute of Electrical and Electronics Engineers</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>17</api:day><api:month>7</api:month><api:year>2023</api:year></api:date></api:field><api:field name="record-made-public-at-source-date" type="date" display-name="Record made publicly available"><api:date><api:day>18</api:day><api:month>7</api:month><api:year>2023</api:year></api:date></api:field><api:field name="repository-status" type="text" display-name="Availability"><api:text>Public</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Feature calibrating and fusing network for RGB-D salient object detection</api:text></api:field><api:files><api:file proprietary-id="https://eprints.whiterose.ac.uk/id/file/6586155"><api:filename>FCFNet_FINAL_VERSION.pdf</api:filename><api:file-url>https://eprints.whiterose.ac.uk/201658/1/FCFNet_FINAL_VERSION.pdf</api:file-url><api:extension>pdf</api:extension><api:file-size>6162141</api:file-size><api:mime-type>application/pdf</api:mime-type><api:checksum algorithm="md5">75FCFF5BFEA69CE1226CC42025140771</api:checksum><api:embargo-release-date>2023-07-23</api:embargo-release-date><api:file-version>Author accepted manuscript</api:file-version></api:file></api:files></api:native></api:record><api:record format="native" id="4334910" source-id="13" source-name="crossref" source-display-name="Crossref" id-at-source="10.1109/tcsvt.2023.3296581" last-modified-when="2024-03-14T21:39:12.05+00:00"><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Zhang</api:last-name><api:initials>Q</api:initials><api:first-names>Qiang</api:first-names><api:separate-first-names><api:first-name>Qiang</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="orcid">0000-0002-2828-9905</api:identifier></api:identifiers></api:person><api:person><api:last-name>Qin</api:last-name><api:initials>Q</api:initials><api:first-names>Qi</api:first-names><api:separate-first-names><api:first-name>Qi</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Yang</api:last-name><api:initials>Y</api:initials><api:first-names>Yang</api:first-names><api:separate-first-names><api:first-name>Yang</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="orcid">0000-0001-5021-5219</api:identifier></api:identifiers></api:person><api:person><api:last-name>Jiao</api:last-name><api:initials>Q</api:initials><api:first-names>Qiang</api:first-names><api:separate-first-names><api:first-name>Qiang</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="orcid">0000-0001-5021-5219</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="36768" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/36768"/></api:links><api:last-name>Han</api:last-name><api:initials>J</api:initials><api:first-names>Jungong</api:first-names><api:separate-first-names><api:first-name>Jungong</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="orcid">0000-0003-4361-956X</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/tcsvt.2023.3296581</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/tcsvt.2023.3296581"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/tcsvt.2023.3296581"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>1558-2205</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/967183"/></api:links></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1051-8215</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/967183"/></api:links></api:field><api:field name="issue" type="text" display-name="Issue"><api:text>3</api:text></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>IEEE Transactions on Circuits and Systems for Video Technology</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1493</api:begin-page><api:end-page>1507</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:month>3</api:month><api:year>2024</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Institute of Electrical and Electronics Engineers (IEEE)</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>http://dx.doi.org/10.1109/tcsvt.2023.3296581</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>8</api:day><api:month>3</api:month><api:year>2024</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Feature Calibrating and Fusing Network for RGB-D Salient Object Detection</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>34</api:text></api:field></api:native></api:record><api:record format="native" id="4334940" source-id="7" source-name="scopus" source-display-name="Scopus" id-at-source="2-s2.0-85165304301" last-modified-when="2024-03-22T14:44:07.057+00:00"><api:citation-count>2</api:citation-count><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Due to their imaging mechanisms and techniques, some depth images inevitably have low visual qualities or have some inconsistent foregrounds with their corresponding RGB images. Directly using such depth images will deteriorate the performance of RGB-D SOD. In view of this, a novel RGB-D salient object detection model is presented, which follows the principle of calibration-Then-fusion to effectively suppress the influence of such two types of depth images on final saliency prediction. Specifically, the proposed model is composed of two stages, i.e., an image generation stage and a saliency reasoning stage. The former generates high-quality and foreground-consistent pseudo depth images via an image generation network. While the latter first calibrates the original depth information with the aid of those newly generated pseudo depth images and then performs cross-modal feature fusion for the final saliency reasoning. Especially, in the first stage, a Two-steps Sample Selection (TSS) strategy is employed to select such reliable depth images from the original RGB-D image pairs as supervision information to optimize the image generation network. Afterwards, in the second stage, a Feature Calibrating and Fusing Network (FCFNet) is proposed to achieve the calibration-Then-fusion of cross-modal information for the final saliency prediction, which is achieved by a Depth Feature Calibration (DFC) module, a Shallow-level Feature Injection (SFI) module and a Multi-modal Multi-scale Fusion (MMF) module. Moreover, a loss function, i.e., Region Consistency Aware (RCA) loss, is presented as an auxiliary loss for FCFNet to facilitate the completeness of salient objects together with the reduction of background interference by considering the local regional consistency in the saliency maps. Experiments on six benchmark datasets demonstrate the superiorities of our proposed RGB-D SOD model over some state-of-The-Arts.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Zhang</api:last-name><api:initials>Q</api:initials><api:first-names>Q</api:first-names><api:separate-first-names><api:first-name>Q</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="CN"><api:line type="organisation">Xidian University</api:line><api:line type="city">Xi'an</api:line><api:line type="country">China</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">55624487042</api:identifier><api:identifier scheme="orcid">0000-0002-2828-9905</api:identifier></api:identifiers></api:person><api:person><api:last-name>Qin</api:last-name><api:initials>Q</api:initials><api:first-names>Q</api:first-names><api:separate-first-names><api:first-name>Q</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="CN"><api:line type="organisation">Xidian University</api:line><api:line type="city">Xi'an</api:line><api:line type="country">China</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">57888892000</api:identifier></api:identifiers></api:person><api:person><api:last-name>Yang</api:last-name><api:initials>Y</api:initials><api:first-names>Y</api:first-names><api:separate-first-names><api:first-name>Y</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="CN"><api:line type="organisation">Xidian University</api:line><api:line type="city">Xi'an</api:line><api:line type="country">China</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">58428512500</api:identifier><api:identifier scheme="orcid">0000-0001-5021-5219</api:identifier></api:identifiers></api:person><api:person><api:last-name>Jiao</api:last-name><api:initials>Q</api:initials><api:first-names>Q</api:first-names><api:separate-first-names><api:first-name>Q</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="CN"><api:line type="organisation">Xidian University</api:line><api:line type="city">Xi'an</api:line><api:line type="country">China</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">56819801000</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="36768" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/36768"/></api:links><api:last-name>Han</api:last-name><api:initials>J</api:initials><api:first-names>J</api:first-names><api:separate-first-names><api:first-name>J</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">The University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">14522692900</api:identifier><api:identifier scheme="orcid">0000-0003-4361-956X</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/TCSVT.2023.3296581</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/TCSVT.2023.3296581"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/TCSVT.2023.3296581"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>1558-2205</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/967183"/></api:links></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1051-8215</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/967183"/></api:links></api:field><api:field name="issue" type="text" display-name="Issue"><api:text>3</api:text></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>IEEE Transactions on Circuits and Systems for Video Technology</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1493</api:begin-page><api:end-page>1507</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>3</api:month><api:year>2024</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Feature Calibrating and Fusing Network for RGB-D Salient Object Detection</api:text></api:field><api:field name="types" type="list" display-name="Sub types"><api:items><api:item>Journal Article</api:item></api:items></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>34</api:text></api:field></api:native></api:record><api:record format="native" id="4334909" source-id="10" source-name="dimensions" source-display-name="Dimensions" id-at-source="pub.1160817684" last-modified-when="2024-05-03T12:19:55.833+01:00"><api:citation-count>3</api:citation-count><api:native><api:field name="associated-identifiers" type="identifier-list" display-name="Associated Identifiers"><api:identifiers><api:identifier scheme="dimensions-grant-id">grant.8311571</api:identifier><api:identifier scheme="dimensions-grant-id">grant.8942035</api:identifier></api:identifiers></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Zhang</api:last-name><api:initials>Q</api:initials><api:first-names>Qiang</api:first-names><api:separate-first-names><api:first-name>Qiang</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="CN"><api:line type="organisation">Xidian University</api:line><api:line type="city">Xi'an</api:line><api:line type="country">China</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.07356503437.94</api:identifier></api:identifiers></api:person><api:person><api:last-name>Qin</api:last-name><api:initials>Q</api:initials><api:first-names>Qi</api:first-names><api:separate-first-names><api:first-name>Qi</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="CN"><api:line type="organisation">Xidian University</api:line><api:line type="city">Xi'an</api:line><api:line type="country">China</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.013644777756.22</api:identifier></api:identifiers></api:person><api:person><api:last-name>Yang</api:last-name><api:initials>Y</api:initials><api:first-names>Yang</api:first-names><api:separate-first-names><api:first-name>Yang</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="CN"><api:line type="organisation">Xidian University</api:line><api:line type="city">Xi'an</api:line><api:line type="country">China</api:line></api:address></api:addresses><api:author-types><api:author-type>corresponding</api:author-type></api:author-types></api:person><api:person><api:last-name>Jiao</api:last-name><api:initials>Q</api:initials><api:first-names>Qiang</api:first-names><api:separate-first-names><api:first-name>Qiang</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="CN"><api:line type="organisation">Xidian University</api:line><api:line type="city">Xi'an</api:line><api:line type="country">China</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.014332125767.32</api:identifier></api:identifiers><api:author-types><api:author-type>corresponding</api:author-type></api:author-types></api:person><api:person><api:links><api:link type="elements/user" id="36768" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/36768"/></api:links><api:last-name>Han</api:last-name><api:initials>J</api:initials><api:first-names>Jungong</api:first-names><api:separate-first-names><api:first-name>Jungong</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.013141527713.39</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/tcsvt.2023.3296581</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/tcsvt.2023.3296581"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/tcsvt.2023.3296581"/></api:links></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1051-8215</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/967183"/></api:links></api:field><api:field name="issue" type="text" display-name="Issue"><api:text>3</api:text></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>IEEE Transactions on Circuits and Systems for Video Technology</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword scheme="for-2020">46 Information and Computing Sciences</api:keyword><api:keyword scheme="for-2020">4603 Computer Vision and Multimedia Computation</api:keyword></api:keywords></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>18</api:day><api:month>7</api:month><api:year>2023</api:year></api:date></api:field><api:field name="open-access-status" type="text" display-name="Open access status"><api:text>Green OA</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1493</api:begin-page><api:end-page>1507</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>3</api:month><api:year>2024</api:year></api:date></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Institute of Electrical and Electronics Engineers (IEEE)</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>21</api:day><api:month>7</api:month><api:year>2023</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Feature Calibrating and Fusing Network for RGB-D Salient Object Detection</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>34</api:text></api:field></api:native></api:record><api:record format="native" id="4568053" source-id="11" source-name="wos-lite" source-display-name="Web of Science (Lite)" id-at-source="WOS:001179365000047" last-modified-when="2024-04-24T01:30:14.6+01:00"><api:citation-count>2</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Zhang</api:last-name><api:initials>Q</api:initials><api:first-names>Qiang</api:first-names><api:separate-first-names><api:first-name>Qiang</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Qin</api:last-name><api:initials>Q</api:initials><api:first-names>Qi</api:first-names><api:separate-first-names><api:first-name>Qi</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Yang</api:last-name><api:initials>Y</api:initials><api:first-names>Yang</api:first-names><api:separate-first-names><api:first-name>Yang</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Jiao</api:last-name><api:initials>Q</api:initials><api:first-names>Qiang</api:first-names><api:separate-first-names><api:first-name>Qiang</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="36768" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/36768"/></api:links><api:last-name>Han</api:last-name><api:initials>J</api:initials><api:first-names>Jungong</api:first-names><api:separate-first-names><api:first-name>Jungong</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>https://www.webofscience.com/api/gateway?GWVersion=2&amp;SrcApp=sheffield_elements_live&amp;SrcAuth=WosAPI&amp;KeyUT=WOS:001179365000047&amp;DestLinkType=FullRecord&amp;DestApp=WOS_CPL</api:text></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/TCSVT.2023.3296581</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/TCSVT.2023.3296581"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/TCSVT.2023.3296581"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>1558-2205</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/967183"/></api:links></api:field><api:field name="external-identifiers" type="identifier-list" display-name="External identifiers"><api:identifiers><api:identifier scheme="isidoc">KI6H5</api:identifier></api:identifiers></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1051-8215</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/967183"/></api:links></api:field><api:field name="issue" type="text" display-name="Issue"><api:text>3</api:text></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>Visualization</api:keyword><api:keyword>Object detection</api:keyword><api:keyword>Image synthesis</api:keyword><api:keyword>Feature extraction</api:keyword><api:keyword>Cognition</api:keyword><api:keyword>Saliency detection</api:keyword><api:keyword>Streaming media</api:keyword><api:keyword>Salient object detection</api:keyword><api:keyword>RGB-D images</api:keyword><api:keyword>two-steps sample selection</api:keyword><api:keyword>calibration-then-fusion</api:keyword><api:keyword>region consistency aware loss</api:keyword></api:keywords></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1493</api:begin-page><api:end-page>1507</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2024</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Feature Calibrating and Fusing Network for RGB-D Salient Object Detection</api:text></api:field><api:field name="types" type="list" display-name="Sub types"><api:items><api:item>Article</api:item></api:items></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>34</api:text></api:field></api:native></api:record><api:record format="native" id="4329488" source-id="1" source-name="manual" source-display-name="Manual" id-at-source="8340E4E1-9928-42E3-8471-E8DA7979CCBB" last-modified-when="2023-07-17T19:32:06.01+01:00"><api:verification-status>unverified</api:verification-status><api:native><api:field name="acceptance-date" type="date" display-name="Date of acceptance"><api:date><api:day>10</api:day><api:month>7</api:month><api:year>2023</api:year></api:date></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Zhang</api:last-name><api:initials>Q</api:initials><api:first-names>Qiang</api:first-names><api:separate-first-names><api:first-name>Qiang</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Qin</api:last-name><api:initials>Q</api:initials><api:first-names>Qi</api:first-names><api:separate-first-names><api:first-name>Qi</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Yang</api:last-name><api:initials>Y</api:initials><api:first-names>Yang</api:first-names><api:separate-first-names><api:first-name>Yang</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Qiang</api:last-name><api:initials>J</api:initials><api:first-names>Jiao</api:first-names><api:separate-first-names><api:first-name>Jiao</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="36768" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/36768"/></api:links><api:last-name>Han</api:last-name><api:initials>J</api:initials><api:first-names>Jungong</api:first-names><api:separate-first-names><api:first-name>Jungong</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="c-data-availability-statement" type="boolean" display-name="Data Availability Statement"><api:boolean>false</api:boolean></api:field><api:field name="c-licence-statement" type="boolean" display-name="Licence statement?"><api:boolean>false</api:boolean></api:field><api:field name="c-ref-no-issn" type="boolean" display-name="REF No ISSN"><api:boolean>false</api:boolean></api:field><api:field name="c-ref-pre-2014" type="boolean" display-name="REF pre-2014"><api:boolean>false</api:boolean></api:field><api:field name="c-rights-retention-opt-out" type="boolean" display-name="Rights retention opt out"><api:boolean>false</api:boolean></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1051-8215</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/967183"/></api:links></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>IEEE Transactions on Circuits and Systems for Video Technology</api:text></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Accepted</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Institute of Electrical and Electronics Engineers</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>17</api:day><api:month>7</api:month><api:year>2023</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Feature Calibrating and Fusing Network for RGB-D Salient Object Detection</api:text></api:field><api:field name="types" type="list" display-name="Sub types"><api:items><api:item>Original research article</api:item></api:items></api:field></api:native></api:record></api:records><api:fields/><api:all-labels type="keyword-list"><api:keywords><api:keyword origin="record-data" source="eprints">Salient object detection</api:keyword><api:keyword origin="record-data" source="eprints">RGB-D images</api:keyword><api:keyword origin="record-data" source="eprints">twosteps sample selection</api:keyword><api:keyword origin="record-data" source="eprints">calibration-then-fusion</api:keyword><api:keyword origin="record-data" source="eprints">region consistency aware loss</api:keyword><api:keyword scheme="for-2020" origin="record-data" source="dimensions">46 Information and Computing Sciences</api:keyword><api:keyword scheme="for-2020" origin="record-data" source="dimensions">4603 Computer Vision and Multimedia Computation</api:keyword><api:keyword origin="record-data" source="wos-lite">Visualization</api:keyword><api:keyword origin="record-data" source="wos-lite">Object detection</api:keyword><api:keyword origin="record-data" source="wos-lite">Image synthesis</api:keyword><api:keyword origin="record-data" source="wos-lite">Feature extraction</api:keyword><api:keyword origin="record-data" source="wos-lite">Cognition</api:keyword><api:keyword origin="record-data" source="wos-lite">Saliency detection</api:keyword><api:keyword origin="record-data" source="wos-lite">Streaming media</api:keyword><api:keyword origin="record-data" source="wos-lite">Salient object detection</api:keyword><api:keyword origin="record-data" source="wos-lite">RGB-D images</api:keyword><api:keyword origin="record-data" source="wos-lite">two-steps sample selection</api:keyword><api:keyword origin="record-data" source="wos-lite">calibration-then-fusion</api:keyword><api:keyword origin="record-data" source="wos-lite">region consistency aware loss</api:keyword><api:keyword scheme="for" origin="issn-inferred">0801 Artificial Intelligence and Image Processing</api:keyword><api:keyword scheme="for" origin="issn-inferred">0906 Electrical and Electronic Engineering</api:keyword><api:keyword scheme="science-metrix" origin="issn-inferred">Artificial Intelligence &amp; Image Processing</api:keyword><api:keyword scheme="for-2020" origin="issn-inferred">4006 Communications engineering</api:keyword><api:keyword scheme="for-2020" origin="issn-inferred">4009 Electronics, sensors and digital hardware</api:keyword><api:keyword scheme="for-2020" origin="issn-inferred">4603 Computer vision and multimedia computation</api:keyword></api:keywords></api:all-labels><api:journal issn="1051-8215" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/967183" title="IEEE transactions on circuits and systems for video technology (Print)"><api:records><api:record source-name="summary"><api:title>IEEE transactions on circuits and systems for video technology (Print)</api:title></api:record></api:records></api:journal><api:relationships href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1550207/relationships"/><api:flagged-as-not-externally-funded>true</api:flagged-as-not-externally-funded></api:object></api:result></api:response>