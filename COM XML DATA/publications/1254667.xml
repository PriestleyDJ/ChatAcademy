<?xml version="1.0" encoding="utf-8"?><api:response xmlns:api="http://www.symplectic.co.uk/publications/api"><api:version uri="https://mypublications.shef.ac.uk/" elements-version="6.17.0.4095" schema-version="6.13" product-name="myPublications"/><api:request href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254667"/><api:result><api:object category="publication" id="1254667" last-affected-when="2024-03-13T20:55:39.217+00:00" last-modified-when="2024-03-13T20:55:39.217+00:00" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254667" created-when="2019-09-03T05:07:02.36+01:00" type-id="4" type-display-name="Conference proceedings paper" type="conference"><api:privacy-level>Public</api:privacy-level><api:privacy-level-locked>false</api:privacy-level-locked><api:ever-approved>true</api:ever-approved><api:reporting-date-1>2018-09-02</api:reporting-date-1><api:allow-type-switching>true</api:allow-type-switching><api:records><api:record format="native" id="4224870" source-id="28" source-name="eprints" source-display-name="White Rose Research Online" id-at-source="152763" last-modified-when="2022-12-29T15:31:55.85+00:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>The standard framework for developing an automatic speech recognition (ASR) system is to generate training and development data for building the system and evaluation data for the final performance analysis. All the data is assumed to come from the domain of interest. Though this framework is matched to some tasks, it is more challenging for systems that are required to operate over broad domains, or where the ability to collect the required data is limited. This paper discusses ASR work performed under the IARPA MATERIAL program, which is aimed at cross-language information retrieval and examines this challenging scenario. In terms of available data, only limited narrow-band conversational telephone speech data was provided. However, the system is required to operate over a range of domains, including broadcast data. As no data is available for the broadcast domain, this paper proposes an approach for system development based on scraping "related" data from the web and using ASR system confidence scores as the primary metric for developing the acoustic and language model components. As an initial evaluation of the approach, the Swahili development language is used, with the final system performance assessed on the IARPA MATERIAL Analysis Pack 1 data.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>M</api:initials><api:first-names>M</api:first-names><api:separate-first-names><api:first-name>M</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;SrcApp=PARTNER_APP&amp;SrcAuth=LinksAMR&amp;KeyUT=WOS:000465363900465&amp;DestLinkType=FullRecord&amp;DestApp=ALL_WOS&amp;UsrCustomerID=0bfafa3ff357b450f062b62b10c587b7</api:text></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.21437/interspeech.2018-1085</api:text><api:links><api:link type="doi" href="http://doi.org/10.21437/interspeech.2018-1085"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.21437/interspeech.2018-1085"/></api:links></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>2</api:day><api:month>9</api:month><api:year>2018</api:year></api:date></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1990-9772</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1001168"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Interspeech 2018</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>cross-domain development</api:keyword><api:keyword>confidence</api:keyword><api:keyword>web data</api:keyword><api:keyword>speech recognition</api:keyword></api:keywords></api:field><api:field name="location" type="text" display-name="Conference place"><api:text>Hyderabad, India</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>Interspeech 2018</api:text></api:field><api:field name="notes" type="text" display-name="Other information"><api:text>Â© 2018 ISCA. Reproduced in accordance with the publisher's self-archiving policy.</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>2</api:day><api:month>9</api:month><api:year>2018</api:year></api:date></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>2217</api:begin-page><api:end-page>2221</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>2</api:day><api:month>9</api:month><api:year>2018</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="public-url" type="text" display-name="Public URL"><api:text>https://eprints.whiterose.ac.uk/id/eprint/152763</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>International Speech Communication Association (ISCA)</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>29</api:day><api:month>10</api:month><api:year>2019</api:year></api:date></api:field><api:field name="record-made-public-at-source-date" type="date" display-name="Record made publicly available"><api:date><api:day>21</api:day><api:month>11</api:month><api:year>2019</api:year></api:date></api:field><api:field name="repository-status" type="text" display-name="Availability"><api:text>Public</api:text></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>2</api:day><api:month>9</api:month><api:year>2018</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Automatic speech recognition system development in the "wild"</api:text></api:field><api:files><api:file proprietary-id="https://eprints.whiterose.ac.uk/id/file/4050187"><api:filename>Ragni and Gales 2018 Automatic speech recognition system development in the wild, ISCA.pdf</api:filename><api:file-url>https://eprints.whiterose.ac.uk/152763/8/Ragni and Gales 2018 Automatic speech recognition system development in the wild%2C ISCA.pdf</api:file-url><api:extension>pdf</api:extension><api:file-size>208486</api:file-size><api:mime-type>application/pdf</api:mime-type><api:checksum algorithm="md5">B4715B5FB58A57C9F32F6D4D57C27495</api:checksum><api:file-version>Published version</api:file-version></api:file></api:files></api:native></api:record><api:record format="native" id="3416398" source-id="1" source-name="manual" source-display-name="Manual" id-at-source="52F44359-8447-4570-8AE0-4AFF7CCF2297" last-modified-when="2019-11-21T11:57:42.52+00:00" is-locked="true"><api:verification-status>verified</api:verification-status><api:verification-comment>21/11/2019 AJ</api:verification-comment><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>The standard framework for developing an automatic speech recognition (ASR) system is to generate training and development data for building the system and evaluation data for the final performance analysis. All the data is assumed to come from the domain of interest. Though this framework is matched to some tasks, it is more challenging for systems that are required to operate over broad domains, or where the ability to collect the required data is limited. This paper discusses ASR work performed under the IARPA MATERIAL program, which is aimed at cross-language information retrieval and examines this challenging scenario. In terms of available data, only limited narrow-band conversational telephone speech data was provided. However, the system is required to operate over a range of domains, including broadcast data. As no data is available for the broadcast domain, this paper proposes an approach for system development based on scraping "related" data from the web and using ASR system confidence scores as the primary metric for developing the acoustic and language model components. As an initial evaluation of the approach, the Swahili development language is used, with the final system performance assessed on the IARPA MATERIAL Analysis Pack 1 data.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>M</api:initials><api:first-names>Mark</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="c-goldoa" type="boolean" display-name="Gold Open Access?"><api:boolean>false</api:boolean></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.21437/interspeech.2018-1085</api:text><api:links><api:link type="doi" href="http://doi.org/10.21437/interspeech.2018-1085"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.21437/interspeech.2018-1085"/></api:links></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>6</api:day><api:month>9</api:month><api:year>2018</api:year></api:date></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1990-9772</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1001168"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Interspeech 2018</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>cross-domain development</api:keyword><api:keyword>confidence</api:keyword><api:keyword>web data</api:keyword><api:keyword>speech recognition</api:keyword></api:keywords></api:field><api:field name="location" type="text" display-name="Conference place"><api:text>Hyderabad, India</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>Interspeech 2018</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>2</api:day><api:month>9</api:month><api:year>2018</api:year></api:date></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>2217</api:begin-page><api:end-page>2221</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>2</api:day><api:month>9</api:month><api:year>2018</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>International Speech Communication Association (ISCA)</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>21</api:day><api:month>11</api:month><api:year>2019</api:year></api:date></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>2</api:day><api:month>9</api:month><api:year>2018</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Automatic speech recognition system development in the "wild"</api:text></api:field></api:native></api:record><api:record format="native" id="3348873" source-id="13" source-name="crossref" source-display-name="Crossref" id-at-source="10.21437/interspeech.2018-1085" last-modified-when="2024-01-28T04:51:19.777+00:00"><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>M</api:initials><api:first-names>Mark</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.21437/interspeech.2018-1085</api:text><api:links><api:link type="doi" href="http://doi.org/10.21437/interspeech.2018-1085"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.21437/interspeech.2018-1085"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Interspeech 2018</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>Interspeech 2018</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>2</api:day><api:month>9</api:month><api:year>2018</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published online</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>ISCA</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>http://dx.doi.org/10.21437/interspeech.2018-1085</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>16</api:day><api:month>1</api:month><api:year>2024</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Automatic Speech Recognition System Development in the "Wild"</api:text></api:field></api:native></api:record><api:record format="native" id="3347054" source-id="7" source-name="scopus" source-display-name="Scopus" id-at-source="2-s2.0-85054973531" last-modified-when="2021-11-23T11:45:13.27+00:00"><api:citation-count>12</api:citation-count><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>The standard framework for developing an automatic speech recognition (ASR) system is to generate training and development data for building the system, and evaluation data for the final performance analysis. All the data is assumed to come from the domain of interest. Though this framework is matched to some tasks, it is more challenging for systems that are required to operate over broad domains, or where the ability to collect the required data is limited. This paper discusses ASR work performed under the IARPA MATERIAL program, which is aimed at cross-language information retrieval, and examines this challenging scenario. In terms of available data, only limited narrow-band conversational telephone speech data was provided. However, the system is required to operate over a range of domains, including broadcast data. As no data is available for the broadcast domain, this paper proposes an approach for system development based on scrapingârelatedâ data from the web, and using ASR system confidence scores as the primary metric for developing the acoustic and language model components. As an initial evaluation of the approach, the Swahili development language is used, with the final system performance assessed on the IARPA MATERIAL Analysis Pack 1 data.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">35743526400</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>MJF</api:first-names><api:separate-first-names><api:first-name>M</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">7004447872</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.21437/Interspeech.2018-1085</api:text><api:links><api:link type="doi" href="http://doi.org/10.21437/Interspeech.2018-1085"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.21437/Interspeech.2018-1085"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>1990-9772</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1001168"/></api:links></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2308-457X</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1029834"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>2217</api:begin-page><api:end-page>2221</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>1</api:month><api:year>2018</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Automatic speech recognition system development in the âwildâ</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>2018-September</api:text></api:field></api:native></api:record><api:record format="native" id="3348330" source-id="10" source-name="dimensions" source-display-name="Dimensions" id-at-source="pub.1106397229" last-modified-when="2022-09-18T21:58:55.213+01:00"><api:citation-count>9</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.011072730015.33</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>M</api:initials><api:first-names>Mark</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.015135510264.46</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.21437/interspeech.2018-1085</api:text><api:links><api:link type="doi" href="http://doi.org/10.21437/interspeech.2018-1085"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.21437/interspeech.2018-1085"/></api:links></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>Interspeech 2018</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>2</api:day><api:month>9</api:month><api:year>2018</api:year></api:date></api:field><api:field name="open-access-status" type="text" display-name="Open access status"><api:text>Green OA</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>2217</api:begin-page><api:end-page>2221</api:end-page></api:pagination></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>International Speech Communication Association</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>30</api:day><api:month>8</api:month><api:year>2018</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Automatic Speech Recognition System Development in the "Wild"</api:text></api:field></api:native></api:record><api:record format="native" id="3346648" source-id="11" source-name="wos-lite" source-display-name="Web of Science (Lite)" id-at-source="WOS:000465363900465" last-modified-when="2024-03-13T20:55:39.22+00:00"><api:citation-count>7</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>https://www.webofscience.com/api/gateway?GWVersion=2&amp;SrcApp=sheffield_elements_live&amp;SrcAuth=WosAPI&amp;KeyUT=WOS:000465363900465&amp;DestLinkType=FullRecord&amp;DestApp=WOS_CPL</api:text></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.21437/Interspeech.2018-1085</api:text><api:links><api:link type="doi" href="http://doi.org/10.21437/Interspeech.2018-1085"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.21437/Interspeech.2018-1085"/></api:links></api:field><api:field name="external-identifiers" type="identifier-list" display-name="External identifiers"><api:identifiers><api:identifier scheme="isidoc">BM5PH</api:identifier></api:identifiers></api:field><api:field name="isbn-13" type="text" display-name="ISBN-13"><api:text>978-1-5108-7221-9</api:text></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2308-457X</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1029834"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2018), VOLS 1-6</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>cross domain development</api:keyword><api:keyword>confidence</api:keyword><api:keyword>web data</api:keyword><api:keyword>speech recognition</api:keyword></api:keywords></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>2217</api:begin-page><api:end-page>2221</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2018</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Automatic Speech Recognition System Development in the "Wild"</api:text></api:field></api:native></api:record><api:record format="native" id="3349102" source-id="6" source-name="dblp" source-display-name="DBLP" id-at-source="conf/interspeech/RagniG18" last-modified-when="2021-02-16T11:34:19.057+00:00"><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="editors" type="person-list" display-name="Editors"><api:people><api:person><api:last-name>Yegnanarayana</api:last-name><api:initials>B</api:initials><api:first-names>B</api:first-names><api:separate-first-names><api:first-name>B</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>INTERSPEECH</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>2217</api:begin-page><api:end-page>2221</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2018</api:year></api:date></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>ISCA</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>https://doi.org/10.21437/Interspeech.2018</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Automatic Speech Recognition System Development in the "Wild".</api:text></api:field></api:native></api:record></api:records><api:fields/><api:all-labels type="keyword-list"><api:keywords><api:keyword origin="record-data" source="eprints">cross-domain development</api:keyword><api:keyword origin="record-data" source="eprints">confidence</api:keyword><api:keyword origin="record-data" source="eprints">web data</api:keyword><api:keyword origin="record-data" source="eprints">speech recognition</api:keyword><api:keyword origin="record-data" source="manual">cross-domain development</api:keyword><api:keyword origin="record-data" source="manual">confidence</api:keyword><api:keyword origin="record-data" source="manual">web data</api:keyword><api:keyword origin="record-data" source="manual">speech recognition</api:keyword><api:keyword origin="record-data" source="wos-lite">cross domain development</api:keyword><api:keyword origin="record-data" source="wos-lite">confidence</api:keyword><api:keyword origin="record-data" source="wos-lite">web data</api:keyword><api:keyword origin="record-data" source="wos-lite">speech recognition</api:keyword></api:keywords></api:all-labels><api:journal issn="1990-9772" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/1001168" title="Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH"><api:records><api:record source-name="summary"><api:title>Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</api:title></api:record></api:records></api:journal><api:relationships href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254667/relationships"/><api:flagged-as-not-externally-funded>true</api:flagged-as-not-externally-funded></api:object></api:result></api:response>