<?xml version="1.0" encoding="utf-8"?><api:response xmlns:api="http://www.symplectic.co.uk/publications/api"><api:version uri="https://mypublications.shef.ac.uk/" elements-version="6.17.0.4095" schema-version="6.13" product-name="myPublications"/><api:request href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254663"/><api:result><api:object category="publication" id="1254663" last-affected-when="2024-04-28T07:07:38.16+01:00" last-modified-when="2024-04-28T07:07:38.16+01:00" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254663" created-when="2019-09-03T05:07:01.33+01:00" type-id="4" type-display-name="Conference proceedings paper" type="conference"><api:privacy-level>Public</api:privacy-level><api:privacy-level-locked>false</api:privacy-level-locked><api:ever-approved>true</api:ever-approved><api:reporting-date-1>2014-07-14</api:reporting-date-1><api:allow-type-switching>true</api:allow-type-switching><api:records><api:record format="native" id="4224911" source-id="28" source-name="eprints" source-display-name="White Rose Research Online" id-at-source="152843" last-modified-when="2022-12-29T15:33:59.37+00:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Adaptation to speaker variations is an essential component of speech recognition systems. One common approach to adapting deep neural network (DNN) acoustic models is to perform global constrained maximum likelihood linear regression (CMLLR) at some point of the systems. Using CMLLR (or more generally, generative approaches) is advantageous especially in unsupervised adaptation scenarios with high baseline error rates. On the other hand, as the DNNs are less sensitive to the increase in the input dimensionality than GMMs, it is becoming more popular to use rich speech representations, such as log mel-filter bank channel outputs, instead of conventional low-dimensional feature vectors, such as MFCCs and PLP coefficients. This work discusses and compares three different configurations of DNN acoustic models that allow CMLLR-based speaker adaptive training (SAT) to be performed in systems with filter bank inputs. Results of unsupervised adaptation experiments conducted on three different data sets are presented, demonstrating that, by choosing an appropriate configuration, SAT with CMLLR can improve the performance of a well-trained filter bank-based speaker independent DNN system by 10.6% relative in a challenging task with a baseline error rate above 40%. It is also shown that the filter bank features are advantageous than the conventional features even when they are used with SAT models. Some other insights are also presented, including the effects of block diagonal transforms and system combination.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Yoshioka</api:last-name><api:initials>T</api:initials><api:first-names>T</api:first-names><api:separate-first-names><api:first-name>T</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>MJF</api:first-names><api:separate-first-names><api:first-name>M</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;SrcApp=PARTNER_APP&amp;SrcAuth=LinksAMR&amp;KeyUT=WOS:000343655306076&amp;DestLinkType=FullRecord&amp;DestApp=ALL_WOS&amp;UsrCustomerID=0bfafa3ff357b450f062b62b10c587b7</api:text></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/icassp.2014.6854825</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/icassp.2014.6854825"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/icassp.2014.6854825"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2379-190X</api:text></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>4</api:day><api:month>5</api:month><api:year>2014</api:year></api:date></api:field><api:field name="isbn-13" type="text" display-name="ISBN-13"><api:text>9781479928934</api:text></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1520-6149</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989137"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>Deep neural network</api:keyword><api:keyword>acoustic model adaptation</api:keyword><api:keyword>hybrid</api:keyword><api:keyword>tandem</api:keyword><api:keyword>stacked hybrid</api:keyword></api:keywords></api:field><api:field name="location" type="text" display-name="Conference place"><api:text>Florence, Italy</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</api:text></api:field><api:field name="notes" type="text" display-name="Other information"><api:text>Â© 2019 IEEE.</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>14</api:day><api:month>7</api:month><api:year>2014</api:year></api:date></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>6344</api:begin-page><api:end-page>6348</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>14</api:day><api:month>7</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="public-url" type="text" display-name="Public URL"><api:text>https://eprints.whiterose.ac.uk/id/eprint/152843</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>IEEE</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>30</api:day><api:month>10</api:month><api:year>2019</api:year></api:date></api:field><api:field name="record-made-public-at-source-date" type="date" display-name="Record made publicly available"><api:date><api:day>13</api:day><api:month>11</api:month><api:year>2019</api:year></api:date></api:field><api:field name="repository-status" type="text" display-name="Availability"><api:text>Public</api:text></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>4</api:day><api:month>5</api:month><api:year>2014</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Investigation of unsupervised adaptation of DNN acoustic models with filter bank input</api:text></api:field></api:native></api:record><api:record format="native" id="3409164" source-id="1" source-name="manual" source-display-name="Manual" id-at-source="E1AE5C52-2840-43EB-8972-54B22A5FEC15" last-modified-when="2019-11-13T10:26:21.957+00:00" is-locked="true"><api:verification-status>verified</api:verification-status><api:verification-comment>13/11/2019 AJ</api:verification-comment><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Adaptation to speaker variations is an essential component of speech recognition systems. One common approach to adapting deep neural network (DNN) acoustic models is to perform global constrained maximum likelihood linear regression (CMLLR) at some point of the systems. Using CMLLR (or more generally, generative approaches) is advantageous especially in unsupervised adaptation scenarios with high baseline error rates. On the other hand, as the DNNs are less sensitive to the increase in the input dimensionality than GMMs, it is becoming more popular to use rich speech representations, such as log mel-filter bank channel outputs, instead of conventional low-dimensional feature vectors, such as MFCCs and PLP coefficients. This work discusses and compares three different configurations of DNN acoustic models that allow CMLLR-based speaker adaptive training (SAT) to be performed in systems with filter bank inputs. Results of unsupervised adaptation experiments conducted on three different data sets are presented, demonstrating that, by choosing an appropriate configuration, SAT with CMLLR can improve the performance of a well-trained filter bank-based speaker independent DNN system by 10.6% relative in a challenging task with a baseline error rate above 40%. It is also shown that the filter bank features are advantageous than the conventional features even when they are used with SAT models. Some other insights are also presented, including the effects of block diagonal transforms and system combination.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Yoshioka</api:last-name><api:initials>T</api:initials><api:first-names>Takuya</api:first-names><api:separate-first-names><api:first-name>Takuya</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="c-goldoa" type="boolean" display-name="Gold Open Access?"><api:boolean>false</api:boolean></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/icassp.2014.6854825</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/icassp.2014.6854825"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/icassp.2014.6854825"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2379-190X</api:text></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>9</api:day><api:month>5</api:month><api:year>2014</api:year></api:date></api:field><api:field name="isbn-13" type="text" display-name="ISBN-13"><api:text>9781479928934</api:text></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1520-6149</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989137"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>Deep neural network</api:keyword><api:keyword>acoustic model adaptation</api:keyword><api:keyword>hybrid</api:keyword><api:keyword>tandem</api:keyword><api:keyword>stacked hybrid</api:keyword></api:keywords></api:field><api:field name="location" type="text" display-name="Conference place"><api:text>Florence, Italy</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>14</api:day><api:month>7</api:month><api:year>2014</api:year></api:date></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>6344</api:begin-page><api:end-page>6348</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>14</api:day><api:month>7</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>IEEE</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>13</api:day><api:month>11</api:month><api:year>2019</api:year></api:date></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>4</api:day><api:month>5</api:month><api:year>2014</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Investigation of unsupervised adaptation of DNN acoustic models with filter bank input</api:text></api:field></api:native></api:record><api:record format="native" id="3348897" source-id="13" source-name="crossref" source-display-name="Crossref" id-at-source="10.1109/icassp.2014.6854825" last-modified-when="2022-09-11T19:21:25.29+01:00"><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Yoshioka</api:last-name><api:initials>T</api:initials><api:first-names>Takuya</api:first-names><api:separate-first-names><api:first-name>Takuya</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/icassp.2014.6854825</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/icassp.2014.6854825"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/icassp.2014.6854825"/></api:links></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>9</api:day><api:month>5</api:month><api:year>2014</api:year></api:date></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>ICASSP 2014 - 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:month>5</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>IEEE</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>http://dx.doi.org/10.1109/icassp.2014.6854825</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>13</api:day><api:month>4</api:month><api:year>2022</api:year></api:date></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>4</api:day><api:month>5</api:month><api:year>2014</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Investigation of unsupervised adaptation of DNN acoustic models with filter bank input</api:text></api:field></api:native></api:record><api:record format="native" id="3347089" source-id="7" source-name="scopus" source-display-name="Scopus" id-at-source="2-s2.0-84905216196" last-modified-when="2024-03-12T12:34:50.323+00:00"><api:citation-count>39</api:citation-count><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Adaptation to speaker variations is an essential component of speech recognition systems. One common approach to adapting deep neural network (DNN) acoustic models is to perform global constrained maximum likelihood linear regression (CMLLR) at some point of the systems. Using CMLLR (or more generally, generative approaches) is advantageous especially in unsupervised adaptation scenarios with high baseline error rates. On the other hand, as the DNNs are less sensitive to the increase in the input dimensionality than GMMs, it is becoming more popular to use rich speech representations, such as log mel-filter bank channel outputs, instead of conventional low-dimensional feature vectors, such as MFCCs and PLP coefficients. This work discusses and compares three different configurations of DNN acoustic models that allow CMLLR-based speaker adaptive training (SAT) to be performed in systems with filter bank inputs. Results of unsupervised adaptation experiments conducted on three different data sets are presented, demonstrating that, by choosing an appropriate configuration, SAT with CMLLR can improve the performance of a well-trained filter bank-based speaker independent DNN system by 10.6% relative in a challenging task with a baseline error rate above 40%. It is also shown that the filter bank features are advantageous than the conventional features even when they are used with SAT models. Some other insights are also presented, including the effects of block diagonal transforms and system combination. Â© 2014 IEEE.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Yoshioka</api:last-name><api:initials>T</api:initials><api:first-names>T</api:first-names><api:separate-first-names><api:first-name>T</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address><api:address iso-country-code="JP"><api:line type="organisation">NTT Communication Science Laboratories</api:line><api:line type="city">Seika</api:line><api:line type="country">Japan</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">18042927200</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">35743526400</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>MJF</api:first-names><api:separate-first-names><api:first-name>M</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">7004447872</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/ICASSP.2014.6854825</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/ICASSP.2014.6854825"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/ICASSP.2014.6854825"/></api:links></api:field><api:field name="isbn-13" type="text" display-name="ISBN-13"><api:text>9781479928927</api:text></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1520-6149</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989137"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>6344</api:begin-page><api:end-page>6348</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>1</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Investigation of unsupervised adaptation of DNN acoustic models with filter bank input</api:text></api:field></api:native></api:record><api:record format="native" id="3348399" source-id="10" source-name="dimensions" source-display-name="Dimensions" id-at-source="pub.1093666199" last-modified-when="2024-04-28T07:07:38.163+01:00"><api:citation-count>34</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Yoshioka</api:last-name><api:initials>T</api:initials><api:first-names>Takuya</api:first-names><api:separate-first-names><api:first-name>Takuya</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address><api:address iso-country-code="JP"><api:line type="organisation">NTT (Japan)</api:line><api:line type="city">Tokyo</api:line><api:line type="country">Japan</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.013257744207.60</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.011072730015.33</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.015135510264.46</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/icassp.2014.6854825</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/icassp.2014.6854825"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/icassp.2014.6854825"/></api:links></api:field><api:field name="field-citation-ratio" type="decimal" display-name="Field citation ratio"><api:decimal>7.83</api:decimal></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword scheme="for-2020">46 Information and Computing Sciences</api:keyword><api:keyword scheme="for-2020">4602 Artificial Intelligence</api:keyword><api:keyword scheme="for-2020">4611 Machine Learning</api:keyword></api:keywords></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</api:text></api:field><api:field name="open-access-status" type="text" display-name="Open access status"><api:text>Closed Access</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>6344</api:begin-page><api:end-page>6348</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>5</api:month><api:year>2014</api:year></api:date></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Institute of Electrical and Electronics Engineers (IEEE)</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>6</api:day><api:month>12</api:month><api:year>2017</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Investigation of Unsupervised Adaptation of DNN Acoustic Models with Filter Bank Input</api:text></api:field></api:native></api:record><api:record format="native" id="3346643" source-id="11" source-name="wos-lite" source-display-name="Web of Science (Lite)" id-at-source="WOS:000343655306076" last-modified-when="2024-03-13T20:55:41.123+00:00"><api:citation-count>0</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Yoshioka</api:last-name><api:initials>T</api:initials><api:first-names>Takuya</api:first-names><api:separate-first-names><api:first-name>Takuya</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>https://www.webofscience.com/api/gateway?GWVersion=2&amp;SrcApp=sheffield_elements_live&amp;SrcAuth=WosAPI&amp;KeyUT=WOS:000343655306076&amp;DestLinkType=FullRecord&amp;DestApp=WOS_CPL</api:text></api:field><api:field name="external-identifiers" type="identifier-list" display-name="External identifiers"><api:identifiers><api:identifier scheme="isidoc">BB5BJ</api:identifier></api:identifiers></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>1520-6149</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989137"/></api:links></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>Deep neural network</api:keyword><api:keyword>acoustic model adaptation</api:keyword><api:keyword>hybrid</api:keyword><api:keyword>tandem</api:keyword><api:keyword>stacked hybrid</api:keyword></api:keywords></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2014</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>INVESTIGATION OF UNSUPERVISED ADAPTATION OF DNN ACOUSTIC MODELS WITH FILTER BANK INPUT</api:text></api:field></api:native></api:record><api:record format="native" id="3349086" source-id="6" source-name="dblp" source-display-name="DBLP" id-at-source="conf/icassp/YoshiokaRG14" last-modified-when="2023-11-21T11:55:05.99+00:00"><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Yoshioka</api:last-name><api:initials>T</api:initials><api:first-names>Takuya</api:first-names><api:separate-first-names><api:first-name>Takuya</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>ICASSP</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>6344</api:begin-page><api:end-page>6348</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2014</api:year></api:date></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>IEEE</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>https://ieeexplore.ieee.org/xpl/conhome/6844297/proceeding</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Investigation of unsupervised adaptation of DNN acoustic models with filter bank input.</api:text></api:field></api:native></api:record></api:records><api:fields/><api:all-labels type="keyword-list"><api:keywords><api:keyword origin="record-data" source="eprints">Deep neural network</api:keyword><api:keyword origin="record-data" source="eprints">acoustic model adaptation</api:keyword><api:keyword origin="record-data" source="eprints">hybrid</api:keyword><api:keyword origin="record-data" source="eprints">tandem</api:keyword><api:keyword origin="record-data" source="eprints">stacked hybrid</api:keyword><api:keyword origin="record-data" source="manual">Deep neural network</api:keyword><api:keyword origin="record-data" source="manual">acoustic model adaptation</api:keyword><api:keyword origin="record-data" source="manual">hybrid</api:keyword><api:keyword origin="record-data" source="manual">tandem</api:keyword><api:keyword origin="record-data" source="manual">stacked hybrid</api:keyword><api:keyword scheme="for-2020" origin="record-data" source="dimensions">46 Information and Computing Sciences</api:keyword><api:keyword scheme="for-2020" origin="record-data" source="dimensions">4602 Artificial Intelligence</api:keyword><api:keyword scheme="for-2020" origin="record-data" source="dimensions">4611 Machine Learning</api:keyword><api:keyword origin="record-data" source="wos-lite">Deep neural network</api:keyword><api:keyword origin="record-data" source="wos-lite">acoustic model adaptation</api:keyword><api:keyword origin="record-data" source="wos-lite">hybrid</api:keyword><api:keyword origin="record-data" source="wos-lite">tandem</api:keyword><api:keyword origin="record-data" source="wos-lite">stacked hybrid</api:keyword></api:keywords></api:all-labels><api:journal issn="1520-6149" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989137" title="Proceedings of the ... IEEE International Conference on Acoustics, Speech, and Signal Processing / sponsored by the Institute of Electrical and Electronics Engineers Signal Processing Society. ICASSP (Conference)"><api:records><api:record source-name="summary"><api:title>Proceedings of the ... IEEE International Conference on Acoustics, Speech, and Signal Processing / sponsored by the Institute of Electrical and Electronics Engineers Signal Processing Society. ICASSP (Conference)</api:title></api:record></api:records></api:journal><api:relationships href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254663/relationships"/></api:object></api:result></api:response>