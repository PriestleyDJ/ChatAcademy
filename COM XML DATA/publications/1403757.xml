<?xml version="1.0" encoding="utf-8"?><api:response xmlns:api="http://www.symplectic.co.uk/publications/api"><api:version uri="https://mypublications.shef.ac.uk/" elements-version="6.17.0.4095" schema-version="6.13" product-name="myPublications"/><api:request href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1403757"/><api:result><api:object category="publication" id="1403757" last-affected-when="2024-04-26T12:55:48.36+01:00" last-modified-when="2024-04-26T12:55:48.36+01:00" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1403757" created-when="2022-04-13T08:40:11.567+01:00" type-id="4" type-display-name="Conference proceedings paper" type="conference"><api:privacy-level>Public</api:privacy-level><api:privacy-level-locked>false</api:privacy-level-locked><api:ever-approved>true</api:ever-approved><api:reporting-date-1>2020-11-01</api:reporting-date-1><api:allow-type-switching>true</api:allow-type-switching><api:records><api:record format="native" id="4238421" source-id="28" source-name="eprints" source-display-name="White Rose Research Online" id-at-source="190602" last-modified-when="2023-01-05T12:30:06.993+00:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Existing NLP datasets contain various biases that models can easily exploit to achieve high performances on the corresponding evaluation sets. However, focusing on dataset-specific biases limits their ability to learn more generalizable knowledge about the task from more general data patterns. In this paper, we investigate the impact of debiasing methods for improving generalization and propose a general framework for improving the performance on both in-domain and out-of-domain datasets by concurrent modeling of multiple biases in the training data. Our framework weights each example based on the biases it contains and the strength of those biases in the training data. It then uses these weights in the training objective so that the model relies less on examples with high bias weights. We extensively evaluate our framework on extractive question answering with training data from various domains with multiple biases of different strengths. We perform the evaluations in two different settings, in which the model is trained on a single domain or multiple domains simultaneously, and show its effectiveness in both settings compared to state-of-the-art debiasing methods.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Wu</api:last-name><api:initials>M</api:initials><api:first-names>M</api:first-names><api:separate-first-names><api:first-name>M</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="34156" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/34156"/></api:links><api:last-name>Moosavi</api:last-name><api:initials>NS</api:initials><api:first-names>NS</api:first-names><api:separate-first-names><api:first-name>N</api:first-name><api:first-name>S</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Rücklé</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gurevych</api:last-name><api:initials>I</api:initials><api:first-names>I</api:first-names><api:separate-first-names><api:first-name>I</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.18653/v1/2020.findings-emnlp.74</api:text><api:links><api:link type="doi" href="http://doi.org/10.18653/v1/2020.findings-emnlp.74"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.18653/v1/2020.findings-emnlp.74"/></api:links></api:field><api:field name="editors" type="person-list" display-name="Editors"><api:people><api:person><api:last-name>Cohn</api:last-name><api:initials>T</api:initials><api:first-names>T</api:first-names><api:separate-first-names><api:first-name>T</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>He</api:last-name><api:initials>Y</api:initials><api:first-names>Y</api:first-names><api:separate-first-names><api:first-name>Y</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Liu</api:last-name><api:initials>Y</api:initials><api:first-names>Y</api:first-names><api:separate-first-names><api:first-name>Y</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>16</api:day><api:month>11</api:month><api:year>2020</api:year></api:date></api:field><api:field name="isbn-13" type="text" display-name="ISBN-13"><api:text>9781952148903</api:text></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Findings of the Association for Computational Linguistics: EMNLP 2020</api:text></api:field><api:field name="location" type="text" display-name="Conference place"><api:text>Online</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>2020 Conference on Empirical Methods in Natural Language Processing (EMNLP 2020)</api:text></api:field><api:field name="notes" type="text" display-name="Other information"><api:text>© 2020 Association for Computational Linguistics. Available under a Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/).</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:month>11</api:month><api:year>2020</api:year></api:date></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>839</api:begin-page><api:end-page>853</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:month>11</api:month><api:year>2020</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="public-url" type="text" display-name="Public URL"><api:text>https://eprints.whiterose.ac.uk/id/eprint/190602</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Association for Computational Linguistics</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>2</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="record-made-public-at-source-date" type="date" display-name="Record made publicly available"><api:date><api:day>7</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="repository-status" type="text" display-name="Availability"><api:text>Public</api:text></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>16</api:day><api:month>11</api:month><api:year>2020</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Improving QA generalization by concurrent modeling of multiple biases</api:text></api:field><api:files><api:file proprietary-id="https://eprints.whiterose.ac.uk/id/file/6044251"><api:filename>2020.findings-emnlp.74.pdf</api:filename><api:file-url>https://eprints.whiterose.ac.uk/190602/1/2020.findings-emnlp.74.pdf</api:file-url><api:extension>pdf</api:extension><api:file-size>548352</api:file-size><api:mime-type>application/pdf</api:mime-type><api:checksum algorithm="md5">75F554E7689E6A87CDD554CA0CF4FCBE</api:checksum><api:file-version>Published version</api:file-version></api:file></api:files></api:native></api:record><api:record format="native" id="3819102" source-id="13" source-name="crossref" source-display-name="Crossref" id-at-source="10.18653/v1/2020.findings-emnlp.74" last-modified-when="2022-09-10T23:58:17.26+01:00"><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Wu</api:last-name><api:initials>M</api:initials><api:first-names>Mingzhu</api:first-names><api:separate-first-names><api:first-name>Mingzhu</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="34156" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/34156"/></api:links><api:last-name>Moosavi</api:last-name><api:initials>NS</api:initials><api:first-names>Nafise Sadat</api:first-names><api:separate-first-names><api:first-name>Nafise</api:first-name><api:first-name>Sadat</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Rücklé</api:last-name><api:initials>A</api:initials><api:first-names>Andreas</api:first-names><api:separate-first-names><api:first-name>Andreas</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gurevych</api:last-name><api:initials>I</api:initials><api:first-names>Iryna</api:first-names><api:separate-first-names><api:first-name>Iryna</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.18653/v1/2020.findings-emnlp.74</api:text><api:links><api:link type="doi" href="http://doi.org/10.18653/v1/2020.findings-emnlp.74"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.18653/v1/2020.findings-emnlp.74"/></api:links></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:month>11</api:month><api:year>2020</api:year></api:date></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Findings of the Association for Computational Linguistics: EMNLP 2020</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>Findings of the Association for Computational Linguistics: EMNLP 2020</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2020</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Association for Computational Linguistics</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>http://dx.doi.org/10.18653/v1/2020.findings-emnlp.74</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>29</api:day><api:month>11</api:month><api:year>2020</api:year></api:date></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:month>11</api:month><api:year>2020</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Improving QA Generalization by Concurrent Modeling of Multiple Biases</api:text></api:field></api:native></api:record><api:record format="native" id="3868571" source-id="7" source-name="scopus" source-display-name="Scopus" id-at-source="2-s2.0-85110812570" last-modified-when="2024-04-26T12:55:48.363+01:00"><api:citation-count>5</api:citation-count><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Existing NLP datasets contain various biases that models can easily exploit to achieve high performances on the corresponding evaluation sets. However, focusing on dataset-specific biases limits their ability to learn more generalizable knowledge about the task from more general data patterns. In this paper, we investigate the impact of debiasing methods for improving generalization and propose a general framework for improving the performance on both in-domain and out-of-domain datasets by concurrent modeling of multiple biases in the training data. Our framework weights each example based on the biases it contains and the strength of those biases in the training data. It then uses these weights in the training objective so that the model relies less on examples with high bias weights. We extensively evaluate our framework on extractive question answering with training data from various domains with multiple biases of different strengths. We perform the evaluations in two different settings, in which the model is trained on a single domain or multiple domains simultaneously, and show its effectiveness in both settings compared to state-of-the-art debiasing methods.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Wu</api:last-name><api:initials>M</api:initials><api:first-names>M</api:first-names><api:separate-first-names><api:first-name>M</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="DE"><api:line type="organisation">Technische Universität Darmstadt</api:line><api:line type="city">Darmstadt</api:line><api:line type="country">Germany</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">57221152476</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="34156" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/34156"/></api:links><api:last-name>Moosavi</api:last-name><api:initials>NS</api:initials><api:first-names>NS</api:first-names><api:separate-first-names><api:first-name>N</api:first-name><api:first-name>S</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="DE"><api:line type="organisation">Technische Universität Darmstadt</api:line><api:line type="city">Darmstadt</api:line><api:line type="country">Germany</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">36968334800</api:identifier></api:identifiers></api:person><api:person><api:last-name>Rücklé</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="DE"><api:line type="organisation">Technische Universität Darmstadt</api:line><api:line type="city">Darmstadt</api:line><api:line type="country">Germany</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">57201683636</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gurevych</api:last-name><api:initials>I</api:initials><api:first-names>I</api:first-names><api:separate-first-names><api:first-name>I</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="DE"><api:line type="organisation">Technische Universität Darmstadt</api:line><api:line type="city">Darmstadt</api:line><api:line type="country">Germany</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">24474583400</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Findings of the Association for Computational Linguistics Findings of ACL: EMNLP 2020</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>839</api:begin-page><api:end-page>853</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>1</api:month><api:year>2020</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Improving QA generalization by concurrent modeling of multiple biases</api:text></api:field></api:native></api:record><api:record format="native" id="3819109" source-id="10" source-name="dimensions" source-display-name="Dimensions" id-at-source="pub.1133174905" last-modified-when="2022-11-23T08:45:31.497+00:00"><api:citation-count>2</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Wu</api:last-name><api:initials>M</api:initials><api:first-names>Mingzhu</api:first-names><api:separate-first-names><api:first-name>Mingzhu</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.014721412435.20</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="34156" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/34156"/></api:links><api:last-name>Moosavi</api:last-name><api:initials>NS</api:initials><api:first-names>Nafise Sadat</api:first-names><api:separate-first-names><api:first-name>Nafise</api:first-name><api:first-name>Sadat</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.012671231645.43</api:identifier></api:identifiers></api:person><api:person><api:last-name>Rücklé</api:last-name><api:initials>A</api:initials><api:first-names>Andreas</api:first-names><api:separate-first-names><api:first-name>Andreas</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.011720331307.66</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gurevych</api:last-name><api:initials>I</api:initials><api:first-names>Iryna</api:first-names><api:separate-first-names><api:first-name>Iryna</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.015772501417.70</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.18653/v1/2020.findings-emnlp.74</api:text><api:links><api:link type="doi" href="http://doi.org/10.18653/v1/2020.findings-emnlp.74"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.18653/v1/2020.findings-emnlp.74"/></api:links></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>Findings of the Association for Computational Linguistics: EMNLP 2020</api:text></api:field><api:field name="open-access-status" type="text" display-name="Open access status"><api:text>Hybrid OA</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>839</api:begin-page><api:end-page>853</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>1</api:month><api:year>2020</api:year></api:date></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Association for Computational Linguistics (ACL)</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>7</api:day><api:month>12</api:month><api:year>2020</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Improving QA Generalization by Concurrent Modeling of Multiple Biases</api:text></api:field></api:native></api:record></api:records><api:fields/><api:relationships href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1403757/relationships"/></api:object></api:result></api:response>