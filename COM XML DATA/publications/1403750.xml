<?xml version="1.0" encoding="utf-8"?><api:response xmlns:api="http://www.symplectic.co.uk/publications/api"><api:version uri="https://mypublications.shef.ac.uk/" elements-version="6.17.0.4095" schema-version="6.13" product-name="myPublications"/><api:request href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1403750"/><api:result><api:object category="publication" id="1403750" last-affected-when="2024-04-26T18:18:45.283+01:00" last-modified-when="2024-04-26T18:18:45.283+01:00" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1403750" created-when="2022-04-13T08:40:10.317+01:00" type-id="4" type-display-name="Conference proceedings paper" type="conference"><api:privacy-level>Public</api:privacy-level><api:privacy-level-locked>false</api:privacy-level-locked><api:ever-approved>true</api:ever-approved><api:reporting-date-1>2020-07-01</api:reporting-date-1><api:allow-type-switching>true</api:allow-type-switching><api:records><api:record format="native" id="4238420" source-id="28" source-name="eprints" source-display-name="White Rose Research Online" id-at-source="190601" last-modified-when="2023-01-05T12:30:04.047+00:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Models for natural language understanding (NLU) tasks often rely on the idiosyncratic biases of the dataset, which make them brittle against test cases outside the training distribution. Recently, several proposed debiasing methods are shown to be very effective in improving out-of-distribution performance. However, their improvements come at the expense of performance drop when models are evaluated on the in-distribution data, which contain examples with higher diversity. This seemingly inevitable trade-off may not tell us much about the changes in the reasoning and understanding capabilities of the resulting models on broader types of examples beyond the small subset represented in the out-of-distribution data. In this paper, we address this trade-off by introducing a novel debiasing method, called confidence regularization, which discourage models from exploiting biases while enabling them to receive enough incentive to learn from all the training examples. We evaluate our method on three NLU tasks and show that, in contrast to its predecessors, it improves the performance on out-of-distribution datasets (e.g., 7pp gain on HANS dataset) while maintaining the original in-distribution accuracy.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Utama</api:last-name><api:initials>PA</api:initials><api:first-names>PA</api:first-names><api:separate-first-names><api:first-name>P</api:first-name><api:first-name>A</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="34156" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/34156"/></api:links><api:last-name>Moosavi</api:last-name><api:initials>NS</api:initials><api:first-names>NS</api:first-names><api:separate-first-names><api:first-name>N</api:first-name><api:first-name>S</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gurevych</api:last-name><api:initials>I</api:initials><api:first-names>I</api:first-names><api:separate-first-names><api:first-name>I</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.18653/v1/2020.acl-main.770</api:text><api:links><api:link type="doi" href="http://doi.org/10.18653/v1/2020.acl-main.770"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.18653/v1/2020.acl-main.770"/></api:links></api:field><api:field name="editors" type="person-list" display-name="Editors"><api:people><api:person><api:last-name>Jurafsky</api:last-name><api:initials>D</api:initials><api:first-names>D</api:first-names><api:separate-first-names><api:first-name>D</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Chai</api:last-name><api:initials>J</api:initials><api:first-names>J</api:first-names><api:separate-first-names><api:first-name>J</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Schluter</api:last-name><api:initials>N</api:initials><api:first-names>N</api:first-names><api:separate-first-names><api:first-name>N</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Tetreault</api:last-name><api:initials>J</api:initials><api:first-names>J</api:first-names><api:separate-first-names><api:first-name>J</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:day>5</api:day><api:month>7</api:month><api:year>2020</api:year></api:date></api:field><api:field name="isbn-13" type="text" display-name="ISBN-13"><api:text>9781952148255</api:text></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL 2020)</api:text></api:field><api:field name="location" type="text" display-name="Conference place"><api:text>Online</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>58th Annual Meeting of the Association for Computational Linguistics (ACL 2020)</api:text></api:field><api:field name="notes" type="text" display-name="Other information"><api:text>© 2020 Association for Computational Linguistics. Available under a Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/).</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:month>7</api:month><api:year>2020</api:year></api:date></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>8717</api:begin-page><api:end-page>8729</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:month>7</api:month><api:year>2020</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="public-url" type="text" display-name="Public URL"><api:text>https://eprints.whiterose.ac.uk/id/eprint/190601</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Association for Computational Linguistics</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>2</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="record-made-public-at-source-date" type="date" display-name="Record made publicly available"><api:date><api:day>7</api:day><api:month>9</api:month><api:year>2022</api:year></api:date></api:field><api:field name="repository-status" type="text" display-name="Availability"><api:text>Public</api:text></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:day>5</api:day><api:month>7</api:month><api:year>2020</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Mind the trade-off: debiasing NLU models without degrading the in-distribution performance</api:text></api:field><api:files><api:file proprietary-id="https://eprints.whiterose.ac.uk/id/file/6043440"><api:filename>2020.acl-main.770.pdf</api:filename><api:file-url>https://eprints.whiterose.ac.uk/190601/1/2020.acl-main.770.pdf</api:file-url><api:extension>pdf</api:extension><api:file-size>662209</api:file-size><api:mime-type>application/pdf</api:mime-type><api:checksum algorithm="md5">BA0C390079FC94C642D13B78CF19D48F</api:checksum><api:file-version>Published version</api:file-version></api:file></api:files></api:native></api:record><api:record format="native" id="3819095" source-id="13" source-name="crossref" source-display-name="Crossref" id-at-source="10.18653/v1/2020.acl-main.770" last-modified-when="2022-09-10T23:58:14.62+01:00"><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Utama</api:last-name><api:initials>PA</api:initials><api:first-names>Prasetya Ajie</api:first-names><api:separate-first-names><api:first-name>Prasetya</api:first-name><api:first-name>Ajie</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="34156" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/34156"/></api:links><api:last-name>Moosavi</api:last-name><api:initials>NS</api:initials><api:first-names>Nafise Sadat</api:first-names><api:separate-first-names><api:first-name>Nafise</api:first-name><api:first-name>Sadat</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gurevych</api:last-name><api:initials>I</api:initials><api:first-names>Iryna</api:first-names><api:separate-first-names><api:first-name>Iryna</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.18653/v1/2020.acl-main.770</api:text><api:links><api:link type="doi" href="http://doi.org/10.18653/v1/2020.acl-main.770"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.18653/v1/2020.acl-main.770"/></api:links></api:field><api:field name="finish-date" type="date" display-name="Conference finish date"><api:date><api:month>7</api:month><api:year>2020</api:year></api:date></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</api:text></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2020</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Association for Computational Linguistics</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>http://dx.doi.org/10.18653/v1/2020.acl-main.770</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>29</api:day><api:month>7</api:month><api:year>2020</api:year></api:date></api:field><api:field name="start-date" type="date" display-name="Conference start date"><api:date><api:month>7</api:month><api:year>2020</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Mind the Trade-off: Debiasing NLU Models without Degrading the In-distribution Performance</api:text></api:field></api:native></api:record><api:record format="native" id="4277960" source-id="7" source-name="scopus" source-display-name="Scopus" id-at-source="2-s2.0-85095314664" last-modified-when="2024-04-26T18:18:45.29+01:00"><api:citation-count>59</api:citation-count><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Models for natural language understanding (NLU) tasks often rely on the idiosyncratic biases of the dataset, which make them brittle against test cases outside the training distribution. Recently, several proposed debiasing methods are shown to be very effective in improving out-of-distribution performance. However, their improvements come at the expense of performance drop when models are evaluated on the in-distribution data, which contain examples with higher diversity. This seemingly inevitable trade-off may not tell us much about the changes in the reasoning and understanding capabilities of the resulting models on broader types of examples beyond the small subset represented in the out-of-distribution data. In this paper, we address this trade-off by introducing a novel debiasing method, called confidence regularization, which discourage models from exploiting biases while enabling them to receive enough incentive to learn from all the training examples. We evaluate our method on three NLU tasks and show that, in contrast to its predecessors, it improves the performance on out-of-distribution datasets (e.g., 7pp gain on HANS dataset) while maintaining the original in-distribution accuracy.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Utama</api:last-name><api:initials>PA</api:initials><api:first-names>PA</api:first-names><api:separate-first-names><api:first-name>P</api:first-name><api:first-name>A</api:first-name></api:separate-first-names><api:addresses><api:address><api:line type="organisation">Research Training Group</api:line></api:address><api:address iso-country-code="DE"><api:line type="organisation">Technische Universität Darmstadt</api:line><api:line type="city">Darmstadt</api:line><api:line type="country">Germany</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">57188985621</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="34156" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/34156"/></api:links><api:last-name>Moosavi</api:last-name><api:initials>NS</api:initials><api:first-names>NS</api:first-names><api:separate-first-names><api:first-name>N</api:first-name><api:first-name>S</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="DE"><api:line type="organisation">Technische Universität Darmstadt</api:line><api:line type="city">Darmstadt</api:line><api:line type="country">Germany</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">36968334800</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gurevych</api:last-name><api:initials>I</api:initials><api:first-names>I</api:first-names><api:separate-first-names><api:first-name>I</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="DE"><api:line type="organisation">Technische Universität Darmstadt</api:line><api:line type="city">Darmstadt</api:line><api:line type="country">Germany</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">24474583400</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>0736-587X</api:text></api:field><api:field name="journal" type="text" display-name="Title of published proceedings"><api:text>Proceedings of the Annual Meeting of the Association for Computational Linguistics</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>8717</api:begin-page><api:end-page>8729</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>1</api:month><api:year>2020</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Mind the trade-off: Debiasing NLU models without degrading the in-distribution performance</api:text></api:field></api:native></api:record><api:record format="native" id="3819110" source-id="10" source-name="dimensions" source-display-name="Dimensions" id-at-source="pub.1129757408" last-modified-when="2024-04-24T08:59:04.767+01:00"><api:citation-count>17</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Utama</api:last-name><api:initials>PA</api:initials><api:first-names>Prasetya Ajie</api:first-names><api:separate-first-names><api:first-name>Prasetya</api:first-name><api:first-name>Ajie</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.014310101400.46</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="34156" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/34156"/></api:links><api:last-name>Moosavi</api:last-name><api:initials>NS</api:initials><api:first-names>Nafise Sadat</api:first-names><api:separate-first-names><api:first-name>Nafise</api:first-name><api:first-name>Sadat</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.012671231645.43</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gurevych</api:last-name><api:initials>I</api:initials><api:first-names>Iryna</api:first-names><api:separate-first-names><api:first-name>Iryna</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.015772501417.70</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.18653/v1/2020.acl-main.770</api:text><api:links><api:link type="doi" href="http://doi.org/10.18653/v1/2020.acl-main.770"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.18653/v1/2020.acl-main.770"/></api:links></api:field><api:field name="name-of-conference" type="text" display-name="Name of conference"><api:text>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</api:text></api:field><api:field name="open-access-status" type="text" display-name="Open access status"><api:text>Hybrid OA</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>8717</api:begin-page><api:end-page>8729</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>1</api:month><api:year>2020</api:year></api:date></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Association for Computational Linguistics (ACL)</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>31</api:day><api:month>7</api:month><api:year>2020</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Mind the Trade-off: Debiasing NLU Models without Degrading the In-distribution Performance</api:text></api:field></api:native></api:record></api:records><api:fields/><api:relationships href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1403750/relationships"/></api:object></api:result></api:response>