<?xml version="1.0" encoding="utf-8"?><api:response xmlns:api="http://www.symplectic.co.uk/publications/api"><api:version uri="https://mypublications.shef.ac.uk/" elements-version="6.17.0.4095" schema-version="6.13" product-name="myPublications"/><api:request href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/93785"/><api:result><api:object category="publication" id="93785" last-affected-when="2024-04-29T19:59:42.76+01:00" last-modified-when="2024-04-29T19:59:42.76+01:00" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/93785" created-when="2011-01-26T17:38:42.577+00:00" type-id="3" type-display-name="Chapter" type="chapter"><api:privacy-level>Public</api:privacy-level><api:privacy-level-locked>false</api:privacy-level-locked><api:ever-approved>true</api:ever-approved><api:reporting-date-1>2010-12-01</api:reporting-date-1><api:allow-type-switching>true</api:allow-type-switching><api:records><api:record format="native" id="3224070" source-id="13" source-name="crossref" source-display-name="Crossref" id-at-source="10.4018/978-1-61520-725-1.ch006" last-modified-when="2022-09-11T00:35:39.96+01:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>&lt;jats:p&gt;For an individual with a speech impairment, it can be necessary for them to use a device to produce synthesized speech to assist their communication. To fully support all functions of human speech communication: communication of information, maintenance of social relationships and displaying identity, the voice must be intelligible and natural-sounding. Ideally, it must also be capable of conveying the speaker’s vocal identity. A new approach based on Hidden Markov models (HMMs) has been proposed as a way of capturing sufficient information about an individual’s speech to enable a personalized speech synthesizer to be developed. This approach adapts a statistical model of speech towards the vocal characteristics of an individual. This chapter describes this approach and how it can be implemented using the HTS toolkit. Results are reported from a study that built personalized synthetic voices for two individuals with dysarthria. An evaluation of the voices by the participants themselves suggests that this technique shows promise for building personalized voices for individuals with progressive dysarthria even when their speech has begun to deteriorate.&lt;/jats:p&gt;</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors of chapter"><api:people><api:person><api:last-name>Creer</api:last-name><api:initials>S</api:initials><api:first-names>Sarah</api:first-names><api:separate-first-names><api:first-name>Sarah</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="2031" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/2031"/></api:links><api:last-name>Green</api:last-name><api:initials>P</api:initials><api:first-names>Phil</api:first-names><api:separate-first-names><api:first-name>Phil</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="1102" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1102"/></api:links><api:last-name>Cunningham</api:last-name><api:initials>S</api:initials><api:first-names>Stuart</api:first-names><api:separate-first-names><api:first-name>Stuart</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Yamagishi</api:last-name><api:initials>J</api:initials><api:first-names>Junichi</api:first-names><api:separate-first-names><api:first-name>Junichi</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.4018/978-1-61520-725-1.ch006</api:text><api:links><api:link type="doi" href="http://doi.org/10.4018/978-1-61520-725-1.ch006"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.4018/978-1-61520-725-1.ch006"/></api:links></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>92</api:begin-page><api:end-page>115</api:end-page></api:pagination></api:field><api:field name="parent-title" type="text" display-name="Book title"><api:text>Computer Synthesized Speech Technologies</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>IGI Global</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>http://dx.doi.org/10.4018/978-1-61520-725-1.ch006</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>19</api:day><api:month>11</api:month><api:year>2018</api:year></api:date></api:field><api:field name="title" type="text" display-name="Chapter title"><api:text>Building Personalized Synthetic Voices for Individuals with Dysarthria using the HTS Toolkit</api:text></api:field></api:native></api:record><api:record format="native" id="830884" source-id="7" source-name="scopus" source-display-name="Scopus" id-at-source="2-s2.0-77953693885" last-modified-when="2023-07-04T18:56:39.457+01:00"><api:citation-count>11</api:citation-count><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>For an individual with a speech impairment, it can be necessary for them to use a device to produce synthesized speech to assist their communication. To fully support all functions of human speech communication: communication of information, maintenance of social relationships and displaying identity, the voice must be intelligible and natural-sounding. Ideally, it must also be capable of conveying the speaker's vocal identity. A new approach based on Hidden Markov models (HMMs) has been proposed as a way of capturing sufficient information about an individual's speech to enable a personalized speech synthesizer to be developed. This approach adapts a statistical model of speech towards the vocal characteristics of an individual. This chapter describes this approach and how it can be implemented using the HTS toolkit. Results are reported from a study that built personalized synthetic voices for two individuals with dysarthria. An evaluation of the voices by the participants themselves suggests that this technique shows promise for building personalized voices for individuals with progressive dysarthria even when their speech has begun to deteriorate. © 2010, IGI Global.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors of chapter"><api:people><api:person><api:last-name>Creer</api:last-name><api:initials>S</api:initials><api:first-names>S</api:first-names><api:separate-first-names><api:first-name>S</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">The University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">35179021600</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="2031" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/2031"/></api:links><api:last-name>Green</api:last-name><api:initials>P</api:initials><api:first-names>P</api:first-names><api:separate-first-names><api:first-name>P</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">The University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">7402935470</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="1102" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1102"/></api:links><api:last-name>Cunningham</api:last-name><api:initials>S</api:initials><api:first-names>S</api:first-names><api:separate-first-names><api:first-name>S</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">The University of Sheffield</api:line><api:line type="city">Sheffield</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">57561110900</api:identifier></api:identifiers></api:person><api:person><api:last-name>Yamagishi</api:last-name><api:initials>J</api:initials><api:first-names>J</api:first-names><api:separate-first-names><api:first-name>J</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">The University of Edinburgh</api:line><api:line type="city">Edinburgh</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">7004695833</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.4018/978-1-61520-725-1.ch006</api:text><api:links><api:link type="doi" href="http://doi.org/10.4018/978-1-61520-725-1.ch006"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.4018/978-1-61520-725-1.ch006"/></api:links></api:field><api:field name="isbn-13" type="text" display-name="Print ISBN-13"><api:text>9781615207251</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>92</api:begin-page><api:end-page>115</api:end-page></api:pagination></api:field><api:field name="parent-title" type="text" display-name="Book title"><api:text>Computer Synthesized Speech Technologies: Tools for Aiding Impairment</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>12</api:month><api:year>2010</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Chapter title"><api:text>Building personalized synthetic voices for individuals with dysarthria using the HTS toolkit</api:text></api:field></api:native></api:record><api:record format="native" id="147247" source-id="1" source-name="manual" source-display-name="Manual" id-at-source="B0EC3968-C666-4B29-8282-D0862F7A16FB" last-modified-when="2014-08-14T23:58:00.287+01:00"><api:verification-status>unverified</api:verification-status><api:native><api:field name="authors" type="person-list" display-name="Authors of chapter"><api:people><api:person><api:last-name>Creer</api:last-name><api:initials>S</api:initials><api:first-names>S</api:first-names><api:separate-first-names><api:first-name>S</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="2031" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/2031"/></api:links><api:last-name>Green</api:last-name><api:initials>PD</api:initials><api:first-names>PD</api:first-names><api:separate-first-names><api:first-name>P</api:first-name><api:first-name>D</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="1102" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/1102"/></api:links><api:last-name>Cunningham</api:last-name><api:initials>SP</api:initials><api:first-names>SP</api:first-names><api:separate-first-names><api:first-name>S</api:first-name><api:first-name>P</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Yamagishi</api:last-name><api:initials>J</api:initials><api:first-names>J</api:first-names><api:separate-first-names><api:first-name>J</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="editors" type="person-list" display-name="Editors of book"><api:people><api:person><api:last-name>Mullennix</api:last-name><api:initials>JW</api:initials><api:first-names>JW</api:first-names><api:separate-first-names><api:first-name>J</api:first-name><api:first-name>W</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Stern</api:last-name><api:initials>SE</api:initials><api:first-names>SE</api:first-names><api:separate-first-names><api:first-name>S</api:first-name><api:first-name>E</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="number" type="text" display-name="Chapter number"><api:text>6</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>92</api:begin-page><api:end-page>115</api:end-page><api:page-count>23</api:page-count></api:pagination></api:field><api:field name="parent-title" type="text" display-name="Book title"><api:text>Computer Synthesized Speech Technologies: tools for aiding impairment</api:text></api:field><api:field name="place-of-publication" type="text" display-name="Place of publication"><api:text>Hershey, PA</api:text></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2010</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>IGI Global</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>26</api:day><api:month>1</api:month><api:year>2011</api:year></api:date></api:field><api:field name="title" type="text" display-name="Chapter title"><api:text>Building personalized synthetic voices for individuals with dysarthria using the HTS toolkit</api:text></api:field></api:native></api:record></api:records><api:fields/><api:relationships href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/93785/relationships"/></api:object></api:result></api:response>