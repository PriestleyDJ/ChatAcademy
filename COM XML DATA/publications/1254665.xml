<?xml version="1.0" encoding="utf-8"?><api:response xmlns:api="http://www.symplectic.co.uk/publications/api"><api:version uri="https://mypublications.shef.ac.uk/" elements-version="6.17.0.4095" schema-version="6.13" product-name="myPublications"/><api:request href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254665"/><api:result><api:object category="publication" id="1254665" last-affected-when="2024-04-28T07:05:23.32+01:00" last-modified-when="2024-04-28T07:05:23.32+01:00" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254665" created-when="2019-09-03T05:07:01.887+01:00" type-id="5" type-display-name="Journal article" type="journal-article"><api:privacy-level>Public</api:privacy-level><api:privacy-level-locked>false</api:privacy-level-locked><api:ever-approved>true</api:ever-approved><api:reporting-date-1>2019-09-01</api:reporting-date-1><api:allow-type-switching>true</api:allow-type-switching><api:records><api:record format="native" id="4224072" source-id="28" source-name="eprints" source-display-name="White Rose Research Online" id-at-source="150520" last-modified-when="2022-12-29T14:52:07.777+00:00"><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Language modeling is a crucial component in a wide range of applications including speech recognition. Language models (LMs) are usually constructed by splitting a sentence into words and computing the probability of a word based on its word history. This sentence probability calculation, making use of conditional probability distributions, assumes that there is little impact from approximations used in the LMs, including the word history representations and finite training data. This motivates examining models that make use of additional information from the sentence. In this paper, future word information, in addition to the history, is used to predict the probability of the current word. For recurrent neural network LMs (RNNLMs), this information can be encapsulated in a bi-directional model. However, if used directly, this form of model is computationally expensive when trained on large quantities of data, and can be problematic when used with word lattices. This paper proposes a novel neural network language model structure, the succeeding-word RNNLM, su-RNNLM, to address these issues. Instead of using a recurrent unit to capture the complete future word contexts, a feedforward unit is used to model a fixed finite number of succeeding words. This is more efficient in training than bi-directional models and can be applied to lattice rescoring. The generated lattices can be used for downstream applications, such as confusion network decoding and keyword search. Experimental results on speech recognition and keyword spotting tasks illustrate the empirical usefulness of future word information, and the flexibility of the proposed model to represent this information.</api:text></api:field><api:field name="acceptance-date" type="date" display-name="Date of acceptance"><api:date><api:day>27</api:day><api:month>5</api:month><api:year>2019</api:year></api:date></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Chen</api:last-name><api:initials>X</api:initials><api:first-names>X</api:first-names><api:separate-first-names><api:first-name>X</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Liu</api:last-name><api:initials>X</api:initials><api:first-names>X</api:first-names><api:separate-first-names><api:first-name>X</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Wang</api:last-name><api:initials>Y</api:initials><api:first-names>Y</api:first-names><api:separate-first-names><api:first-name>Y</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Wong</api:last-name><api:initials>JHM</api:initials><api:first-names>JHM</api:first-names><api:separate-first-names><api:first-name>J</api:first-name><api:first-name>H</api:first-name><api:first-name>M</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>MJF</api:first-names><api:separate-first-names><api:first-name>M</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;SrcApp=PARTNER_APP&amp;SrcAuth=LinksAMR&amp;KeyUT=WOS:000473469800004&amp;DestLinkType=FullRecord&amp;DestApp=ALL_WOS&amp;UsrCustomerID=0bfafa3ff357b450f062b62b10c587b7</api:text></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/taslp.2019.2922048</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/taslp.2019.2922048"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/taslp.2019.2922048"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2329-9304</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989238"/></api:links></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2329-9290</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989238"/></api:links></api:field><api:field name="issue" type="text" display-name="Issue"><api:text>9</api:text></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>IEEE/ACM Transactions on Audio, Speech, and Language Processing</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>Recurrent neural network</api:keyword><api:keyword>language model</api:keyword><api:keyword>succeeding words</api:keyword><api:keyword>speech recognition</api:keyword><api:keyword>keyword search</api:keyword></api:keywords></api:field><api:field name="notes" type="text" display-name="Other information"><api:text>Â© 2019 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other users, including reprinting/ republishing this material for advertising or promotional purposes, creating new collective works for resale or redistribution to servers or lists, or reuse of any copyrighted components of this work in other works. Reproduced in accordance with the publisher's self-archiving policy.</api:text></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>11</api:day><api:month>6</api:month><api:year>2019</api:year></api:date></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1444</api:begin-page><api:end-page>1454</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:month>9</api:month><api:year>2019</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="public-url" type="text" display-name="Public URL"><api:text>https://eprints.whiterose.ac.uk/id/eprint/150520</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Institute of Electrical and Electronics Engineers (IEEE)</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>5</api:day><api:month>9</api:month><api:year>2019</api:year></api:date></api:field><api:field name="record-made-public-at-source-date" type="date" display-name="Record made publicly available"><api:date><api:day>5</api:day><api:month>9</api:month><api:year>2019</api:year></api:date></api:field><api:field name="repository-status" type="text" display-name="Availability"><api:text>Public</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Exploiting future word contexts in neural network language models for speech recognition</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>27</api:text></api:field><api:files><api:file proprietary-id="https://eprints.whiterose.ac.uk/id/file/3872444"><api:filename>article.pdf</api:filename><api:file-url>https://eprints.whiterose.ac.uk/150520/1/article.pdf</api:file-url><api:extension>pdf</api:extension><api:file-size>1059742</api:file-size><api:mime-type>application/pdf</api:mime-type><api:checksum algorithm="md5">F94AB8B839BBD0BCB65379D523D11DBF</api:checksum><api:file-version>Author accepted manuscript</api:file-version></api:file></api:files></api:native></api:record><api:record format="native" id="3352402" source-id="1" source-name="manual" source-display-name="Manual" id-at-source="A79492CD-BE3F-4706-B9CA-07667B7194B9" last-modified-when="2019-09-05T14:47:34.223+01:00" is-locked="true"><api:verification-status>verified</api:verification-status><api:verification-comment>5/9/2019 AJ</api:verification-comment><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Language modeling is a crucial component in a wide range of applications including speech recognition. Language models (LMs) are usually constructed by splitting a sentence into words and computing the probability of a word based on its word history. This sentence probability calculation, making use of conditional probability distributions, assumes that there is little impact from approximations used in the LMs, including the word history representations and finite training data. This motivates examining models that make use of additional information from the sentence. In this paper, future word information, in addition to the history, is used to predict the probability of the current word. For recurrent neural network LMs (RNNLMs), this information can be encapsulated in a bi-directional model. However, if used directly, this form of model is computationally expensive when trained on large quantities of data, and can be problematic when used with word lattices. This paper proposes a novel neural network language model structure, the succeeding-word RNNLM, su-RNNLM, to address these issues. Instead of using a recurrent unit to capture the complete future word contexts, a feedforward unit is used to model a fixed finite number of succeeding words. This is more efficient in training than bi-directional models and can be applied to lattice rescoring. The generated lattices can be used for downstream applications, such as confusion network decoding and keyword search. Experimental results on speech recognition and keyword spotting tasks illustrate the empirical usefulness of future word information, and the flexibility of the proposed model to represent this information.</api:text></api:field><api:field name="acceptance-date" type="date" display-name="Date of acceptance"><api:date><api:day>27</api:day><api:month>5</api:month><api:year>2019</api:year></api:date></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Chen</api:last-name><api:initials>X</api:initials><api:first-names>Xie</api:first-names><api:separate-first-names><api:first-name>Xie</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Liu</api:last-name><api:initials>X</api:initials><api:first-names>Xunying</api:first-names><api:separate-first-names><api:first-name>Xunying</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Wang</api:last-name><api:initials>Y</api:initials><api:first-names>Yu</api:first-names><api:separate-first-names><api:first-name>Yu</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Wong</api:last-name><api:initials>JHM</api:initials><api:first-names>Jeremy HM</api:first-names><api:separate-first-names><api:first-name>Jeremy</api:first-name><api:first-name>H</api:first-name><api:first-name>M</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="c-goldoa" type="boolean" display-name="Gold Open Access?"><api:boolean>false</api:boolean></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/taslp.2019.2922048</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/taslp.2019.2922048"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/taslp.2019.2922048"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2329-9304</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989238"/></api:links></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2329-9290</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989238"/></api:links></api:field><api:field name="issue" type="text" display-name="Issue"><api:text>9</api:text></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>IEEE/ACM Transactions on Audio, Speech, and Language Processing</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>Recurrent neural network</api:keyword><api:keyword>language model</api:keyword><api:keyword>succeeding words</api:keyword><api:keyword>speech recognition</api:keyword><api:keyword>keyword search</api:keyword></api:keywords></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>11</api:day><api:month>6</api:month><api:year>2019</api:year></api:date></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1444</api:begin-page><api:end-page>1454</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:month>9</api:month><api:year>2019</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Institute of Electrical and Electronics Engineers (IEEE)</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>5</api:day><api:month>9</api:month><api:year>2019</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Exploiting future word contexts in neural network language models for speech recognition</api:text></api:field><api:field name="types" type="list" display-name="Sub types"><api:items><api:item>Original research article</api:item></api:items></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>27</api:text></api:field></api:native></api:record><api:record format="native" id="3348869" source-id="13" source-name="crossref" source-display-name="Crossref" id-at-source="10.1109/taslp.2019.2922048" last-modified-when="2022-09-11T19:21:23.35+01:00"><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Chen</api:last-name><api:initials>X</api:initials><api:first-names>Xie</api:first-names><api:separate-first-names><api:first-name>Xie</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="orcid">0000-0001-7423-617X</api:identifier></api:identifiers></api:person><api:person><api:last-name>Liu</api:last-name><api:initials>X</api:initials><api:first-names>Xunying</api:first-names><api:separate-first-names><api:first-name>Xunying</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="orcid">0000-0001-6725-1160</api:identifier></api:identifiers></api:person><api:person><api:last-name>Wang</api:last-name><api:initials>Y</api:initials><api:first-names>Yu</api:first-names><api:separate-first-names><api:first-name>Yu</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="orcid">0000-0001-9500-081X</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Wong</api:last-name><api:initials>JHM</api:initials><api:first-names>Jeremy HM</api:first-names><api:separate-first-names><api:first-name>Jeremy</api:first-name><api:first-name>H</api:first-name><api:first-name>M</api:first-name></api:separate-first-names><api:identifiers><api:identifier scheme="orcid">0000-0003-3742-7510</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/taslp.2019.2922048</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/taslp.2019.2922048"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/taslp.2019.2922048"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2329-9304</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989238"/></api:links></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2329-9290</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989238"/></api:links></api:field><api:field name="issue" type="text" display-name="Issue"><api:text>9</api:text></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>IEEE/ACM Transactions on Audio, Speech, and Language Processing</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1444</api:begin-page><api:end-page>1454</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:month>9</api:month><api:year>2019</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Institute of Electrical and Electronics Engineers (IEEE)</api:text></api:field><api:field name="publisher-url" type="text" display-name="Link 2"><api:text>http://dx.doi.org/10.1109/taslp.2019.2922048</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>13</api:day><api:month>7</api:month><api:year>2022</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Exploiting Future Word Contexts in Neural Network Language Models for Speech Recognition</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>27</api:text></api:field></api:native></api:record><api:record format="native" id="3347048" source-id="7" source-name="scopus" source-display-name="Scopus" id-at-source="2-s2.0-85068227809" last-modified-when="2024-04-23T12:33:20.34+01:00"><api:citation-count>17</api:citation-count><api:native><api:field name="abstract" type="text" display-name="Abstract"><api:text>Language modeling is a crucial component in a wide range of applications including speech recognition. Language models (LMs) are usually constructed by splitting a sentence into words and computing the probability of a word based on its word history. This sentence probability calculation, making use of conditional probability distributions, assumes that there is little impact from approximations used in the LMs, including the word history representations and finite training data. This motivates examining models that make use of additional information from the sentence. In this paper, future word information, in addition to the history, is used to predict the probability of the current word. For recurrent neural network LMs (RNNLMs), this information can be encapsulated in a bi-directional model. However, if used directly, this form of model is computationally expensive when trained on large quantities of data, and can be problematic when used with word lattices. This paper proposes a novel neural network language model structure, the succeeding-word RNNLM, su-RNNLM, to address these issues. Instead of using a recurrent unit to capture the complete future word contexts, a feedforward unit is used to model a fixed finite number of succeeding words. This is more efficient in training than bi-directional models and can be applied to lattice rescoring. The generated lattices can be used for downstream applications, such as confusion network decoding and keyword search. Experimental results on speech recognition and keyword spotting tasks illustrate the empirical usefulness of future word information, and the flexibility of the proposed model to represent this information.</api:text></api:field><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Chen</api:last-name><api:initials>X</api:initials><api:first-names>X</api:first-names><api:separate-first-names><api:first-name>X</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">56303280300</api:identifier><api:identifier scheme="orcid">0000-0001-7423-617X</api:identifier></api:identifiers></api:person><api:person><api:last-name>Liu</api:last-name><api:initials>X</api:initials><api:first-names>X</api:first-names><api:separate-first-names><api:first-name>X</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="HK"><api:line type="organisation">Chinese University of Hong Kong</api:line><api:line type="city">Hong Kong</api:line><api:line type="country">Hong Kong</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">13608959800</api:identifier><api:identifier scheme="orcid">0000-0001-6725-1160</api:identifier></api:identifiers></api:person><api:person><api:last-name>Wang</api:last-name><api:initials>Y</api:initials><api:first-names>Y</api:first-names><api:separate-first-names><api:first-name>Y</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">58396880400</api:identifier><api:identifier scheme="orcid">0000-0001-9500-081X</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>A</api:first-names><api:separate-first-names><api:first-name>A</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">35743526400</api:identifier></api:identifiers></api:person><api:person><api:last-name>Wong</api:last-name><api:initials>JHM</api:initials><api:first-names>JHM</api:first-names><api:separate-first-names><api:first-name>J</api:first-name><api:first-name>H</api:first-name><api:first-name>M</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">57191855979</api:identifier><api:identifier scheme="orcid">0000-0003-3742-7510</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>MJF</api:first-names><api:separate-first-names><api:first-name>M</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="scopus-author-id">7004447872</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/TASLP.2019.2922048</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/TASLP.2019.2922048"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/TASLP.2019.2922048"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2329-9304</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989238"/></api:links></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2329-9290</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989238"/></api:links></api:field><api:field name="issue" type="text" display-name="Issue"><api:text>9</api:text></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>IEEE/ACM Transactions on Audio Speech and Language Processing</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1444</api:begin-page><api:end-page>1454</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:day>1</api:day><api:month>9</api:month><api:year>2019</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Exploiting Future Word Contexts in Neural Network Language Models for Speech Recognition</api:text></api:field><api:field name="types" type="list" display-name="Sub types"><api:items><api:item>Journal Article</api:item></api:items></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>27</api:text></api:field></api:native></api:record><api:record format="native" id="3348296" source-id="10" source-name="dimensions" source-display-name="Dimensions" id-at-source="pub.1117050748" last-modified-when="2024-04-28T07:05:23.323+01:00"><api:citation-count>14</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Chen</api:last-name><api:initials>X</api:initials><api:first-names>Xie</api:first-names><api:separate-first-names><api:first-name>Xie</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address><api:address iso-country-code="US"><api:line type="organisation">Microsoft (United States)</api:line><api:line type="city">Redmond</api:line><api:line type="state">Washington</api:line><api:line type="country">United States</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.013115646576.88</api:identifier></api:identifiers><api:author-types><api:author-type>corresponding</api:author-type></api:author-types></api:person><api:person><api:last-name>Liu</api:last-name><api:initials>X</api:initials><api:first-names>Xunying</api:first-names><api:separate-first-names><api:first-name>Xunying</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="CN"><api:line type="organisation">Chinese University of Hong Kong</api:line><api:line type="city">Hong Kong</api:line><api:line type="country">China</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.011213240053.80</api:identifier></api:identifiers></api:person><api:person><api:last-name>Wang</api:last-name><api:initials>Y</api:initials><api:first-names>Yu</api:first-names><api:separate-first-names><api:first-name>Yu</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.013713227176.28</api:identifier></api:identifiers></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.011072730015.33</api:identifier></api:identifiers></api:person><api:person><api:last-name>Wong</api:last-name><api:initials>JHM</api:initials><api:first-names>Jeremy HM</api:first-names><api:separate-first-names><api:first-name>Jeremy</api:first-name><api:first-name>H</api:first-name><api:first-name>M</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.013300771625.24</api:identifier></api:identifiers></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names><api:addresses><api:address iso-country-code="GB"><api:line type="organisation">University of Cambridge</api:line><api:line type="city">Cambridge</api:line><api:line type="country">United Kingdom</api:line></api:address></api:addresses><api:identifiers><api:identifier scheme="dimensions-researcher-id">ur.015135510264.46</api:identifier></api:identifiers></api:person></api:people></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/taslp.2019.2922048</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/taslp.2019.2922048"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/taslp.2019.2922048"/></api:links></api:field><api:field name="field-citation-ratio" type="decimal" display-name="Field citation ratio"><api:decimal>4.15</api:decimal></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2329-9290</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989238"/></api:links></api:field><api:field name="issue" type="text" display-name="Issue"><api:text>9</api:text></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>IEEE/ACM Transactions on Audio Speech and Language Processing</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword scheme="for-2020">46 Information and Computing Sciences</api:keyword><api:keyword scheme="for-2020">4611 Machine Learning</api:keyword><api:keyword scheme="rcdc">Neurosciences</api:keyword></api:keywords></api:field><api:field name="online-publication-date" type="date" display-name="Online publication date"><api:date><api:day>11</api:day><api:month>6</api:month><api:year>2019</api:year></api:date></api:field><api:field name="open-access-status" type="text" display-name="Open access status"><api:text>Green OA</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1444</api:begin-page><api:end-page>1454</api:end-page></api:pagination></api:field><api:field name="publisher" type="text" display-name="Publisher"><api:text>Institute of Electrical and Electronics Engineers (IEEE)</api:text></api:field><api:field name="record-created-at-source-date" type="date" display-name="Record created at source"><api:date><api:day>13</api:day><api:month>6</api:month><api:year>2019</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Exploiting Future Word Contexts in Neural Network Language Models for Speech Recognition</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>27</api:text></api:field></api:native></api:record><api:record format="native" id="3346646" source-id="11" source-name="wos-lite" source-display-name="Web of Science (Lite)" id-at-source="WOS:000473469800004" last-modified-when="2024-03-26T14:06:26.813+00:00"><api:citation-count>13</api:citation-count><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Chen</api:last-name><api:initials>X</api:initials><api:first-names>Xie</api:first-names><api:separate-first-names><api:first-name>Xie</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Liu</api:last-name><api:initials>X</api:initials><api:first-names>Xunying</api:first-names><api:separate-first-names><api:first-name>Xunying</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Wang</api:last-name><api:initials>Y</api:initials><api:first-names>Yu</api:first-names><api:separate-first-names><api:first-name>Yu</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Wong</api:last-name><api:initials>JHM</api:initials><api:first-names>Jeremy HM</api:first-names><api:separate-first-names><api:first-name>Jeremy</api:first-name><api:first-name>H</api:first-name><api:first-name>M</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="author-url" type="text" display-name="Link 1"><api:text>https://www.webofscience.com/api/gateway?GWVersion=2&amp;SrcApp=sheffield_elements_live&amp;SrcAuth=WosAPI&amp;KeyUT=WOS:000473469800004&amp;DestLinkType=FullRecord&amp;DestApp=WOS_CPL</api:text></api:field><api:field name="doi" type="text" display-name="DOI"><api:text>10.1109/TASLP.2019.2922048</api:text><api:links><api:link type="doi" href="http://doi.org/10.1109/TASLP.2019.2922048"/><api:link type="altmetric" href="http://www.altmetric.com/details.php?doi=10.1109/TASLP.2019.2922048"/></api:links></api:field><api:field name="eissn" type="text" display-name="eISSN"><api:text>2329-9304</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989238"/></api:links></api:field><api:field name="external-identifiers" type="identifier-list" display-name="External identifiers"><api:identifiers><api:identifier scheme="isidoc">IG0GS</api:identifier></api:identifiers></api:field><api:field name="issn" type="text" display-name="ISSN"><api:text>2329-9290</api:text><api:links><api:link type="elements/journal" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989238"/></api:links></api:field><api:field name="issue" type="text" display-name="Issue"><api:text>9</api:text></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING</api:text></api:field><api:field name="keywords" type="keyword-list" display-name="Keywords"><api:keywords><api:keyword>Recurrent neural network</api:keyword><api:keyword>language model</api:keyword><api:keyword>succeeding words</api:keyword><api:keyword>speech recognition</api:keyword><api:keyword>keyword search</api:keyword></api:keywords></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1444</api:begin-page><api:end-page>1454</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2019</api:year></api:date></api:field><api:field name="publication-status" type="text" display-name="Status"><api:text>Published</api:text></api:field><api:field name="title" type="text" display-name="Title"><api:text>Exploiting Future Word Contexts in Neural Network Language Models for Speech Recognition</api:text></api:field><api:field name="types" type="list" display-name="Sub types"><api:items><api:item>Article</api:item></api:items></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>27</api:text></api:field></api:native></api:record><api:record format="native" id="3471806" source-id="6" source-name="dblp" source-display-name="DBLP" id-at-source="journals/taslp/ChenLWRWG19" last-modified-when="2023-11-21T13:06:16.043+00:00"><api:native><api:field name="authors" type="person-list" display-name="Authors"><api:people><api:person><api:last-name>Chen</api:last-name><api:initials>X</api:initials><api:first-names>Xie</api:first-names><api:separate-first-names><api:first-name>Xie</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Liu</api:last-name><api:initials>X</api:initials><api:first-names>Xunying</api:first-names><api:separate-first-names><api:first-name>Xunying</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Wang</api:last-name><api:initials>Y</api:initials><api:first-names>Yu</api:first-names><api:separate-first-names><api:first-name>Yu</api:first-name></api:separate-first-names></api:person><api:person><api:links><api:link type="elements/user" id="28583" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/users/28583"/></api:links><api:last-name>Ragni</api:last-name><api:initials>A</api:initials><api:first-names>Anton</api:first-names><api:separate-first-names><api:first-name>Anton</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Wong</api:last-name><api:initials>JHM</api:initials><api:first-names>Jeremy Heng Meng</api:first-names><api:separate-first-names><api:first-name>Jeremy</api:first-name><api:first-name>Heng</api:first-name><api:first-name>Meng</api:first-name></api:separate-first-names></api:person><api:person><api:last-name>Gales</api:last-name><api:initials>MJF</api:initials><api:first-names>Mark JF</api:first-names><api:separate-first-names><api:first-name>Mark</api:first-name><api:first-name>J</api:first-name><api:first-name>F</api:first-name></api:separate-first-names></api:person></api:people></api:field><api:field name="journal" type="text" display-name="Journal"><api:text>IEEE ACM Trans. Audio Speech Lang. Process.</api:text></api:field><api:field name="number" type="text" display-name="Article number"><api:text>9</api:text></api:field><api:field name="pagination" type="pagination" display-name="Pagination"><api:pagination><api:begin-page>1444</api:begin-page><api:end-page>1454</api:end-page></api:pagination></api:field><api:field name="publication-date" type="date" display-name="Publication date"><api:date><api:year>2019</api:year></api:date></api:field><api:field name="title" type="text" display-name="Title"><api:text>Exploiting Future Word Contexts in Neural Network Language Models for Speech Recognition.</api:text></api:field><api:field name="volume" type="text" display-name="Volume"><api:text>27</api:text></api:field></api:native></api:record></api:records><api:fields/><api:all-labels type="keyword-list"><api:keywords><api:keyword origin="record-data" source="eprints">Recurrent neural network</api:keyword><api:keyword origin="record-data" source="eprints">language model</api:keyword><api:keyword origin="record-data" source="eprints">succeeding words</api:keyword><api:keyword origin="record-data" source="eprints">speech recognition</api:keyword><api:keyword origin="record-data" source="eprints">keyword search</api:keyword><api:keyword origin="record-data" source="manual">Recurrent neural network</api:keyword><api:keyword origin="record-data" source="manual">language model</api:keyword><api:keyword origin="record-data" source="manual">succeeding words</api:keyword><api:keyword origin="record-data" source="manual">speech recognition</api:keyword><api:keyword origin="record-data" source="manual">keyword search</api:keyword><api:keyword scheme="for-2020" origin="record-data" source="dimensions">46 Information and Computing Sciences</api:keyword><api:keyword scheme="for-2020" origin="record-data" source="dimensions">4611 Machine Learning</api:keyword><api:keyword scheme="rcdc" origin="record-data" source="dimensions">Neurosciences</api:keyword><api:keyword origin="record-data" source="wos-lite">Recurrent neural network</api:keyword><api:keyword origin="record-data" source="wos-lite">language model</api:keyword><api:keyword origin="record-data" source="wos-lite">succeeding words</api:keyword><api:keyword origin="record-data" source="wos-lite">speech recognition</api:keyword><api:keyword origin="record-data" source="wos-lite">keyword search</api:keyword><api:keyword scheme="for-2020" origin="issn-inferred">4006 Communications engineering</api:keyword><api:keyword scheme="for-2020" origin="issn-inferred">4602 Artificial intelligence</api:keyword><api:keyword scheme="for-2020" origin="issn-inferred">4603 Computer vision and multimedia computation</api:keyword></api:keywords></api:all-labels><api:journal issn="2329-9290" href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/journals/989238" title="IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP)"><api:records><api:record source-name="summary"><api:title>IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP)</api:title></api:record></api:records></api:journal><api:relationships href="https://mypublications.shef.ac.uk:8091/secure-api/v6.13/publications/1254665/relationships"/><api:flagged-as-not-externally-funded>true</api:flagged-as-not-externally-funded></api:object></api:result></api:response>